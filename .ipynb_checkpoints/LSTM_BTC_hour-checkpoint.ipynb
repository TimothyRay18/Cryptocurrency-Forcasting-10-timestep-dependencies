{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499ef9d1-2655-483e-9f50-0badccf17d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for lstm\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from openpyxl.workbook import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b213829a-295a-46a7-bbd7-152bcce0aeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set-up to have matplotlib use its support for notebook inline plots\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ed0706-d5c2-4868-beee-6933c00b0a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unix</th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Volume BTC</th>\n",
       "      <th>Volume USDT</th>\n",
       "      <th>tradecount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.669684e+12</td>\n",
       "      <td>2022-11-29 01:00:00</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>16178.74</td>\n",
       "      <td>16309.03</td>\n",
       "      <td>16171.17</td>\n",
       "      <td>16250.77</td>\n",
       "      <td>9098.01403</td>\n",
       "      <td>1.476206e+08</td>\n",
       "      <td>227013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.669680e+12</td>\n",
       "      <td>2022-11-29 00:00:00</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>16212.18</td>\n",
       "      <td>16224.83</td>\n",
       "      <td>16100.00</td>\n",
       "      <td>16130.62</td>\n",
       "      <td>6565.59515</td>\n",
       "      <td>1.061095e+08</td>\n",
       "      <td>125147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.669676e+12</td>\n",
       "      <td>2022-11-28 23:00:00</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>16220.36</td>\n",
       "      <td>16245.92</td>\n",
       "      <td>16195.63</td>\n",
       "      <td>16212.91</td>\n",
       "      <td>4925.09556</td>\n",
       "      <td>7.988443e+07</td>\n",
       "      <td>112061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.669673e+12</td>\n",
       "      <td>2022-11-28 22:00:00</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>16200.56</td>\n",
       "      <td>16235.21</td>\n",
       "      <td>16195.72</td>\n",
       "      <td>16220.76</td>\n",
       "      <td>3742.40807</td>\n",
       "      <td>6.068580e+07</td>\n",
       "      <td>89180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.669669e+12</td>\n",
       "      <td>2022-11-28 21:00:00</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>16256.33</td>\n",
       "      <td>16262.77</td>\n",
       "      <td>16186.00</td>\n",
       "      <td>16199.59</td>\n",
       "      <td>6780.81367</td>\n",
       "      <td>1.099914e+08</td>\n",
       "      <td>155815.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46291</th>\n",
       "      <td>1.502957e+09</td>\n",
       "      <td>2017-08-17 08:00:00</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>4349.99</td>\n",
       "      <td>4377.85</td>\n",
       "      <td>4333.32</td>\n",
       "      <td>4360.69</td>\n",
       "      <td>0.94990</td>\n",
       "      <td>4.139700e+03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46292</th>\n",
       "      <td>1.502953e+09</td>\n",
       "      <td>2017-08-17 07:00:00</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>4324.35</td>\n",
       "      <td>4349.99</td>\n",
       "      <td>4287.41</td>\n",
       "      <td>4349.99</td>\n",
       "      <td>4.44000</td>\n",
       "      <td>1.924106e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46293</th>\n",
       "      <td>1.502950e+09</td>\n",
       "      <td>2017-08-17 06:00:00</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>4315.32</td>\n",
       "      <td>4345.45</td>\n",
       "      <td>4309.37</td>\n",
       "      <td>4324.35</td>\n",
       "      <td>7.23000</td>\n",
       "      <td>3.128231e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46294</th>\n",
       "      <td>1.502946e+09</td>\n",
       "      <td>2017-08-17 05:00:00</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>4308.83</td>\n",
       "      <td>4328.69</td>\n",
       "      <td>4291.37</td>\n",
       "      <td>4315.32</td>\n",
       "      <td>23.23000</td>\n",
       "      <td>1.003048e+05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46295</th>\n",
       "      <td>1.502942e+09</td>\n",
       "      <td>2017-08-17 04:00:00</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>16199.91</td>\n",
       "      <td>16199.91</td>\n",
       "      <td>4261.32</td>\n",
       "      <td>4308.83</td>\n",
       "      <td>44.51000</td>\n",
       "      <td>1.909529e+05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46296 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               unix                 date    symbol      open      high  \\\n",
       "0      1.669684e+12  2022-11-29 01:00:00  BTC/USDT  16178.74  16309.03   \n",
       "1      1.669680e+12  2022-11-29 00:00:00  BTC/USDT  16212.18  16224.83   \n",
       "2      1.669676e+12  2022-11-28 23:00:00  BTC/USDT  16220.36  16245.92   \n",
       "3      1.669673e+12  2022-11-28 22:00:00  BTC/USDT  16200.56  16235.21   \n",
       "4      1.669669e+12  2022-11-28 21:00:00  BTC/USDT  16256.33  16262.77   \n",
       "...             ...                  ...       ...       ...       ...   \n",
       "46291  1.502957e+09  2017-08-17 08:00:00  BTC/USDT   4349.99   4377.85   \n",
       "46292  1.502953e+09  2017-08-17 07:00:00  BTC/USDT   4324.35   4349.99   \n",
       "46293  1.502950e+09  2017-08-17 06:00:00  BTC/USDT   4315.32   4345.45   \n",
       "46294  1.502946e+09  2017-08-17 05:00:00  BTC/USDT   4308.83   4328.69   \n",
       "46295  1.502942e+09  2017-08-17 04:00:00  BTC/USDT  16199.91  16199.91   \n",
       "\n",
       "            low     close  Volume BTC   Volume USDT  tradecount  \n",
       "0      16171.17  16250.77  9098.01403  1.476206e+08    227013.0  \n",
       "1      16100.00  16130.62  6565.59515  1.061095e+08    125147.0  \n",
       "2      16195.63  16212.91  4925.09556  7.988443e+07    112061.0  \n",
       "3      16195.72  16220.76  3742.40807  6.068580e+07     89180.0  \n",
       "4      16186.00  16199.59  6780.81367  1.099914e+08    155815.0  \n",
       "...         ...       ...         ...           ...         ...  \n",
       "46291   4333.32   4360.69     0.94990  4.139700e+03         NaN  \n",
       "46292   4287.41   4349.99     4.44000  1.924106e+04         NaN  \n",
       "46293   4309.37   4324.35     7.23000  3.128231e+04         NaN  \n",
       "46294   4291.37   4315.32    23.23000  1.003048e+05         NaN  \n",
       "46295   4261.32   4308.83    44.51000  1.909529e+05         NaN  \n",
       "\n",
       "[46296 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc_dfd = pd.read_csv('Binance_BTCUSDT_1h.csv')\n",
    "btc_dfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41062755-9cca-4348-91bc-e80d46b79c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Volume USDT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-29 00:00:00</td>\n",
       "      <td>16212.18</td>\n",
       "      <td>16224.83</td>\n",
       "      <td>16100.00</td>\n",
       "      <td>16130.62</td>\n",
       "      <td>1.061095e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-28 23:00:00</td>\n",
       "      <td>16220.36</td>\n",
       "      <td>16245.92</td>\n",
       "      <td>16195.63</td>\n",
       "      <td>16212.91</td>\n",
       "      <td>7.988443e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-28 22:00:00</td>\n",
       "      <td>16200.56</td>\n",
       "      <td>16235.21</td>\n",
       "      <td>16195.72</td>\n",
       "      <td>16220.76</td>\n",
       "      <td>6.068580e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-28 21:00:00</td>\n",
       "      <td>16256.33</td>\n",
       "      <td>16262.77</td>\n",
       "      <td>16186.00</td>\n",
       "      <td>16199.59</td>\n",
       "      <td>1.099914e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-11-28 20:00:00</td>\n",
       "      <td>16225.53</td>\n",
       "      <td>16271.09</td>\n",
       "      <td>16211.26</td>\n",
       "      <td>16256.33</td>\n",
       "      <td>9.872633e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43011</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>13410.03</td>\n",
       "      <td>13623.29</td>\n",
       "      <td>13322.15</td>\n",
       "      <td>13601.01</td>\n",
       "      <td>4.394871e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43012</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>13330.18</td>\n",
       "      <td>13611.27</td>\n",
       "      <td>13290.00</td>\n",
       "      <td>13410.03</td>\n",
       "      <td>5.470652e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43013</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>13203.06</td>\n",
       "      <td>13418.43</td>\n",
       "      <td>13200.00</td>\n",
       "      <td>13330.18</td>\n",
       "      <td>5.402610e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43014</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>13529.01</td>\n",
       "      <td>13595.89</td>\n",
       "      <td>13155.38</td>\n",
       "      <td>13203.06</td>\n",
       "      <td>4.832292e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43015</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>13716.36</td>\n",
       "      <td>13716.36</td>\n",
       "      <td>13400.01</td>\n",
       "      <td>13529.01</td>\n",
       "      <td>5.769896e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43015 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date      open      high       low     close  \\\n",
       "1      2022-11-29 00:00:00  16212.18  16224.83  16100.00  16130.62   \n",
       "2      2022-11-28 23:00:00  16220.36  16245.92  16195.63  16212.91   \n",
       "3      2022-11-28 22:00:00  16200.56  16235.21  16195.72  16220.76   \n",
       "4      2022-11-28 21:00:00  16256.33  16262.77  16186.00  16199.59   \n",
       "5      2022-11-28 20:00:00  16225.53  16271.09  16211.26  16256.33   \n",
       "...                    ...       ...       ...       ...       ...   \n",
       "43011  2018-01-01 04:00:00  13410.03  13623.29  13322.15  13601.01   \n",
       "43012  2018-01-01 03:00:00  13330.18  13611.27  13290.00  13410.03   \n",
       "43013  2018-01-01 02:00:00  13203.06  13418.43  13200.00  13330.18   \n",
       "43014  2018-01-01 01:00:00  13529.01  13595.89  13155.38  13203.06   \n",
       "43015  2018-01-01 00:00:00  13716.36  13716.36  13400.01  13529.01   \n",
       "\n",
       "        Volume USDT  \n",
       "1      1.061095e+08  \n",
       "2      7.988443e+07  \n",
       "3      6.068580e+07  \n",
       "4      1.099914e+08  \n",
       "5      9.872633e+07  \n",
       "...             ...  \n",
       "43011  4.394871e+06  \n",
       "43012  5.470652e+06  \n",
       "43013  5.402610e+06  \n",
       "43014  4.832292e+06  \n",
       "43015  5.769896e+06  \n",
       "\n",
       "[43015 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc_clean = btc_dfd.drop(['unix', 'symbol', 'Volume BTC', 'tradecount'], axis=1)\n",
    "# res_btc = btc_clean[~(btc_clean['date'] < pd.to_datetime(\"2018-01-01\").date())]\n",
    "btc_clean = btc_clean[1:43016]\n",
    "btc_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc368c1b-a82f-4dbf-85c4-f19ebff7a21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Volume USDT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43015</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>13716.36</td>\n",
       "      <td>13716.36</td>\n",
       "      <td>13400.01</td>\n",
       "      <td>13529.01</td>\n",
       "      <td>5.769896e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43014</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>13529.01</td>\n",
       "      <td>13595.89</td>\n",
       "      <td>13155.38</td>\n",
       "      <td>13203.06</td>\n",
       "      <td>4.832292e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43013</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>13203.06</td>\n",
       "      <td>13418.43</td>\n",
       "      <td>13200.00</td>\n",
       "      <td>13330.18</td>\n",
       "      <td>5.402610e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43012</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>13330.18</td>\n",
       "      <td>13611.27</td>\n",
       "      <td>13290.00</td>\n",
       "      <td>13410.03</td>\n",
       "      <td>5.470652e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43011</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>13410.03</td>\n",
       "      <td>13623.29</td>\n",
       "      <td>13322.15</td>\n",
       "      <td>13601.01</td>\n",
       "      <td>4.394871e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-11-28 20:00:00</td>\n",
       "      <td>16225.53</td>\n",
       "      <td>16271.09</td>\n",
       "      <td>16211.26</td>\n",
       "      <td>16256.33</td>\n",
       "      <td>9.872633e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-28 21:00:00</td>\n",
       "      <td>16256.33</td>\n",
       "      <td>16262.77</td>\n",
       "      <td>16186.00</td>\n",
       "      <td>16199.59</td>\n",
       "      <td>1.099914e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-28 22:00:00</td>\n",
       "      <td>16200.56</td>\n",
       "      <td>16235.21</td>\n",
       "      <td>16195.72</td>\n",
       "      <td>16220.76</td>\n",
       "      <td>6.068580e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-28 23:00:00</td>\n",
       "      <td>16220.36</td>\n",
       "      <td>16245.92</td>\n",
       "      <td>16195.63</td>\n",
       "      <td>16212.91</td>\n",
       "      <td>7.988443e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-29 00:00:00</td>\n",
       "      <td>16212.18</td>\n",
       "      <td>16224.83</td>\n",
       "      <td>16100.00</td>\n",
       "      <td>16130.62</td>\n",
       "      <td>1.061095e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43015 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date      open      high       low     close  \\\n",
       "43015  2018-01-01 00:00:00  13716.36  13716.36  13400.01  13529.01   \n",
       "43014  2018-01-01 01:00:00  13529.01  13595.89  13155.38  13203.06   \n",
       "43013  2018-01-01 02:00:00  13203.06  13418.43  13200.00  13330.18   \n",
       "43012  2018-01-01 03:00:00  13330.18  13611.27  13290.00  13410.03   \n",
       "43011  2018-01-01 04:00:00  13410.03  13623.29  13322.15  13601.01   \n",
       "...                    ...       ...       ...       ...       ...   \n",
       "5      2022-11-28 20:00:00  16225.53  16271.09  16211.26  16256.33   \n",
       "4      2022-11-28 21:00:00  16256.33  16262.77  16186.00  16199.59   \n",
       "3      2022-11-28 22:00:00  16200.56  16235.21  16195.72  16220.76   \n",
       "2      2022-11-28 23:00:00  16220.36  16245.92  16195.63  16212.91   \n",
       "1      2022-11-29 00:00:00  16212.18  16224.83  16100.00  16130.62   \n",
       "\n",
       "        Volume USDT  \n",
       "43015  5.769896e+06  \n",
       "43014  4.832292e+06  \n",
       "43013  5.402610e+06  \n",
       "43012  5.470652e+06  \n",
       "43011  4.394871e+06  \n",
       "...             ...  \n",
       "5      9.872633e+07  \n",
       "4      1.099914e+08  \n",
       "3      6.068580e+07  \n",
       "2      7.988443e+07  \n",
       "1      1.061095e+08  \n",
       "\n",
       "[43015 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc = btc_clean.iloc[::-1]\n",
    "btc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "483f3731-9efb-47c6-af9c-6eadc95287e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Volume USDT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>13716.36</td>\n",
       "      <td>13716.36</td>\n",
       "      <td>13400.01</td>\n",
       "      <td>13529.01</td>\n",
       "      <td>5.769896e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>13529.01</td>\n",
       "      <td>13595.89</td>\n",
       "      <td>13155.38</td>\n",
       "      <td>13203.06</td>\n",
       "      <td>4.832292e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>13203.06</td>\n",
       "      <td>13418.43</td>\n",
       "      <td>13200.00</td>\n",
       "      <td>13330.18</td>\n",
       "      <td>5.402610e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>13330.18</td>\n",
       "      <td>13611.27</td>\n",
       "      <td>13290.00</td>\n",
       "      <td>13410.03</td>\n",
       "      <td>5.470652e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>13410.03</td>\n",
       "      <td>13623.29</td>\n",
       "      <td>13322.15</td>\n",
       "      <td>13601.01</td>\n",
       "      <td>4.394871e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43010</th>\n",
       "      <td>2022-11-28 20:00:00</td>\n",
       "      <td>16225.53</td>\n",
       "      <td>16271.09</td>\n",
       "      <td>16211.26</td>\n",
       "      <td>16256.33</td>\n",
       "      <td>9.872633e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43011</th>\n",
       "      <td>2022-11-28 21:00:00</td>\n",
       "      <td>16256.33</td>\n",
       "      <td>16262.77</td>\n",
       "      <td>16186.00</td>\n",
       "      <td>16199.59</td>\n",
       "      <td>1.099914e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43012</th>\n",
       "      <td>2022-11-28 22:00:00</td>\n",
       "      <td>16200.56</td>\n",
       "      <td>16235.21</td>\n",
       "      <td>16195.72</td>\n",
       "      <td>16220.76</td>\n",
       "      <td>6.068580e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43013</th>\n",
       "      <td>2022-11-28 23:00:00</td>\n",
       "      <td>16220.36</td>\n",
       "      <td>16245.92</td>\n",
       "      <td>16195.63</td>\n",
       "      <td>16212.91</td>\n",
       "      <td>7.988443e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43014</th>\n",
       "      <td>2022-11-29 00:00:00</td>\n",
       "      <td>16212.18</td>\n",
       "      <td>16224.83</td>\n",
       "      <td>16100.00</td>\n",
       "      <td>16130.62</td>\n",
       "      <td>1.061095e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43015 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date      open      high       low     close  \\\n",
       "0      2018-01-01 00:00:00  13716.36  13716.36  13400.01  13529.01   \n",
       "1      2018-01-01 01:00:00  13529.01  13595.89  13155.38  13203.06   \n",
       "2      2018-01-01 02:00:00  13203.06  13418.43  13200.00  13330.18   \n",
       "3      2018-01-01 03:00:00  13330.18  13611.27  13290.00  13410.03   \n",
       "4      2018-01-01 04:00:00  13410.03  13623.29  13322.15  13601.01   \n",
       "...                    ...       ...       ...       ...       ...   \n",
       "43010  2022-11-28 20:00:00  16225.53  16271.09  16211.26  16256.33   \n",
       "43011  2022-11-28 21:00:00  16256.33  16262.77  16186.00  16199.59   \n",
       "43012  2022-11-28 22:00:00  16200.56  16235.21  16195.72  16220.76   \n",
       "43013  2022-11-28 23:00:00  16220.36  16245.92  16195.63  16212.91   \n",
       "43014  2022-11-29 00:00:00  16212.18  16224.83  16100.00  16130.62   \n",
       "\n",
       "        Volume USDT  \n",
       "0      5.769896e+06  \n",
       "1      4.832292e+06  \n",
       "2      5.402610e+06  \n",
       "3      5.470652e+06  \n",
       "4      4.394871e+06  \n",
       "...             ...  \n",
       "43010  9.872633e+07  \n",
       "43011  1.099914e+08  \n",
       "43012  6.068580e+07  \n",
       "43013  7.988443e+07  \n",
       "43014  1.061095e+08  \n",
       "\n",
       "[43015 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc = btc.reset_index(drop=True)\n",
    "btc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "140ecfee-f8cf-45f6-b3c6-49e8e7458101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c42a7847-70b8-4487-a874-67e370666724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [date, open, high, low, close, Volume USDT]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "duplicates = btc[btc.duplicated()]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8e525a6-83d0-4c8b-9875-33e0e15480ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No duplicated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08213717-a303-4c9e-97bb-280204035109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date           0\n",
       "open           0\n",
       "high           0\n",
       "low            0\n",
       "close          0\n",
       "Volume USDT    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aff76bd7-16f2-4bf2-8a64-f1f6a1194661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4efa14c4-f85e-47c3-bc04-7f0d029d3a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>Volume USDT</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13716.36</td>\n",
       "      <td>13716.36</td>\n",
       "      <td>13400.01</td>\n",
       "      <td>5.769896e+06</td>\n",
       "      <td>13529.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13529.01</td>\n",
       "      <td>13595.89</td>\n",
       "      <td>13155.38</td>\n",
       "      <td>4.832292e+06</td>\n",
       "      <td>13203.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13203.06</td>\n",
       "      <td>13418.43</td>\n",
       "      <td>13200.00</td>\n",
       "      <td>5.402610e+06</td>\n",
       "      <td>13330.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13330.18</td>\n",
       "      <td>13611.27</td>\n",
       "      <td>13290.00</td>\n",
       "      <td>5.470652e+06</td>\n",
       "      <td>13410.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13410.03</td>\n",
       "      <td>13623.29</td>\n",
       "      <td>13322.15</td>\n",
       "      <td>4.394871e+06</td>\n",
       "      <td>13601.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43010</th>\n",
       "      <td>16225.53</td>\n",
       "      <td>16271.09</td>\n",
       "      <td>16211.26</td>\n",
       "      <td>9.872633e+07</td>\n",
       "      <td>16256.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43011</th>\n",
       "      <td>16256.33</td>\n",
       "      <td>16262.77</td>\n",
       "      <td>16186.00</td>\n",
       "      <td>1.099914e+08</td>\n",
       "      <td>16199.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43012</th>\n",
       "      <td>16200.56</td>\n",
       "      <td>16235.21</td>\n",
       "      <td>16195.72</td>\n",
       "      <td>6.068580e+07</td>\n",
       "      <td>16220.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43013</th>\n",
       "      <td>16220.36</td>\n",
       "      <td>16245.92</td>\n",
       "      <td>16195.63</td>\n",
       "      <td>7.988443e+07</td>\n",
       "      <td>16212.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43014</th>\n",
       "      <td>16212.18</td>\n",
       "      <td>16224.83</td>\n",
       "      <td>16100.00</td>\n",
       "      <td>1.061095e+08</td>\n",
       "      <td>16130.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43015 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           open      high       low   Volume USDT     close\n",
       "0      13716.36  13716.36  13400.01  5.769896e+06  13529.01\n",
       "1      13529.01  13595.89  13155.38  4.832292e+06  13203.06\n",
       "2      13203.06  13418.43  13200.00  5.402610e+06  13330.18\n",
       "3      13330.18  13611.27  13290.00  5.470652e+06  13410.03\n",
       "4      13410.03  13623.29  13322.15  4.394871e+06  13601.01\n",
       "...         ...       ...       ...           ...       ...\n",
       "43010  16225.53  16271.09  16211.26  9.872633e+07  16256.33\n",
       "43011  16256.33  16262.77  16186.00  1.099914e+08  16199.59\n",
       "43012  16200.56  16235.21  16195.72  6.068580e+07  16220.76\n",
       "43013  16220.36  16245.92  16195.63  7.988443e+07  16212.91\n",
       "43014  16212.18  16224.83  16100.00  1.061095e+08  16130.62\n",
       "\n",
       "[43015 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc = btc[['open', 'high', 'low', 'Volume USDT', 'close']]\n",
    "btc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51dc56af-5903-45ab-a70b-556fb3f3d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "btc_df = scaler.fit_transform(np.array(btc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d98152d5-e8c5-4645-90ea-876a042b25e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16107265, 0.16001778, 0.15688431, 0.00191969, 0.15821418],\n",
       "       [0.15821073, 0.15818735, 0.15313777, 0.00160774, 0.15323493],\n",
       "       [0.15323159, 0.15549101, 0.15382113, 0.00179749, 0.15517683],\n",
       "       ...,\n",
       "       [0.19902076, 0.1982893 , 0.19970096, 0.02019068, 0.19933369],\n",
       "       [0.19932322, 0.19845203, 0.19969958, 0.02657823, 0.19921377],\n",
       "       [0.19919827, 0.19813159, 0.19823499, 0.03530354, 0.1979567 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50d04ca0-f51f-465b-8229-af015c624039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data:  (34412, 5)\n",
      "test_data:  (8603, 5)\n"
     ]
    }
   ],
   "source": [
    "training_size = int(len(btc_df)*0.8)\n",
    "test_size = len(btc_df)-training_size\n",
    "train_data,test_data = btc_df[0:training_size,:],btc_df[training_size:len(btc_df),:]\n",
    "print('train_data: ', train_data.shape)\n",
    "print('test_data: ', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d06c56c-8ef3-4e92-8c96-99b93dbaaa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step)]  \n",
    "        b = dataset[i+time_step][4]\n",
    "        dataX.append(a)\n",
    "        dataY.append(float(b))\n",
    "    \n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "894700da-fd83-4d14-bedd-39f52b99890f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (34401, 10, 5)\n",
      "X_test:  (8592, 10, 5)\n"
     ]
    }
   ],
   "source": [
    "time_step = 10\n",
    "train_X, train_y = create_dataset(train_data, time_step)\n",
    "test_X, test_y = create_dataset(test_data, time_step)\n",
    "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "# X_train = X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
    "# X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)\n",
    "print(\"X_train: \", train_X.shape)\n",
    "print(\"X_test: \", test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f4b787e-f47b-459d-97fa-887ef0780417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.16107265, 0.16001778, 0.15688431, 0.00191969, 0.15821418],\n",
       "        [0.15821073, 0.15818735, 0.15313777, 0.00160774, 0.15323493],\n",
       "        [0.15323159, 0.15549101, 0.15382113, 0.00179749, 0.15517683],\n",
       "        ...,\n",
       "        [0.16205106, 0.16157046, 0.15925831, 0.00127041, 0.1588457 ],\n",
       "        [0.15884223, 0.16030464, 0.15688416, 0.00118336, 0.15777087],\n",
       "        [0.15776743, 0.15931338, 0.15778943, 0.00092558, 0.15955818]],\n",
       "\n",
       "       [[0.15821073, 0.15818735, 0.15313777, 0.00160774, 0.15323493],\n",
       "        [0.15323159, 0.15549101, 0.15382113, 0.00179749, 0.15517683],\n",
       "        [0.15517344, 0.15842103, 0.15519949, 0.00182013, 0.15639663],\n",
       "        ...,\n",
       "        [0.15884223, 0.16030464, 0.15688416, 0.00118336, 0.15777087],\n",
       "        [0.15776743, 0.15931338, 0.15778943, 0.00092558, 0.15955818],\n",
       "        [0.15955469, 0.15912984, 0.15838473, 0.00074592, 0.15884051]],\n",
       "\n",
       "       [[0.15323159, 0.15549101, 0.15382113, 0.00179749, 0.15517683],\n",
       "        [0.15517344, 0.15842103, 0.15519949, 0.00182013, 0.15639663],\n",
       "        [0.15639322, 0.15860367, 0.15569187, 0.00146221, 0.15931407],\n",
       "        ...,\n",
       "        [0.15776743, 0.15931338, 0.15778943, 0.00092558, 0.15955818],\n",
       "        [0.15955469, 0.15912984, 0.15838473, 0.00074592, 0.15884051],\n",
       "        [0.15883704, 0.15809619, 0.15077541, 0.00274369, 0.15350226]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.70238701, 0.7067397 , 0.69161802, 0.06468626, 0.69918658],\n",
       "        [0.69921316, 0.69997744, 0.69660738, 0.02518401, 0.70034512],\n",
       "        [0.70032997, 0.6978056 , 0.69890985, 0.02113432, 0.70094379],\n",
       "        ...,\n",
       "        [0.70715565, 0.70625258, 0.7056165 , 0.03019965, 0.7044909 ],\n",
       "        [0.70447536, 0.70482874, 0.7042945 , 0.02400097, 0.70732264],\n",
       "        [0.70730719, 0.7033294 , 0.69750806, 0.0322464 , 0.69993343]],\n",
       "\n",
       "       [[0.69921316, 0.69997744, 0.69660738, 0.02518401, 0.70034512],\n",
       "        [0.70032997, 0.6978056 , 0.69890985, 0.02113432, 0.70094379],\n",
       "        [0.70092832, 0.70181683, 0.69971053, 0.0241012 , 0.70268236],\n",
       "        ...,\n",
       "        [0.70447536, 0.70482874, 0.7042945 , 0.02400097, 0.70732264],\n",
       "        [0.70730719, 0.7033294 , 0.69750806, 0.0322464 , 0.69993343],\n",
       "        [0.69991798, 0.70244556, 0.69962155, 0.01971978, 0.70364384]],\n",
       "\n",
       "       [[0.70032997, 0.6978056 , 0.69890985, 0.02113432, 0.70094379],\n",
       "        [0.70092832, 0.70181683, 0.69971053, 0.0241012 , 0.70268236],\n",
       "        [0.70266686, 0.70005614, 0.69952368, 0.01606106, 0.69929397],\n",
       "        ...,\n",
       "        [0.70730719, 0.7033294 , 0.69750806, 0.0322464 , 0.69993343],\n",
       "        [0.69991798, 0.70244556, 0.69962155, 0.01971978, 0.70364384],\n",
       "        [0.70362847, 0.70215566, 0.70168358, 0.02017671, 0.70377904]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dd6b140-b080-4165-bab5-3736ec95b4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15884051, 0.15350226, 0.15276687, ..., 0.70364384, 0.70377904,\n",
       "       0.70591403])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "869ef0ff-56bc-45e3-aed4-a88338222b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34401, 10, 5) (34401,) (8592, 10, 5) (8592,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf43011a-1b18-4fef-b638-d84109a5347b",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c6e3c5f-f40b-427b-bbf6-715de9fbfed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16, 25, 50),\n",
       " (16, 25, 60),\n",
       " (16, 25, 100),\n",
       " (16, 50, 50),\n",
       " (16, 50, 60),\n",
       " (16, 50, 100),\n",
       " (16, 100, 50),\n",
       " (16, 100, 60),\n",
       " (16, 100, 100),\n",
       " (32, 25, 50),\n",
       " (32, 25, 60),\n",
       " (32, 25, 100),\n",
       " (32, 50, 50),\n",
       " (32, 50, 60),\n",
       " (32, 50, 100),\n",
       " (32, 100, 50),\n",
       " (32, 100, 60),\n",
       " (32, 100, 100),\n",
       " (64, 25, 50),\n",
       " (64, 25, 60),\n",
       " (64, 25, 100),\n",
       " (64, 50, 50),\n",
       " (64, 50, 60),\n",
       " (64, 50, 100),\n",
       " (64, 100, 50),\n",
       " (64, 100, 60),\n",
       " (64, 100, 100)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams = []\n",
    "batch = [16, 32, 64]\n",
    "epoch = [25, 50, 100]\n",
    "neuron = [50, 60, 100]\n",
    "for j in batch:\n",
    "    for k in epoch:\n",
    "        for l in neuron:\n",
    "            hyperparams.append((j,k,l))\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c52fc162-d986-4cb9-9893-7619681dfc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16, 25, 50),\n",
       " (16, 25, 60),\n",
       " (16, 25, 100),\n",
       " (16, 50, 50),\n",
       " (16, 50, 60),\n",
       " (16, 50, 100),\n",
       " (16, 100, 50),\n",
       " (16, 100, 60),\n",
       " (16, 100, 100)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparam1 = hyperparams[:9]\n",
    "hyperparam2 = hyperparams[9:18]\n",
    "hyperparam3 = hyperparams[18:27]\n",
    "hyperparam1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d42226bd-8cc7-4f34-bb16-195c46f1e33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 25, 50),\n",
       " (32, 25, 60),\n",
       " (32, 25, 100),\n",
       " (32, 50, 50),\n",
       " (32, 50, 60),\n",
       " (32, 50, 100),\n",
       " (32, 100, 50),\n",
       " (32, 100, 60),\n",
       " (32, 100, 100)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparam2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed77be16-ab42-4b03-b115-2019aff75427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(64, 25, 50),\n",
       " (64, 25, 60),\n",
       " (64, 25, 100),\n",
       " (64, 50, 50),\n",
       " (64, 50, 60),\n",
       " (64, 50, 100),\n",
       " (64, 100, 50),\n",
       " (64, 100, 60),\n",
       " (64, 100, 100)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparam3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "327f83dc-5358-43d9-88df-f4b70afa1dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Evaluation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ffd8dc1-5eb8-4d7e-aba2-cab78df020ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 23:33:41.449347: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-16 23:33:41.450806: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 23:33:42.279102: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-02-16 23:33:42.712277: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-16 23:33:42.833399: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-16 23:33:44.722022: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-16 23:34:04.012541: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-16 23:34:04.042035: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2151/2151 - 24s - loss: 1.3803e-04 - val_loss: 0.0043 - 24s/epoch - 11ms/step\n",
      "Epoch 2/25\n",
      "2151/2151 - 17s - loss: 1.1673e-04 - val_loss: 0.0125 - 17s/epoch - 8ms/step\n",
      "Epoch 3/25\n",
      "2151/2151 - 17s - loss: 2.2240e-04 - val_loss: 0.0199 - 17s/epoch - 8ms/step\n",
      "Epoch 4/25\n",
      "2151/2151 - 17s - loss: 2.4869e-04 - val_loss: 0.0203 - 17s/epoch - 8ms/step\n",
      "Epoch 5/25\n",
      "2151/2151 - 17s - loss: 2.5457e-04 - val_loss: 0.0227 - 17s/epoch - 8ms/step\n",
      "Epoch 6/25\n",
      "2151/2151 - 17s - loss: 2.6156e-04 - val_loss: 0.0227 - 17s/epoch - 8ms/step\n",
      "Epoch 7/25\n",
      "2151/2151 - 17s - loss: 2.6025e-04 - val_loss: 0.0230 - 17s/epoch - 8ms/step\n",
      "Epoch 8/25\n",
      "2151/2151 - 17s - loss: 2.5477e-04 - val_loss: 0.0211 - 17s/epoch - 8ms/step\n",
      "Epoch 9/25\n",
      "2151/2151 - 17s - loss: 2.4806e-04 - val_loss: 0.0184 - 17s/epoch - 8ms/step\n",
      "Epoch 10/25\n",
      "2151/2151 - 17s - loss: 2.3675e-04 - val_loss: 0.0143 - 17s/epoch - 8ms/step\n",
      "Epoch 11/25\n",
      "2151/2151 - 17s - loss: 2.2628e-04 - val_loss: 0.0107 - 17s/epoch - 8ms/step\n",
      "Epoch 12/25\n",
      "2151/2151 - 17s - loss: 2.1847e-04 - val_loss: 0.0078 - 17s/epoch - 8ms/step\n",
      "Epoch 13/25\n",
      "2151/2151 - 17s - loss: 2.1062e-04 - val_loss: 0.0059 - 17s/epoch - 8ms/step\n",
      "Epoch 14/25\n",
      "2151/2151 - 17s - loss: 2.0046e-04 - val_loss: 0.0047 - 17s/epoch - 8ms/step\n",
      "Epoch 15/25\n",
      "2151/2151 - 17s - loss: 1.8981e-04 - val_loss: 0.0040 - 17s/epoch - 8ms/step\n",
      "Epoch 16/25\n",
      "2151/2151 - 17s - loss: 1.8040e-04 - val_loss: 0.0037 - 17s/epoch - 8ms/step\n",
      "Epoch 17/25\n",
      "2151/2151 - 17s - loss: 1.7213e-04 - val_loss: 0.0036 - 17s/epoch - 8ms/step\n",
      "Epoch 18/25\n",
      "2151/2151 - 17s - loss: 1.6584e-04 - val_loss: 0.0035 - 17s/epoch - 8ms/step\n",
      "Epoch 19/25\n",
      "2151/2151 - 18s - loss: 1.6251e-04 - val_loss: 0.0033 - 18s/epoch - 8ms/step\n",
      "Epoch 20/25\n",
      "2151/2151 - 18s - loss: 1.6042e-04 - val_loss: 0.0029 - 18s/epoch - 8ms/step\n",
      "Epoch 21/25\n",
      "2151/2151 - 19s - loss: 1.5595e-04 - val_loss: 0.0025 - 19s/epoch - 9ms/step\n",
      "Epoch 22/25\n",
      "2151/2151 - 19s - loss: 1.4918e-04 - val_loss: 0.0023 - 19s/epoch - 9ms/step\n",
      "Epoch 23/25\n",
      "2151/2151 - 17s - loss: 1.4206e-04 - val_loss: 0.0021 - 17s/epoch - 8ms/step\n",
      "Epoch 24/25\n",
      "2151/2151 - 17s - loss: 1.3522e-04 - val_loss: 0.0020 - 17s/epoch - 8ms/step\n",
      "Epoch 25/25\n",
      "2151/2151 - 18s - loss: 1.2866e-04 - val_loss: 0.0019 - 18s/epoch - 8ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 23:41:03.526917: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-16 23:41:03.627983: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-16 23:41:03.884207: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-16 23:41:20.523723: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-16 23:41:20.555041: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2151/2151 - 19s - loss: 2.4810e-04 - val_loss: 0.0068 - 19s/epoch - 9ms/step\n",
      "Epoch 2/25\n",
      "2151/2151 - 18s - loss: 1.6537e-04 - val_loss: 0.0201 - 18s/epoch - 8ms/step\n",
      "Epoch 3/25\n",
      "2151/2151 - 18s - loss: 2.7155e-04 - val_loss: 0.0243 - 18s/epoch - 8ms/step\n",
      "Epoch 4/25\n",
      "2151/2151 - 18s - loss: 2.8174e-04 - val_loss: 0.0253 - 18s/epoch - 8ms/step\n",
      "Epoch 5/25\n",
      "2151/2151 - 18s - loss: 2.8322e-04 - val_loss: 0.0242 - 18s/epoch - 8ms/step\n",
      "Epoch 6/25\n",
      "2151/2151 - 18s - loss: 2.6900e-04 - val_loss: 0.0222 - 18s/epoch - 8ms/step\n",
      "Epoch 7/25\n",
      "2151/2151 - 17s - loss: 2.4935e-04 - val_loss: 0.0203 - 17s/epoch - 8ms/step\n",
      "Epoch 8/25\n",
      "2151/2151 - 17s - loss: 2.3586e-04 - val_loss: 0.0177 - 17s/epoch - 8ms/step\n",
      "Epoch 9/25\n",
      "2151/2151 - 17s - loss: 2.2609e-04 - val_loss: 0.0153 - 17s/epoch - 8ms/step\n",
      "Epoch 10/25\n",
      "2151/2151 - 17s - loss: 2.2241e-04 - val_loss: 0.0125 - 17s/epoch - 8ms/step\n",
      "Epoch 11/25\n",
      "2151/2151 - 17s - loss: 2.1178e-04 - val_loss: 0.0098 - 17s/epoch - 8ms/step\n",
      "Epoch 12/25\n",
      "2151/2151 - 17s - loss: 1.9658e-04 - val_loss: 0.0074 - 17s/epoch - 8ms/step\n",
      "Epoch 13/25\n",
      "2151/2151 - 17s - loss: 1.8352e-04 - val_loss: 0.0059 - 17s/epoch - 8ms/step\n",
      "Epoch 14/25\n",
      "2151/2151 - 19s - loss: 1.7331e-04 - val_loss: 0.0050 - 19s/epoch - 9ms/step\n",
      "Epoch 15/25\n",
      "2151/2151 - 19s - loss: 1.6546e-04 - val_loss: 0.0044 - 19s/epoch - 9ms/step\n",
      "Epoch 16/25\n",
      "2151/2151 - 19s - loss: 1.5925e-04 - val_loss: 0.0039 - 19s/epoch - 9ms/step\n",
      "Epoch 17/25\n",
      "2151/2151 - 18s - loss: 1.5364e-04 - val_loss: 0.0036 - 18s/epoch - 8ms/step\n",
      "Epoch 18/25\n",
      "2151/2151 - 17s - loss: 1.4877e-04 - val_loss: 0.0033 - 17s/epoch - 8ms/step\n",
      "Epoch 19/25\n",
      "2151/2151 - 17s - loss: 1.4395e-04 - val_loss: 0.0031 - 17s/epoch - 8ms/step\n",
      "Epoch 20/25\n",
      "2151/2151 - 17s - loss: 1.3935e-04 - val_loss: 0.0029 - 17s/epoch - 8ms/step\n",
      "Epoch 21/25\n",
      "2151/2151 - 17s - loss: 1.3497e-04 - val_loss: 0.0028 - 17s/epoch - 8ms/step\n",
      "Epoch 22/25\n",
      "2151/2151 - 17s - loss: 1.3086e-04 - val_loss: 0.0026 - 17s/epoch - 8ms/step\n",
      "Epoch 23/25\n",
      "2151/2151 - 17s - loss: 1.2690e-04 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 24/25\n",
      "2151/2151 - 19s - loss: 1.2277e-04 - val_loss: 0.0023 - 19s/epoch - 9ms/step\n",
      "Epoch 25/25\n",
      "2151/2151 - 17s - loss: 1.1824e-04 - val_loss: 0.0022 - 17s/epoch - 8ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 23:48:24.195306: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-16 23:48:24.282158: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-16 23:48:24.474310: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-16 23:48:41.541557: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-16 23:48:41.568870: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2151/2151 - 20s - loss: 1.3667e-04 - val_loss: 0.0067 - 20s/epoch - 9ms/step\n",
      "Epoch 2/25\n",
      "2151/2151 - 19s - loss: 1.3900e-04 - val_loss: 0.0134 - 19s/epoch - 9ms/step\n",
      "Epoch 3/25\n",
      "2151/2151 - 21s - loss: 2.1967e-04 - val_loss: 0.0204 - 21s/epoch - 10ms/step\n",
      "Epoch 4/25\n",
      "2151/2151 - 18s - loss: 2.7364e-04 - val_loss: 0.0208 - 18s/epoch - 8ms/step\n",
      "Epoch 5/25\n",
      "2151/2151 - 18s - loss: 2.5123e-04 - val_loss: 0.0162 - 18s/epoch - 8ms/step\n",
      "Epoch 6/25\n",
      "2151/2151 - 18s - loss: 2.0670e-04 - val_loss: 0.0125 - 18s/epoch - 8ms/step\n",
      "Epoch 7/25\n",
      "2151/2151 - 18s - loss: 1.6899e-04 - val_loss: 0.0103 - 18s/epoch - 8ms/step\n",
      "Epoch 8/25\n",
      "2151/2151 - 18s - loss: 1.3852e-04 - val_loss: 0.0083 - 18s/epoch - 8ms/step\n",
      "Epoch 9/25\n",
      "2151/2151 - 18s - loss: 1.1228e-04 - val_loss: 0.0067 - 18s/epoch - 8ms/step\n",
      "Epoch 10/25\n",
      "2151/2151 - 18s - loss: 9.0775e-05 - val_loss: 0.0053 - 18s/epoch - 8ms/step\n",
      "Epoch 11/25\n",
      "2151/2151 - 18s - loss: 7.5875e-05 - val_loss: 0.0044 - 18s/epoch - 8ms/step\n",
      "Epoch 12/25\n",
      "2151/2151 - 18s - loss: 6.6880e-05 - val_loss: 0.0038 - 18s/epoch - 8ms/step\n",
      "Epoch 13/25\n",
      "2151/2151 - 18s - loss: 6.2936e-05 - val_loss: 0.0035 - 18s/epoch - 8ms/step\n",
      "Epoch 14/25\n",
      "2151/2151 - 18s - loss: 5.9615e-05 - val_loss: 0.0034 - 18s/epoch - 8ms/step\n",
      "Epoch 15/25\n",
      "2151/2151 - 18s - loss: 5.8633e-05 - val_loss: 0.0032 - 18s/epoch - 8ms/step\n",
      "Epoch 16/25\n",
      "2151/2151 - 18s - loss: 5.5605e-05 - val_loss: 0.0029 - 18s/epoch - 9ms/step\n",
      "Epoch 17/25\n",
      "2151/2151 - 18s - loss: 5.4356e-05 - val_loss: 0.0029 - 18s/epoch - 8ms/step\n",
      "Epoch 18/25\n",
      "2151/2151 - 18s - loss: 5.2962e-05 - val_loss: 0.0027 - 18s/epoch - 8ms/step\n",
      "Epoch 19/25\n",
      "2151/2151 - 18s - loss: 5.1915e-05 - val_loss: 0.0025 - 18s/epoch - 8ms/step\n",
      "Epoch 20/25\n",
      "2151/2151 - 18s - loss: 4.9784e-05 - val_loss: 0.0024 - 18s/epoch - 8ms/step\n",
      "Epoch 21/25\n",
      "2151/2151 - 18s - loss: 4.9819e-05 - val_loss: 0.0024 - 18s/epoch - 8ms/step\n",
      "Epoch 22/25\n",
      "2151/2151 - 18s - loss: 4.9151e-05 - val_loss: 0.0024 - 18s/epoch - 8ms/step\n",
      "Epoch 23/25\n",
      "2151/2151 - 18s - loss: 4.9611e-05 - val_loss: 0.0023 - 18s/epoch - 8ms/step\n",
      "Epoch 24/25\n",
      "2151/2151 - 18s - loss: 4.9216e-05 - val_loss: 0.0026 - 18s/epoch - 9ms/step\n",
      "Epoch 25/25\n",
      "2151/2151 - 18s - loss: 4.9579e-05 - val_loss: 0.0024 - 18s/epoch - 9ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 23:56:00.091065: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-16 23:56:00.212018: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-16 23:56:00.332661: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-16 23:56:16.360713: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-16 23:56:16.392349: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2151/2151 - 19s - loss: 2.1093e-04 - val_loss: 0.0056 - 19s/epoch - 9ms/step\n",
      "Epoch 2/50\n",
      "2151/2151 - 18s - loss: 1.4446e-04 - val_loss: 0.0152 - 18s/epoch - 8ms/step\n",
      "Epoch 3/50\n",
      "2151/2151 - 18s - loss: 2.4607e-04 - val_loss: 0.0209 - 18s/epoch - 8ms/step\n",
      "Epoch 4/50\n",
      "2151/2151 - 18s - loss: 2.6381e-04 - val_loss: 0.0229 - 18s/epoch - 8ms/step\n",
      "Epoch 5/50\n",
      "2151/2151 - 18s - loss: 2.7502e-04 - val_loss: 0.0238 - 18s/epoch - 8ms/step\n",
      "Epoch 6/50\n",
      "2151/2151 - 17s - loss: 2.7437e-04 - val_loss: 0.0233 - 17s/epoch - 8ms/step\n",
      "Epoch 7/50\n",
      "2151/2151 - 18s - loss: 2.6652e-04 - val_loss: 0.0220 - 18s/epoch - 8ms/step\n",
      "Epoch 8/50\n",
      "2151/2151 - 18s - loss: 2.5707e-04 - val_loss: 0.0202 - 18s/epoch - 8ms/step\n",
      "Epoch 9/50\n",
      "2151/2151 - 17s - loss: 2.4991e-04 - val_loss: 0.0181 - 17s/epoch - 8ms/step\n",
      "Epoch 10/50\n",
      "2151/2151 - 17s - loss: 2.4218e-04 - val_loss: 0.0147 - 17s/epoch - 8ms/step\n",
      "Epoch 11/50\n",
      "2151/2151 - 20s - loss: 2.3385e-04 - val_loss: 0.0118 - 20s/epoch - 9ms/step\n",
      "Epoch 12/50\n",
      "2151/2151 - 18s - loss: 2.2422e-04 - val_loss: 0.0092 - 18s/epoch - 8ms/step\n",
      "Epoch 13/50\n",
      "2151/2151 - 18s - loss: 2.1428e-04 - val_loss: 0.0072 - 18s/epoch - 8ms/step\n",
      "Epoch 14/50\n",
      "2151/2151 - 18s - loss: 2.0392e-04 - val_loss: 0.0057 - 18s/epoch - 8ms/step\n",
      "Epoch 15/50\n",
      "2151/2151 - 17s - loss: 1.9285e-04 - val_loss: 0.0048 - 17s/epoch - 8ms/step\n",
      "Epoch 16/50\n",
      "2151/2151 - 17s - loss: 1.8179e-04 - val_loss: 0.0042 - 17s/epoch - 8ms/step\n",
      "Epoch 17/50\n",
      "2151/2151 - 17s - loss: 1.7201e-04 - val_loss: 0.0038 - 17s/epoch - 8ms/step\n",
      "Epoch 18/50\n",
      "2151/2151 - 17s - loss: 1.6316e-04 - val_loss: 0.0036 - 17s/epoch - 8ms/step\n",
      "Epoch 19/50\n",
      "2151/2151 - 17s - loss: 1.5519e-04 - val_loss: 0.0035 - 17s/epoch - 8ms/step\n",
      "Epoch 20/50\n",
      "2151/2151 - 17s - loss: 1.4781e-04 - val_loss: 0.0035 - 17s/epoch - 8ms/step\n",
      "Epoch 21/50\n",
      "2151/2151 - 18s - loss: 1.4162e-04 - val_loss: 0.0034 - 18s/epoch - 8ms/step\n",
      "Epoch 22/50\n",
      "2151/2151 - 17s - loss: 1.3654e-04 - val_loss: 0.0033 - 17s/epoch - 8ms/step\n",
      "Epoch 23/50\n",
      "2151/2151 - 17s - loss: 1.3280e-04 - val_loss: 0.0031 - 17s/epoch - 8ms/step\n",
      "Epoch 24/50\n",
      "2151/2151 - 17s - loss: 1.2893e-04 - val_loss: 0.0029 - 17s/epoch - 8ms/step\n",
      "Epoch 25/50\n",
      "2151/2151 - 19s - loss: 1.2378e-04 - val_loss: 0.0026 - 19s/epoch - 9ms/step\n",
      "Epoch 26/50\n",
      "2151/2151 - 17s - loss: 1.1703e-04 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 27/50\n",
      "2151/2151 - 18s - loss: 1.0955e-04 - val_loss: 0.0023 - 18s/epoch - 8ms/step\n",
      "Epoch 28/50\n",
      "2151/2151 - 23s - loss: 1.0237e-04 - val_loss: 0.0022 - 23s/epoch - 11ms/step\n",
      "Epoch 29/50\n",
      "2151/2151 - 18s - loss: 9.6176e-05 - val_loss: 0.0022 - 18s/epoch - 8ms/step\n",
      "Epoch 30/50\n",
      "2151/2151 - 18s - loss: 9.1169e-05 - val_loss: 0.0022 - 18s/epoch - 8ms/step\n",
      "Epoch 31/50\n",
      "2151/2151 - 18s - loss: 8.7260e-05 - val_loss: 0.0022 - 18s/epoch - 8ms/step\n",
      "Epoch 32/50\n",
      "2151/2151 - 18s - loss: 8.4242e-05 - val_loss: 0.0022 - 18s/epoch - 8ms/step\n",
      "Epoch 33/50\n",
      "2151/2151 - 17s - loss: 8.1885e-05 - val_loss: 0.0023 - 17s/epoch - 8ms/step\n",
      "Epoch 34/50\n",
      "2151/2151 - 17s - loss: 7.9988e-05 - val_loss: 0.0023 - 17s/epoch - 8ms/step\n",
      "Epoch 35/50\n",
      "2151/2151 - 17s - loss: 7.8421e-05 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 36/50\n",
      "2151/2151 - 17s - loss: 7.7092e-05 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 37/50\n",
      "2151/2151 - 17s - loss: 7.5946e-05 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 38/50\n",
      "2151/2151 - 17s - loss: 7.4927e-05 - val_loss: 0.0025 - 17s/epoch - 8ms/step\n",
      "Epoch 39/50\n",
      "2151/2151 - 18s - loss: 7.4004e-05 - val_loss: 0.0025 - 18s/epoch - 8ms/step\n",
      "Epoch 40/50\n",
      "2151/2151 - 17s - loss: 7.3087e-05 - val_loss: 0.0025 - 17s/epoch - 8ms/step\n",
      "Epoch 41/50\n",
      "2151/2151 - 17s - loss: 7.2189e-05 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 42/50\n",
      "2151/2151 - 17s - loss: 7.1236e-05 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 43/50\n",
      "2151/2151 - 17s - loss: 7.0224e-05 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 44/50\n",
      "2151/2151 - 17s - loss: 6.9181e-05 - val_loss: 0.0023 - 17s/epoch - 8ms/step\n",
      "Epoch 45/50\n",
      "2151/2151 - 17s - loss: 6.8126e-05 - val_loss: 0.0023 - 17s/epoch - 8ms/step\n",
      "Epoch 46/50\n",
      "2151/2151 - 17s - loss: 6.7089e-05 - val_loss: 0.0022 - 17s/epoch - 8ms/step\n",
      "Epoch 47/50\n",
      "2151/2151 - 18s - loss: 6.6136e-05 - val_loss: 0.0022 - 18s/epoch - 8ms/step\n",
      "Epoch 48/50\n",
      "2151/2151 - 17s - loss: 6.5281e-05 - val_loss: 0.0021 - 17s/epoch - 8ms/step\n",
      "Epoch 49/50\n",
      "2151/2151 - 17s - loss: 6.4418e-05 - val_loss: 0.0021 - 17s/epoch - 8ms/step\n",
      "Epoch 50/50\n",
      "2151/2151 - 17s - loss: 6.3531e-05 - val_loss: 0.0021 - 17s/epoch - 8ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 00:10:44.678297: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 00:10:44.798310: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 00:10:44.890863: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 00:11:00.503208: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 00:11:00.538018: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2151/2151 - 18s - loss: 9.4669e-05 - val_loss: 0.0046 - 18s/epoch - 8ms/step\n",
      "Epoch 2/50\n",
      "2151/2151 - 17s - loss: 1.1269e-04 - val_loss: 0.0125 - 17s/epoch - 8ms/step\n",
      "Epoch 3/50\n",
      "2151/2151 - 17s - loss: 2.1404e-04 - val_loss: 0.0188 - 17s/epoch - 8ms/step\n",
      "Epoch 4/50\n",
      "2151/2151 - 17s - loss: 2.3855e-04 - val_loss: 0.0198 - 17s/epoch - 8ms/step\n",
      "Epoch 5/50\n",
      "2151/2151 - 17s - loss: 2.5132e-04 - val_loss: 0.0226 - 17s/epoch - 8ms/step\n",
      "Epoch 6/50\n",
      "2151/2151 - 17s - loss: 2.6074e-04 - val_loss: 0.0224 - 17s/epoch - 8ms/step\n",
      "Epoch 7/50\n",
      "2151/2151 - 17s - loss: 2.5357e-04 - val_loss: 0.0230 - 17s/epoch - 8ms/step\n",
      "Epoch 8/50\n",
      "2151/2151 - 17s - loss: 2.4833e-04 - val_loss: 0.0208 - 17s/epoch - 8ms/step\n",
      "Epoch 9/50\n",
      "2151/2151 - 17s - loss: 2.4138e-04 - val_loss: 0.0190 - 17s/epoch - 8ms/step\n",
      "Epoch 10/50\n",
      "2151/2151 - 17s - loss: 2.3423e-04 - val_loss: 0.0148 - 17s/epoch - 8ms/step\n",
      "Epoch 11/50\n",
      "2151/2151 - 17s - loss: 2.2785e-04 - val_loss: 0.0117 - 17s/epoch - 8ms/step\n",
      "Epoch 12/50\n",
      "2151/2151 - 17s - loss: 2.1897e-04 - val_loss: 0.0086 - 17s/epoch - 8ms/step\n",
      "Epoch 13/50\n",
      "2151/2151 - 17s - loss: 2.0830e-04 - val_loss: 0.0065 - 17s/epoch - 8ms/step\n",
      "Epoch 14/50\n",
      "2151/2151 - 17s - loss: 1.9631e-04 - val_loss: 0.0053 - 17s/epoch - 8ms/step\n",
      "Epoch 15/50\n",
      "2151/2151 - 17s - loss: 1.8491e-04 - val_loss: 0.0047 - 17s/epoch - 8ms/step\n",
      "Epoch 16/50\n",
      "2151/2151 - 17s - loss: 1.7535e-04 - val_loss: 0.0043 - 17s/epoch - 8ms/step\n",
      "Epoch 17/50\n",
      "2151/2151 - 17s - loss: 1.6665e-04 - val_loss: 0.0040 - 17s/epoch - 8ms/step\n",
      "Epoch 18/50\n",
      "2151/2151 - 17s - loss: 1.5866e-04 - val_loss: 0.0038 - 17s/epoch - 8ms/step\n",
      "Epoch 19/50\n",
      "2151/2151 - 17s - loss: 1.5110e-04 - val_loss: 0.0036 - 17s/epoch - 8ms/step\n",
      "Epoch 20/50\n",
      "2151/2151 - 17s - loss: 1.4378e-04 - val_loss: 0.0034 - 17s/epoch - 8ms/step\n",
      "Epoch 21/50\n",
      "2151/2151 - 17s - loss: 1.3685e-04 - val_loss: 0.0033 - 17s/epoch - 8ms/step\n",
      "Epoch 22/50\n",
      "2151/2151 - 17s - loss: 1.3016e-04 - val_loss: 0.0032 - 17s/epoch - 8ms/step\n",
      "Epoch 23/50\n",
      "2151/2151 - 17s - loss: 1.2395e-04 - val_loss: 0.0031 - 17s/epoch - 8ms/step\n",
      "Epoch 24/50\n",
      "2151/2151 - 17s - loss: 1.1814e-04 - val_loss: 0.0030 - 17s/epoch - 8ms/step\n",
      "Epoch 25/50\n",
      "2151/2151 - 17s - loss: 1.1289e-04 - val_loss: 0.0030 - 17s/epoch - 8ms/step\n",
      "Epoch 26/50\n",
      "2151/2151 - 17s - loss: 1.0814e-04 - val_loss: 0.0029 - 17s/epoch - 8ms/step\n",
      "Epoch 27/50\n",
      "2151/2151 - 17s - loss: 1.0389e-04 - val_loss: 0.0029 - 17s/epoch - 8ms/step\n",
      "Epoch 28/50\n",
      "2151/2151 - 17s - loss: 1.0011e-04 - val_loss: 0.0028 - 17s/epoch - 8ms/step\n",
      "Epoch 29/50\n",
      "2151/2151 - 17s - loss: 9.6759e-05 - val_loss: 0.0028 - 17s/epoch - 8ms/step\n",
      "Epoch 30/50\n",
      "2151/2151 - 17s - loss: 9.3756e-05 - val_loss: 0.0028 - 17s/epoch - 8ms/step\n",
      "Epoch 31/50\n",
      "2151/2151 - 17s - loss: 9.1051e-05 - val_loss: 0.0027 - 17s/epoch - 8ms/step\n",
      "Epoch 32/50\n",
      "2151/2151 - 17s - loss: 8.8593e-05 - val_loss: 0.0027 - 17s/epoch - 8ms/step\n",
      "Epoch 33/50\n",
      "2151/2151 - 17s - loss: 8.6348e-05 - val_loss: 0.0027 - 17s/epoch - 8ms/step\n",
      "Epoch 34/50\n",
      "2151/2151 - 17s - loss: 8.4279e-05 - val_loss: 0.0027 - 17s/epoch - 8ms/step\n",
      "Epoch 35/50\n",
      "2151/2151 - 17s - loss: 8.2359e-05 - val_loss: 0.0026 - 17s/epoch - 8ms/step\n",
      "Epoch 36/50\n",
      "2151/2151 - 17s - loss: 8.0565e-05 - val_loss: 0.0026 - 17s/epoch - 8ms/step\n",
      "Epoch 37/50\n",
      "2151/2151 - 17s - loss: 7.8892e-05 - val_loss: 0.0026 - 17s/epoch - 8ms/step\n",
      "Epoch 38/50\n",
      "2151/2151 - 17s - loss: 7.7314e-05 - val_loss: 0.0026 - 17s/epoch - 8ms/step\n",
      "Epoch 39/50\n",
      "2151/2151 - 17s - loss: 7.5832e-05 - val_loss: 0.0026 - 17s/epoch - 8ms/step\n",
      "Epoch 40/50\n",
      "2151/2151 - 17s - loss: 7.4446e-05 - val_loss: 0.0025 - 17s/epoch - 8ms/step\n",
      "Epoch 41/50\n",
      "2151/2151 - 17s - loss: 7.3156e-05 - val_loss: 0.0025 - 17s/epoch - 8ms/step\n",
      "Epoch 42/50\n",
      "2151/2151 - 17s - loss: 7.1961e-05 - val_loss: 0.0025 - 17s/epoch - 8ms/step\n",
      "Epoch 43/50\n",
      "2151/2151 - 17s - loss: 7.0853e-05 - val_loss: 0.0025 - 17s/epoch - 8ms/step\n",
      "Epoch 44/50\n",
      "2151/2151 - 17s - loss: 6.9818e-05 - val_loss: 0.0025 - 17s/epoch - 8ms/step\n",
      "Epoch 45/50\n",
      "2151/2151 - 17s - loss: 6.8826e-05 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 46/50\n",
      "2151/2151 - 17s - loss: 6.7853e-05 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 47/50\n",
      "2151/2151 - 17s - loss: 6.6873e-05 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 48/50\n",
      "2151/2151 - 18s - loss: 6.5870e-05 - val_loss: 0.0023 - 18s/epoch - 8ms/step\n",
      "Epoch 49/50\n",
      "2151/2151 - 17s - loss: 6.4834e-05 - val_loss: 0.0023 - 17s/epoch - 8ms/step\n",
      "Epoch 50/50\n",
      "2151/2151 - 17s - loss: 6.3770e-05 - val_loss: 0.0022 - 17s/epoch - 8ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 00:25:08.207346: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 00:25:08.311051: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 00:25:08.407217: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 00:25:24.596142: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 00:25:24.623343: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2151/2151 - 20s - loss: 1.4241e-04 - val_loss: 0.0053 - 20s/epoch - 9ms/step\n",
      "Epoch 2/50\n",
      "2151/2151 - 18s - loss: 1.3016e-04 - val_loss: 0.0134 - 18s/epoch - 8ms/step\n",
      "Epoch 3/50\n",
      "2151/2151 - 18s - loss: 2.3046e-04 - val_loss: 0.0225 - 18s/epoch - 8ms/step\n",
      "Epoch 4/50\n",
      "2151/2151 - 18s - loss: 2.8624e-04 - val_loss: 0.0233 - 18s/epoch - 8ms/step\n",
      "Epoch 5/50\n",
      "2151/2151 - 18s - loss: 2.9098e-04 - val_loss: 0.0244 - 18s/epoch - 8ms/step\n",
      "Epoch 6/50\n",
      "2151/2151 - 18s - loss: 2.8408e-04 - val_loss: 0.0231 - 18s/epoch - 8ms/step\n",
      "Epoch 7/50\n",
      "2151/2151 - 18s - loss: 2.5996e-04 - val_loss: 0.0208 - 18s/epoch - 8ms/step\n",
      "Epoch 8/50\n",
      "2151/2151 - 18s - loss: 2.3718e-04 - val_loss: 0.0192 - 18s/epoch - 8ms/step\n",
      "Epoch 9/50\n",
      "2151/2151 - 18s - loss: 2.2422e-04 - val_loss: 0.0176 - 18s/epoch - 8ms/step\n",
      "Epoch 10/50\n",
      "2151/2151 - 18s - loss: 2.2127e-04 - val_loss: 0.0157 - 18s/epoch - 8ms/step\n",
      "Epoch 11/50\n",
      "2151/2151 - 18s - loss: 2.2563e-04 - val_loss: 0.0135 - 18s/epoch - 8ms/step\n",
      "Epoch 12/50\n",
      "2151/2151 - 18s - loss: 2.2415e-04 - val_loss: 0.0106 - 18s/epoch - 8ms/step\n",
      "Epoch 13/50\n",
      "2151/2151 - 18s - loss: 2.1531e-04 - val_loss: 0.0080 - 18s/epoch - 8ms/step\n",
      "Epoch 14/50\n",
      "2151/2151 - 18s - loss: 2.0404e-04 - val_loss: 0.0065 - 18s/epoch - 8ms/step\n",
      "Epoch 15/50\n",
      "2151/2151 - 18s - loss: 1.9335e-04 - val_loss: 0.0055 - 18s/epoch - 8ms/step\n",
      "Epoch 16/50\n",
      "2151/2151 - 18s - loss: 1.8228e-04 - val_loss: 0.0049 - 18s/epoch - 8ms/step\n",
      "Epoch 17/50\n",
      "2151/2151 - 18s - loss: 1.7167e-04 - val_loss: 0.0045 - 18s/epoch - 8ms/step\n",
      "Epoch 18/50\n",
      "2151/2151 - 18s - loss: 1.6184e-04 - val_loss: 0.0043 - 18s/epoch - 8ms/step\n",
      "Epoch 19/50\n",
      "2151/2151 - 18s - loss: 1.5269e-04 - val_loss: 0.0041 - 18s/epoch - 8ms/step\n",
      "Epoch 20/50\n",
      "2151/2151 - 18s - loss: 1.4465e-04 - val_loss: 0.0040 - 18s/epoch - 8ms/step\n",
      "Epoch 21/50\n",
      "2151/2151 - 18s - loss: 1.3762e-04 - val_loss: 0.0038 - 18s/epoch - 8ms/step\n",
      "Epoch 22/50\n",
      "2151/2151 - 18s - loss: 1.3155e-04 - val_loss: 0.0037 - 18s/epoch - 8ms/step\n",
      "Epoch 23/50\n",
      "2151/2151 - 18s - loss: 1.2646e-04 - val_loss: 0.0035 - 18s/epoch - 8ms/step\n",
      "Epoch 24/50\n",
      "2151/2151 - 18s - loss: 1.2205e-04 - val_loss: 0.0033 - 18s/epoch - 8ms/step\n",
      "Epoch 25/50\n",
      "2151/2151 - 18s - loss: 1.1773e-04 - val_loss: 0.0031 - 18s/epoch - 8ms/step\n",
      "Epoch 26/50\n",
      "2151/2151 - 18s - loss: 1.1300e-04 - val_loss: 0.0029 - 18s/epoch - 8ms/step\n",
      "Epoch 27/50\n",
      "2151/2151 - 18s - loss: 1.0807e-04 - val_loss: 0.0028 - 18s/epoch - 8ms/step\n",
      "Epoch 28/50\n",
      "2151/2151 - 18s - loss: 1.0358e-04 - val_loss: 0.0027 - 18s/epoch - 8ms/step\n",
      "Epoch 29/50\n",
      "2151/2151 - 18s - loss: 1.0001e-04 - val_loss: 0.0026 - 18s/epoch - 8ms/step\n",
      "Epoch 30/50\n",
      "2151/2151 - 18s - loss: 9.7313e-05 - val_loss: 0.0026 - 18s/epoch - 8ms/step\n",
      "Epoch 31/50\n",
      "2151/2151 - 18s - loss: 9.5217e-05 - val_loss: 0.0025 - 18s/epoch - 9ms/step\n",
      "Epoch 32/50\n",
      "2151/2151 - 18s - loss: 9.3401e-05 - val_loss: 0.0025 - 18s/epoch - 9ms/step\n",
      "Epoch 33/50\n",
      "2151/2151 - 18s - loss: 9.1674e-05 - val_loss: 0.0024 - 18s/epoch - 8ms/step\n",
      "Epoch 34/50\n",
      "2151/2151 - 18s - loss: 8.9947e-05 - val_loss: 0.0024 - 18s/epoch - 8ms/step\n",
      "Epoch 35/50\n",
      "2151/2151 - 18s - loss: 8.8278e-05 - val_loss: 0.0023 - 18s/epoch - 8ms/step\n",
      "Epoch 36/50\n",
      "2151/2151 - 18s - loss: 8.6632e-05 - val_loss: 0.0022 - 18s/epoch - 8ms/step\n",
      "Epoch 37/50\n",
      "2151/2151 - 18s - loss: 8.4760e-05 - val_loss: 0.0022 - 18s/epoch - 8ms/step\n",
      "Epoch 38/50\n",
      "2151/2151 - 18s - loss: 8.2777e-05 - val_loss: 0.0021 - 18s/epoch - 8ms/step\n",
      "Epoch 39/50\n",
      "2151/2151 - 18s - loss: 8.0726e-05 - val_loss: 0.0021 - 18s/epoch - 8ms/step\n",
      "Epoch 40/50\n",
      "2151/2151 - 18s - loss: 7.8546e-05 - val_loss: 0.0020 - 18s/epoch - 8ms/step\n",
      "Epoch 41/50\n",
      "2151/2151 - 18s - loss: 7.6321e-05 - val_loss: 0.0020 - 18s/epoch - 8ms/step\n",
      "Epoch 42/50\n",
      "2151/2151 - 18s - loss: 7.4128e-05 - val_loss: 0.0019 - 18s/epoch - 8ms/step\n",
      "Epoch 43/50\n",
      "2151/2151 - 18s - loss: 7.2051e-05 - val_loss: 0.0019 - 18s/epoch - 8ms/step\n",
      "Epoch 44/50\n",
      "2151/2151 - 18s - loss: 7.0137e-05 - val_loss: 0.0019 - 18s/epoch - 8ms/step\n",
      "Epoch 45/50\n",
      "2151/2151 - 18s - loss: 6.8386e-05 - val_loss: 0.0018 - 18s/epoch - 8ms/step\n",
      "Epoch 46/50\n",
      "2151/2151 - 18s - loss: 6.6779e-05 - val_loss: 0.0018 - 18s/epoch - 8ms/step\n",
      "Epoch 47/50\n",
      "2151/2151 - 18s - loss: 6.5306e-05 - val_loss: 0.0018 - 18s/epoch - 8ms/step\n",
      "Epoch 48/50\n",
      "2151/2151 - 18s - loss: 6.3944e-05 - val_loss: 0.0018 - 18s/epoch - 8ms/step\n",
      "Epoch 49/50\n",
      "2151/2151 - 18s - loss: 6.2674e-05 - val_loss: 0.0018 - 18s/epoch - 8ms/step\n",
      "Epoch 50/50\n",
      "2151/2151 - 18s - loss: 6.1478e-05 - val_loss: 0.0018 - 18s/epoch - 8ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 00:40:03.336942: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 00:40:03.419517: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 00:40:03.505685: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 00:40:19.292358: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 00:40:19.324425: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2151/2151 - 18s - loss: 2.2492e-04 - val_loss: 0.0047 - 18s/epoch - 8ms/step\n",
      "Epoch 2/100\n",
      "2151/2151 - 17s - loss: 1.2622e-04 - val_loss: 0.0120 - 17s/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "2151/2151 - 17s - loss: 2.3392e-04 - val_loss: 0.0217 - 17s/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "2151/2151 - 17s - loss: 2.7727e-04 - val_loss: 0.0264 - 17s/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "2151/2151 - 17s - loss: 3.0996e-04 - val_loss: 0.0303 - 17s/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "2151/2151 - 17s - loss: 3.3246e-04 - val_loss: 0.0303 - 17s/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "2151/2151 - 17s - loss: 3.2742e-04 - val_loss: 0.0250 - 17s/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "2151/2151 - 17s - loss: 2.9765e-04 - val_loss: 0.0186 - 17s/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "2151/2151 - 17s - loss: 2.6393e-04 - val_loss: 0.0136 - 17s/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "2151/2151 - 17s - loss: 2.4166e-04 - val_loss: 0.0098 - 17s/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "2151/2151 - 17s - loss: 2.2726e-04 - val_loss: 0.0073 - 17s/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "2151/2151 - 17s - loss: 2.1459e-04 - val_loss: 0.0056 - 17s/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "2151/2151 - 17s - loss: 2.0480e-04 - val_loss: 0.0046 - 17s/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "2151/2151 - 17s - loss: 1.9708e-04 - val_loss: 0.0040 - 17s/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "2151/2151 - 17s - loss: 1.9251e-04 - val_loss: 0.0033 - 17s/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "2151/2151 - 17s - loss: 1.8738e-04 - val_loss: 0.0030 - 17s/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "2151/2151 - 17s - loss: 1.7931e-04 - val_loss: 0.0025 - 17s/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "2151/2151 - 17s - loss: 1.7171e-04 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "2151/2151 - 17s - loss: 1.6328e-04 - val_loss: 0.0022 - 17s/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "2151/2151 - 17s - loss: 1.5615e-04 - val_loss: 0.0021 - 17s/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "2151/2151 - 17s - loss: 1.4923e-04 - val_loss: 0.0020 - 17s/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "2151/2151 - 17s - loss: 1.4251e-04 - val_loss: 0.0020 - 17s/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "2151/2151 - 17s - loss: 1.3567e-04 - val_loss: 0.0019 - 17s/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "2151/2151 - 17s - loss: 1.2864e-04 - val_loss: 0.0019 - 17s/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "2151/2151 - 17s - loss: 1.2162e-04 - val_loss: 0.0019 - 17s/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "2151/2151 - 17s - loss: 1.1470e-04 - val_loss: 0.0019 - 17s/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "2151/2151 - 17s - loss: 1.0812e-04 - val_loss: 0.0019 - 17s/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "2151/2151 - 17s - loss: 1.0209e-04 - val_loss: 0.0019 - 17s/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "2151/2151 - 17s - loss: 9.6795e-05 - val_loss: 0.0020 - 17s/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "2151/2151 - 17s - loss: 9.2309e-05 - val_loss: 0.0020 - 17s/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "2151/2151 - 17s - loss: 8.8612e-05 - val_loss: 0.0020 - 17s/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "2151/2151 - 17s - loss: 8.5594e-05 - val_loss: 0.0021 - 17s/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "2151/2151 - 17s - loss: 8.3114e-05 - val_loss: 0.0022 - 17s/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "2151/2151 - 17s - loss: 8.1044e-05 - val_loss: 0.0022 - 17s/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "2151/2151 - 17s - loss: 7.9292e-05 - val_loss: 0.0023 - 17s/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "2151/2151 - 17s - loss: 7.7795e-05 - val_loss: 0.0023 - 17s/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "2151/2151 - 17s - loss: 7.6508e-05 - val_loss: 0.0023 - 17s/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "2151/2151 - 17s - loss: 7.5392e-05 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "2151/2151 - 17s - loss: 7.4416e-05 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "2151/2151 - 17s - loss: 7.3546e-05 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "2151/2151 - 17s - loss: 7.2751e-05 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "2151/2151 - 17s - loss: 7.2004e-05 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "2151/2151 - 17s - loss: 7.1277e-05 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "2151/2151 - 17s - loss: 7.0545e-05 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "2151/2151 - 17s - loss: 6.9781e-05 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "2151/2151 - 17s - loss: 6.8984e-05 - val_loss: 0.0023 - 17s/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "2151/2151 - 18s - loss: 6.8250e-05 - val_loss: 0.0023 - 18s/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "2151/2151 - 17s - loss: 6.7457e-05 - val_loss: 0.0023 - 17s/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "2151/2151 - 17s - loss: 6.6713e-05 - val_loss: 0.0022 - 17s/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "2151/2151 - 17s - loss: 6.5971e-05 - val_loss: 0.0022 - 17s/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "2151/2151 - 17s - loss: 6.5259e-05 - val_loss: 0.0022 - 17s/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "2151/2151 - 17s - loss: 6.4577e-05 - val_loss: 0.0021 - 17s/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "2151/2151 - 17s - loss: 6.3926e-05 - val_loss: 0.0021 - 17s/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "2151/2151 - 17s - loss: 6.3302e-05 - val_loss: 0.0021 - 17s/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "2151/2151 - 17s - loss: 6.2701e-05 - val_loss: 0.0020 - 17s/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "2151/2151 - 17s - loss: 6.2121e-05 - val_loss: 0.0020 - 17s/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "2151/2151 - 17s - loss: 6.1562e-05 - val_loss: 0.0020 - 17s/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "2151/2151 - 17s - loss: 6.1028e-05 - val_loss: 0.0019 - 17s/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "2151/2151 - 17s - loss: 6.0517e-05 - val_loss: 0.0019 - 17s/epoch - 8ms/step\n",
      "Epoch 60/100\n",
      "2151/2151 - 17s - loss: 6.0033e-05 - val_loss: 0.0019 - 17s/epoch - 8ms/step\n",
      "Epoch 61/100\n",
      "2151/2151 - 17s - loss: 5.9574e-05 - val_loss: 0.0019 - 17s/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "2151/2151 - 17s - loss: 5.9134e-05 - val_loss: 0.0018 - 17s/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "2151/2151 - 17s - loss: 5.8673e-05 - val_loss: 0.0018 - 17s/epoch - 8ms/step\n",
      "Epoch 64/100\n",
      "2151/2151 - 17s - loss: 5.8145e-05 - val_loss: 0.0018 - 17s/epoch - 8ms/step\n",
      "Epoch 65/100\n",
      "2151/2151 - 17s - loss: 5.7546e-05 - val_loss: 0.0017 - 17s/epoch - 8ms/step\n",
      "Epoch 66/100\n",
      "2151/2151 - 17s - loss: 5.6919e-05 - val_loss: 0.0017 - 17s/epoch - 8ms/step\n",
      "Epoch 67/100\n",
      "2151/2151 - 17s - loss: 5.6280e-05 - val_loss: 0.0017 - 17s/epoch - 8ms/step\n",
      "Epoch 68/100\n",
      "2151/2151 - 17s - loss: 5.5644e-05 - val_loss: 0.0016 - 17s/epoch - 8ms/step\n",
      "Epoch 69/100\n",
      "2151/2151 - 17s - loss: 5.5036e-05 - val_loss: 0.0016 - 17s/epoch - 8ms/step\n",
      "Epoch 70/100\n",
      "2151/2151 - 17s - loss: 5.4500e-05 - val_loss: 0.0015 - 17s/epoch - 8ms/step\n",
      "Epoch 71/100\n",
      "2151/2151 - 17s - loss: 5.4049e-05 - val_loss: 0.0015 - 17s/epoch - 8ms/step\n",
      "Epoch 72/100\n",
      "2151/2151 - 17s - loss: 5.3614e-05 - val_loss: 0.0015 - 17s/epoch - 8ms/step\n",
      "Epoch 73/100\n",
      "2151/2151 - 17s - loss: 5.3333e-05 - val_loss: 0.0015 - 17s/epoch - 8ms/step\n",
      "Epoch 74/100\n",
      "2151/2151 - 17s - loss: 5.3352e-05 - val_loss: 0.0015 - 17s/epoch - 8ms/step\n",
      "Epoch 75/100\n",
      "2151/2151 - 17s - loss: 5.3218e-05 - val_loss: 0.0014 - 17s/epoch - 8ms/step\n",
      "Epoch 76/100\n",
      "2151/2151 - 17s - loss: 5.2782e-05 - val_loss: 0.0014 - 17s/epoch - 8ms/step\n",
      "Epoch 77/100\n",
      "2151/2151 - 17s - loss: 5.2239e-05 - val_loss: 0.0014 - 17s/epoch - 8ms/step\n",
      "Epoch 78/100\n",
      "2151/2151 - 17s - loss: 5.1701e-05 - val_loss: 0.0013 - 17s/epoch - 8ms/step\n",
      "Epoch 79/100\n",
      "2151/2151 - 17s - loss: 5.1180e-05 - val_loss: 0.0013 - 17s/epoch - 8ms/step\n",
      "Epoch 80/100\n",
      "2151/2151 - 17s - loss: 5.0665e-05 - val_loss: 0.0013 - 17s/epoch - 8ms/step\n",
      "Epoch 81/100\n",
      "2151/2151 - 17s - loss: 5.0140e-05 - val_loss: 0.0013 - 17s/epoch - 8ms/step\n",
      "Epoch 82/100\n",
      "2151/2151 - 17s - loss: 4.9576e-05 - val_loss: 0.0013 - 17s/epoch - 8ms/step\n",
      "Epoch 83/100\n",
      "2151/2151 - 17s - loss: 4.9029e-05 - val_loss: 0.0013 - 17s/epoch - 8ms/step\n",
      "Epoch 84/100\n",
      "2151/2151 - 18s - loss: 4.8521e-05 - val_loss: 0.0013 - 18s/epoch - 8ms/step\n",
      "Epoch 85/100\n",
      "2151/2151 - 17s - loss: 4.8042e-05 - val_loss: 0.0012 - 17s/epoch - 8ms/step\n",
      "Epoch 86/100\n",
      "2151/2151 - 17s - loss: 4.7603e-05 - val_loss: 0.0012 - 17s/epoch - 8ms/step\n",
      "Epoch 87/100\n",
      "2151/2151 - 17s - loss: 4.7193e-05 - val_loss: 0.0012 - 17s/epoch - 8ms/step\n",
      "Epoch 88/100\n",
      "2151/2151 - 17s - loss: 4.6816e-05 - val_loss: 0.0012 - 17s/epoch - 8ms/step\n",
      "Epoch 89/100\n",
      "2151/2151 - 17s - loss: 4.6464e-05 - val_loss: 0.0012 - 17s/epoch - 8ms/step\n",
      "Epoch 90/100\n",
      "2151/2151 - 17s - loss: 4.6135e-05 - val_loss: 0.0012 - 17s/epoch - 8ms/step\n",
      "Epoch 91/100\n",
      "2151/2151 - 17s - loss: 4.5822e-05 - val_loss: 0.0012 - 17s/epoch - 8ms/step\n",
      "Epoch 92/100\n",
      "2151/2151 - 17s - loss: 4.5523e-05 - val_loss: 0.0012 - 17s/epoch - 8ms/step\n",
      "Epoch 93/100\n",
      "2151/2151 - 17s - loss: 4.5233e-05 - val_loss: 0.0012 - 17s/epoch - 8ms/step\n",
      "Epoch 94/100\n",
      "2151/2151 - 17s - loss: 4.4948e-05 - val_loss: 0.0012 - 17s/epoch - 8ms/step\n",
      "Epoch 95/100\n",
      "2151/2151 - 17s - loss: 4.4667e-05 - val_loss: 0.0012 - 17s/epoch - 8ms/step\n",
      "Epoch 96/100\n",
      "2151/2151 - 17s - loss: 4.4389e-05 - val_loss: 0.0012 - 17s/epoch - 8ms/step\n",
      "Epoch 97/100\n",
      "2151/2151 - 17s - loss: 4.4114e-05 - val_loss: 0.0012 - 17s/epoch - 8ms/step\n",
      "Epoch 98/100\n",
      "2151/2151 - 17s - loss: 4.3841e-05 - val_loss: 0.0012 - 17s/epoch - 8ms/step\n",
      "Epoch 99/100\n",
      "2151/2151 - 17s - loss: 4.3571e-05 - val_loss: 0.0012 - 17s/epoch - 8ms/step\n",
      "Epoch 100/100\n",
      "2151/2151 - 17s - loss: 4.3304e-05 - val_loss: 0.0012 - 17s/epoch - 8ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 01:08:39.080474: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 01:08:39.166990: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 01:08:39.261099: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 01:08:54.998781: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 01:08:55.025672: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2151/2151 - 18s - loss: 1.2990e-04 - val_loss: 0.0041 - 18s/epoch - 8ms/step\n",
      "Epoch 2/100\n",
      "2151/2151 - 17s - loss: 1.1349e-04 - val_loss: 0.0097 - 17s/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "2151/2151 - 17s - loss: 1.8369e-04 - val_loss: 0.0181 - 17s/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "2151/2151 - 17s - loss: 2.2463e-04 - val_loss: 0.0163 - 17s/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "2151/2151 - 18s - loss: 2.0785e-04 - val_loss: 0.0146 - 18s/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "2151/2151 - 17s - loss: 1.9762e-04 - val_loss: 0.0134 - 17s/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "2151/2151 - 18s - loss: 1.7565e-04 - val_loss: 0.0113 - 18s/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "2151/2151 - 17s - loss: 1.5921e-04 - val_loss: 0.0102 - 17s/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "2151/2151 - 17s - loss: 1.3718e-04 - val_loss: 0.0083 - 17s/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "2151/2151 - 17s - loss: 1.2274e-04 - val_loss: 0.0075 - 17s/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "2151/2151 - 17s - loss: 1.0514e-04 - val_loss: 0.0062 - 17s/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "2151/2151 - 17s - loss: 9.4363e-05 - val_loss: 0.0054 - 17s/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "2151/2151 - 17s - loss: 8.6131e-05 - val_loss: 0.0049 - 17s/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "2151/2151 - 17s - loss: 8.0128e-05 - val_loss: 0.0045 - 17s/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "2151/2151 - 17s - loss: 7.6667e-05 - val_loss: 0.0041 - 17s/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "2151/2151 - 17s - loss: 7.4637e-05 - val_loss: 0.0041 - 17s/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "2151/2151 - 17s - loss: 7.4133e-05 - val_loss: 0.0040 - 17s/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "2151/2151 - 17s - loss: 7.4197e-05 - val_loss: 0.0040 - 17s/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "2151/2151 - 17s - loss: 7.4593e-05 - val_loss: 0.0041 - 17s/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "2151/2151 - 17s - loss: 7.5554e-05 - val_loss: 0.0041 - 17s/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "2151/2151 - 17s - loss: 7.5664e-05 - val_loss: 0.0040 - 17s/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "2151/2151 - 17s - loss: 7.6131e-05 - val_loss: 0.0039 - 17s/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "2151/2151 - 17s - loss: 7.6263e-05 - val_loss: 0.0038 - 17s/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "2151/2151 - 17s - loss: 7.7281e-05 - val_loss: 0.0038 - 17s/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "2151/2151 - 17s - loss: 7.8730e-05 - val_loss: 0.0038 - 17s/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "2151/2151 - 17s - loss: 8.1393e-05 - val_loss: 0.0039 - 17s/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "2151/2151 - 17s - loss: 8.3452e-05 - val_loss: 0.0039 - 17s/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "2151/2151 - 17s - loss: 9.0231e-05 - val_loss: 0.0045 - 17s/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "2151/2151 - 17s - loss: 9.5391e-05 - val_loss: 0.0044 - 17s/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "2151/2151 - 17s - loss: 9.9982e-05 - val_loss: 0.0045 - 17s/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "2151/2151 - 17s - loss: 1.0230e-04 - val_loss: 0.0042 - 17s/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "2151/2151 - 17s - loss: 1.0301e-04 - val_loss: 0.0040 - 17s/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "2151/2151 - 18s - loss: 1.0172e-04 - val_loss: 0.0037 - 18s/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "2151/2151 - 17s - loss: 1.0002e-04 - val_loss: 0.0036 - 17s/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "2151/2151 - 17s - loss: 9.7535e-05 - val_loss: 0.0035 - 17s/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "2151/2151 - 17s - loss: 9.5283e-05 - val_loss: 0.0033 - 17s/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "2151/2151 - 17s - loss: 9.2905e-05 - val_loss: 0.0033 - 17s/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "2151/2151 - 17s - loss: 9.0587e-05 - val_loss: 0.0032 - 17s/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "2151/2151 - 17s - loss: 8.8152e-05 - val_loss: 0.0031 - 17s/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "2151/2151 - 17s - loss: 8.6345e-05 - val_loss: 0.0031 - 17s/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "2151/2151 - 17s - loss: 8.4149e-05 - val_loss: 0.0030 - 17s/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "2151/2151 - 17s - loss: 8.2281e-05 - val_loss: 0.0029 - 17s/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "2151/2151 - 17s - loss: 8.0151e-05 - val_loss: 0.0029 - 17s/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "2151/2151 - 17s - loss: 7.7996e-05 - val_loss: 0.0027 - 17s/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "2151/2151 - 17s - loss: 7.6470e-05 - val_loss: 0.0028 - 17s/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "2151/2151 - 17s - loss: 7.4912e-05 - val_loss: 0.0027 - 17s/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "2151/2151 - 17s - loss: 7.3519e-05 - val_loss: 0.0027 - 17s/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "2151/2151 - 17s - loss: 7.1901e-05 - val_loss: 0.0026 - 17s/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "2151/2151 - 17s - loss: 7.1764e-05 - val_loss: 0.0026 - 17s/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "2151/2151 - 17s - loss: 7.0425e-05 - val_loss: 0.0026 - 17s/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "2151/2151 - 17s - loss: 6.9678e-05 - val_loss: 0.0025 - 17s/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "2151/2151 - 17s - loss: 6.9509e-05 - val_loss: 0.0026 - 17s/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "2151/2151 - 17s - loss: 6.8266e-05 - val_loss: 0.0023 - 17s/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "2151/2151 - 17s - loss: 6.8617e-05 - val_loss: 0.0026 - 17s/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "2151/2151 - 17s - loss: 6.7375e-05 - val_loss: 0.0023 - 17s/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "2151/2151 - 17s - loss: 6.7808e-05 - val_loss: 0.0026 - 17s/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "2151/2151 - 17s - loss: 6.6926e-05 - val_loss: 0.0023 - 17s/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "2151/2151 - 17s - loss: 6.4586e-05 - val_loss: 0.0022 - 17s/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "2151/2151 - 17s - loss: 6.5393e-05 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 60/100\n",
      "2151/2151 - 17s - loss: 6.4356e-05 - val_loss: 0.0022 - 17s/epoch - 8ms/step\n",
      "Epoch 61/100\n",
      "2151/2151 - 17s - loss: 6.3789e-05 - val_loss: 0.0023 - 17s/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "2151/2151 - 17s - loss: 6.2787e-05 - val_loss: 0.0020 - 17s/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "2151/2151 - 17s - loss: 6.1968e-05 - val_loss: 0.0025 - 17s/epoch - 8ms/step\n",
      "Epoch 64/100\n",
      "2151/2151 - 17s - loss: 6.3442e-05 - val_loss: 0.0024 - 17s/epoch - 8ms/step\n",
      "Epoch 65/100\n",
      "2151/2151 - 17s - loss: 6.2418e-05 - val_loss: 0.0023 - 17s/epoch - 8ms/step\n",
      "Epoch 66/100\n",
      "2151/2151 - 17s - loss: 6.0386e-05 - val_loss: 0.0022 - 17s/epoch - 8ms/step\n",
      "Epoch 67/100\n",
      "2151/2151 - 17s - loss: 6.0317e-05 - val_loss: 0.0022 - 17s/epoch - 8ms/step\n",
      "Epoch 68/100\n",
      "2151/2151 - 17s - loss: 5.9274e-05 - val_loss: 0.0022 - 17s/epoch - 8ms/step\n",
      "Epoch 69/100\n",
      "2151/2151 - 17s - loss: 5.9245e-05 - val_loss: 0.0021 - 17s/epoch - 8ms/step\n",
      "Epoch 70/100\n",
      "2151/2151 - 17s - loss: 5.8752e-05 - val_loss: 0.0021 - 17s/epoch - 8ms/step\n",
      "Epoch 71/100\n",
      "2151/2151 - 17s - loss: 5.8409e-05 - val_loss: 0.0021 - 17s/epoch - 8ms/step\n",
      "Epoch 72/100\n",
      "2151/2151 - 17s - loss: 5.7998e-05 - val_loss: 0.0020 - 17s/epoch - 8ms/step\n",
      "Epoch 73/100\n",
      "2151/2151 - 17s - loss: 5.7585e-05 - val_loss: 0.0020 - 17s/epoch - 8ms/step\n",
      "Epoch 74/100\n",
      "2151/2151 - 17s - loss: 5.7177e-05 - val_loss: 0.0020 - 17s/epoch - 8ms/step\n",
      "Epoch 75/100\n",
      "2151/2151 - 17s - loss: 5.6971e-05 - val_loss: 0.0020 - 17s/epoch - 8ms/step\n",
      "Epoch 76/100\n",
      "2151/2151 - 17s - loss: 5.6713e-05 - val_loss: 0.0020 - 17s/epoch - 8ms/step\n",
      "Epoch 77/100\n",
      "2151/2151 - 17s - loss: 5.6387e-05 - val_loss: 0.0019 - 17s/epoch - 8ms/step\n",
      "Epoch 78/100\n",
      "2151/2151 - 17s - loss: 5.5980e-05 - val_loss: 0.0019 - 17s/epoch - 8ms/step\n",
      "Epoch 79/100\n",
      "2151/2151 - 17s - loss: 5.5559e-05 - val_loss: 0.0019 - 17s/epoch - 8ms/step\n",
      "Epoch 80/100\n",
      "2151/2151 - 17s - loss: 5.5121e-05 - val_loss: 0.0018 - 17s/epoch - 8ms/step\n",
      "Epoch 81/100\n",
      "2151/2151 - 17s - loss: 5.4501e-05 - val_loss: 0.0018 - 17s/epoch - 8ms/step\n",
      "Epoch 82/100\n",
      "2151/2151 - 18s - loss: 5.3931e-05 - val_loss: 0.0018 - 18s/epoch - 8ms/step\n",
      "Epoch 83/100\n",
      "2151/2151 - 17s - loss: 5.3364e-05 - val_loss: 0.0018 - 17s/epoch - 8ms/step\n",
      "Epoch 84/100\n",
      "2151/2151 - 17s - loss: 5.2801e-05 - val_loss: 0.0017 - 17s/epoch - 8ms/step\n",
      "Epoch 85/100\n",
      "2151/2151 - 17s - loss: 5.2228e-05 - val_loss: 0.0017 - 17s/epoch - 8ms/step\n",
      "Epoch 86/100\n",
      "2151/2151 - 17s - loss: 5.1665e-05 - val_loss: 0.0017 - 17s/epoch - 8ms/step\n",
      "Epoch 87/100\n",
      "2151/2151 - 17s - loss: 5.1117e-05 - val_loss: 0.0017 - 17s/epoch - 8ms/step\n",
      "Epoch 88/100\n",
      "2151/2151 - 17s - loss: 5.0599e-05 - val_loss: 0.0017 - 17s/epoch - 8ms/step\n",
      "Epoch 89/100\n",
      "2151/2151 - 17s - loss: 5.0110e-05 - val_loss: 0.0017 - 17s/epoch - 8ms/step\n",
      "Epoch 90/100\n",
      "2151/2151 - 17s - loss: 4.9654e-05 - val_loss: 0.0017 - 17s/epoch - 8ms/step\n",
      "Epoch 91/100\n",
      "2151/2151 - 17s - loss: 4.9210e-05 - val_loss: 0.0016 - 17s/epoch - 8ms/step\n",
      "Epoch 92/100\n",
      "2151/2151 - 17s - loss: 4.8786e-05 - val_loss: 0.0016 - 17s/epoch - 8ms/step\n",
      "Epoch 93/100\n",
      "2151/2151 - 17s - loss: 4.8335e-05 - val_loss: 0.0016 - 17s/epoch - 8ms/step\n",
      "Epoch 94/100\n",
      "2151/2151 - 17s - loss: 4.7899e-05 - val_loss: 0.0016 - 17s/epoch - 8ms/step\n",
      "Epoch 95/100\n",
      "2151/2151 - 17s - loss: 4.7404e-05 - val_loss: 0.0016 - 17s/epoch - 8ms/step\n",
      "Epoch 96/100\n",
      "2151/2151 - 17s - loss: 4.6965e-05 - val_loss: 0.0015 - 17s/epoch - 8ms/step\n",
      "Epoch 97/100\n",
      "2151/2151 - 17s - loss: 4.6458e-05 - val_loss: 0.0015 - 17s/epoch - 8ms/step\n",
      "Epoch 98/100\n",
      "2151/2151 - 17s - loss: 4.6056e-05 - val_loss: 0.0015 - 17s/epoch - 8ms/step\n",
      "Epoch 99/100\n",
      "2151/2151 - 17s - loss: 4.5648e-05 - val_loss: 0.0015 - 17s/epoch - 8ms/step\n",
      "Epoch 100/100\n",
      "2151/2151 - 17s - loss: 4.5340e-05 - val_loss: 0.0015 - 17s/epoch - 8ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 01:37:19.346694: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 01:37:19.446578: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 01:37:19.547231: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 01:37:35.533939: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 01:37:35.563913: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2151/2151 - 19s - loss: 1.5234e-04 - val_loss: 0.0068 - 19s/epoch - 9ms/step\n",
      "Epoch 2/100\n",
      "2151/2151 - 18s - loss: 1.4458e-04 - val_loss: 0.0147 - 18s/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "2151/2151 - 18s - loss: 2.3583e-04 - val_loss: 0.0214 - 18s/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "2151/2151 - 18s - loss: 2.5919e-04 - val_loss: 0.0180 - 18s/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "2151/2151 - 18s - loss: 2.3574e-04 - val_loss: 0.0158 - 18s/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "2151/2151 - 18s - loss: 2.1520e-04 - val_loss: 0.0134 - 18s/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "2151/2151 - 18s - loss: 1.7895e-04 - val_loss: 0.0110 - 18s/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "2151/2151 - 18s - loss: 1.5029e-04 - val_loss: 0.0090 - 18s/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "2151/2151 - 18s - loss: 1.2509e-04 - val_loss: 0.0074 - 18s/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "2151/2151 - 18s - loss: 1.0337e-04 - val_loss: 0.0059 - 18s/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "2151/2151 - 18s - loss: 8.7130e-05 - val_loss: 0.0050 - 18s/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "2151/2151 - 18s - loss: 7.6857e-05 - val_loss: 0.0043 - 18s/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "2151/2151 - 18s - loss: 7.1123e-05 - val_loss: 0.0038 - 18s/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "2151/2151 - 18s - loss: 6.7373e-05 - val_loss: 0.0035 - 18s/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "2151/2151 - 18s - loss: 6.7048e-05 - val_loss: 0.0034 - 18s/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "2151/2151 - 18s - loss: 6.7870e-05 - val_loss: 0.0035 - 18s/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "2151/2151 - 18s - loss: 7.0388e-05 - val_loss: 0.0038 - 18s/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "2151/2151 - 18s - loss: 7.4289e-05 - val_loss: 0.0041 - 18s/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "2151/2151 - 18s - loss: 7.7281e-05 - val_loss: 0.0045 - 18s/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "2151/2151 - 18s - loss: 8.0981e-05 - val_loss: 0.0048 - 18s/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "2151/2151 - 18s - loss: 8.2008e-05 - val_loss: 0.0049 - 18s/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "2151/2151 - 18s - loss: 8.8345e-05 - val_loss: 0.0055 - 18s/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "2151/2151 - 18s - loss: 9.3704e-05 - val_loss: 0.0060 - 18s/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "2151/2151 - 18s - loss: 1.0329e-04 - val_loss: 0.0067 - 18s/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "2151/2151 - 18s - loss: 1.1162e-04 - val_loss: 0.0068 - 18s/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "2151/2151 - 18s - loss: 1.1984e-04 - val_loss: 0.0065 - 18s/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "2151/2151 - 18s - loss: 1.2469e-04 - val_loss: 0.0058 - 18s/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "2151/2151 - 18s - loss: 1.2448e-04 - val_loss: 0.0050 - 18s/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "2151/2151 - 18s - loss: 1.2104e-04 - val_loss: 0.0044 - 18s/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "2151/2151 - 18s - loss: 1.1748e-04 - val_loss: 0.0040 - 18s/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "2151/2151 - 18s - loss: 1.1404e-04 - val_loss: 0.0037 - 18s/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "2151/2151 - 18s - loss: 1.1023e-04 - val_loss: 0.0034 - 18s/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "2151/2151 - 18s - loss: 1.0617e-04 - val_loss: 0.0032 - 18s/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "2151/2151 - 18s - loss: 1.0224e-04 - val_loss: 0.0030 - 18s/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "2151/2151 - 18s - loss: 9.8529e-05 - val_loss: 0.0029 - 18s/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "2151/2151 - 18s - loss: 9.5004e-05 - val_loss: 0.0028 - 18s/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "2151/2151 - 18s - loss: 9.1985e-05 - val_loss: 0.0027 - 18s/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "2151/2151 - 18s - loss: 8.9065e-05 - val_loss: 0.0027 - 18s/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "2151/2151 - 18s - loss: 8.6824e-05 - val_loss: 0.0026 - 18s/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "2151/2151 - 18s - loss: 8.4894e-05 - val_loss: 0.0026 - 18s/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "2151/2151 - 18s - loss: 8.3006e-05 - val_loss: 0.0026 - 18s/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "2151/2151 - 18s - loss: 8.1154e-05 - val_loss: 0.0025 - 18s/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "2151/2151 - 18s - loss: 7.9391e-05 - val_loss: 0.0025 - 18s/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "2151/2151 - 18s - loss: 7.7755e-05 - val_loss: 0.0025 - 18s/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "2151/2151 - 18s - loss: 7.6180e-05 - val_loss: 0.0025 - 18s/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "2151/2151 - 18s - loss: 7.4785e-05 - val_loss: 0.0025 - 18s/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "2151/2151 - 18s - loss: 7.3493e-05 - val_loss: 0.0024 - 18s/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "2151/2151 - 18s - loss: 7.2309e-05 - val_loss: 0.0024 - 18s/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "2151/2151 - 18s - loss: 7.1178e-05 - val_loss: 0.0024 - 18s/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "2151/2151 - 18s - loss: 7.0143e-05 - val_loss: 0.0024 - 18s/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "2151/2151 - 18s - loss: 6.9173e-05 - val_loss: 0.0023 - 18s/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "2151/2151 - 18s - loss: 6.8276e-05 - val_loss: 0.0023 - 18s/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "2151/2151 - 18s - loss: 6.7436e-05 - val_loss: 0.0023 - 18s/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "2151/2151 - 18s - loss: 6.6650e-05 - val_loss: 0.0023 - 18s/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "2151/2151 - 18s - loss: 6.5904e-05 - val_loss: 0.0023 - 18s/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "2151/2151 - 18s - loss: 6.5193e-05 - val_loss: 0.0022 - 18s/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "2151/2151 - 18s - loss: 6.4507e-05 - val_loss: 0.0022 - 18s/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "2151/2151 - 18s - loss: 6.3841e-05 - val_loss: 0.0022 - 18s/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "2151/2151 - 18s - loss: 6.3170e-05 - val_loss: 0.0021 - 18s/epoch - 8ms/step\n",
      "Epoch 60/100\n",
      "2151/2151 - 18s - loss: 6.2476e-05 - val_loss: 0.0021 - 18s/epoch - 8ms/step\n",
      "Epoch 61/100\n",
      "2151/2151 - 18s - loss: 6.1776e-05 - val_loss: 0.0021 - 18s/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "2151/2151 - 18s - loss: 6.1118e-05 - val_loss: 0.0021 - 18s/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "2151/2151 - 18s - loss: 6.0524e-05 - val_loss: 0.0020 - 18s/epoch - 8ms/step\n",
      "Epoch 64/100\n",
      "2151/2151 - 18s - loss: 5.9986e-05 - val_loss: 0.0020 - 18s/epoch - 8ms/step\n",
      "Epoch 65/100\n",
      "2151/2151 - 18s - loss: 5.9477e-05 - val_loss: 0.0020 - 18s/epoch - 8ms/step\n",
      "Epoch 66/100\n",
      "2151/2151 - 18s - loss: 5.8998e-05 - val_loss: 0.0019 - 18s/epoch - 8ms/step\n",
      "Epoch 67/100\n",
      "2151/2151 - 18s - loss: 5.8541e-05 - val_loss: 0.0019 - 18s/epoch - 8ms/step\n",
      "Epoch 68/100\n",
      "2151/2151 - 18s - loss: 5.8075e-05 - val_loss: 0.0019 - 18s/epoch - 8ms/step\n",
      "Epoch 69/100\n",
      "2151/2151 - 18s - loss: 5.7550e-05 - val_loss: 0.0019 - 18s/epoch - 8ms/step\n",
      "Epoch 70/100\n",
      "2151/2151 - 18s - loss: 5.6974e-05 - val_loss: 0.0018 - 18s/epoch - 8ms/step\n",
      "Epoch 71/100\n",
      "2151/2151 - 18s - loss: 5.6381e-05 - val_loss: 0.0018 - 18s/epoch - 8ms/step\n",
      "Epoch 72/100\n",
      "2151/2151 - 18s - loss: 5.5783e-05 - val_loss: 0.0018 - 18s/epoch - 8ms/step\n",
      "Epoch 73/100\n",
      "2151/2151 - 18s - loss: 5.5259e-05 - val_loss: 0.0018 - 18s/epoch - 8ms/step\n",
      "Epoch 74/100\n",
      "2151/2151 - 18s - loss: 5.4783e-05 - val_loss: 0.0017 - 18s/epoch - 8ms/step\n",
      "Epoch 75/100\n",
      "2151/2151 - 18s - loss: 5.4286e-05 - val_loss: 0.0017 - 18s/epoch - 8ms/step\n",
      "Epoch 76/100\n",
      "2151/2151 - 18s - loss: 5.3965e-05 - val_loss: 0.0017 - 18s/epoch - 8ms/step\n",
      "Epoch 77/100\n",
      "2151/2151 - 18s - loss: 5.3719e-05 - val_loss: 0.0017 - 18s/epoch - 8ms/step\n",
      "Epoch 78/100\n",
      "2151/2151 - 18s - loss: 5.3218e-05 - val_loss: 0.0017 - 18s/epoch - 8ms/step\n",
      "Epoch 79/100\n",
      "2151/2151 - 18s - loss: 5.2829e-05 - val_loss: 0.0017 - 18s/epoch - 8ms/step\n",
      "Epoch 80/100\n",
      "2151/2151 - 18s - loss: 5.2342e-05 - val_loss: 0.0016 - 18s/epoch - 8ms/step\n",
      "Epoch 81/100\n",
      "2151/2151 - 18s - loss: 5.1743e-05 - val_loss: 0.0016 - 18s/epoch - 8ms/step\n",
      "Epoch 82/100\n",
      "2151/2151 - 18s - loss: 5.1416e-05 - val_loss: 0.0016 - 18s/epoch - 8ms/step\n",
      "Epoch 83/100\n",
      "2151/2151 - 18s - loss: 5.0454e-05 - val_loss: 0.0015 - 18s/epoch - 8ms/step\n",
      "Epoch 84/100\n",
      "2151/2151 - 18s - loss: 5.0233e-05 - val_loss: 0.0015 - 18s/epoch - 8ms/step\n",
      "Epoch 85/100\n",
      "2151/2151 - 18s - loss: 4.9573e-05 - val_loss: 0.0015 - 18s/epoch - 8ms/step\n",
      "Epoch 86/100\n",
      "2151/2151 - 18s - loss: 4.9611e-05 - val_loss: 0.0015 - 18s/epoch - 8ms/step\n",
      "Epoch 87/100\n",
      "2151/2151 - 18s - loss: 4.9078e-05 - val_loss: 0.0015 - 18s/epoch - 8ms/step\n",
      "Epoch 88/100\n",
      "2151/2151 - 18s - loss: 4.8962e-05 - val_loss: 0.0015 - 18s/epoch - 8ms/step\n",
      "Epoch 89/100\n",
      "2151/2151 - 18s - loss: 4.8558e-05 - val_loss: 0.0014 - 18s/epoch - 8ms/step\n",
      "Epoch 90/100\n",
      "2151/2151 - 18s - loss: 4.8286e-05 - val_loss: 0.0014 - 18s/epoch - 8ms/step\n",
      "Epoch 91/100\n",
      "2151/2151 - 18s - loss: 4.7924e-05 - val_loss: 0.0014 - 18s/epoch - 8ms/step\n",
      "Epoch 92/100\n",
      "2151/2151 - 18s - loss: 4.7575e-05 - val_loss: 0.0014 - 18s/epoch - 8ms/step\n",
      "Epoch 93/100\n",
      "2151/2151 - 18s - loss: 4.7195e-05 - val_loss: 0.0014 - 18s/epoch - 8ms/step\n",
      "Epoch 94/100\n",
      "2151/2151 - 18s - loss: 4.6774e-05 - val_loss: 0.0013 - 18s/epoch - 8ms/step\n",
      "Epoch 95/100\n",
      "2151/2151 - 18s - loss: 4.6363e-05 - val_loss: 0.0013 - 18s/epoch - 8ms/step\n",
      "Epoch 96/100\n",
      "2151/2151 - 18s - loss: 4.5954e-05 - val_loss: 0.0013 - 18s/epoch - 8ms/step\n",
      "Epoch 97/100\n",
      "2151/2151 - 18s - loss: 4.5545e-05 - val_loss: 0.0013 - 18s/epoch - 8ms/step\n",
      "Epoch 98/100\n",
      "2151/2151 - 18s - loss: 4.5127e-05 - val_loss: 0.0013 - 18s/epoch - 8ms/step\n",
      "Epoch 99/100\n",
      "2151/2151 - 18s - loss: 4.4704e-05 - val_loss: 0.0013 - 18s/epoch - 8ms/step\n",
      "Epoch 100/100\n",
      "2151/2151 - 18s - loss: 4.4278e-05 - val_loss: 0.0013 - 18s/epoch - 8ms/step\n"
     ]
    }
   ],
   "source": [
    "lstms1 = []\n",
    "models1 = []\n",
    "for batch, epoch, neuron in hyperparam1:\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neuron, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(loss='mse',optimizer='adam')\n",
    "    lstm = model.fit(train_X, train_y, epochs=epoch, batch_size=batch, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    lstms1.append(lstm)\n",
    "    models1.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ebe15d8d-6bc9-4220-a7db-48e4d4c7cd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 1s 3ms/step\n",
      "(16, 25, 50)\n",
      "Epoch: 25\n",
      "Neurons: 50\n",
      "RMSE\n",
      "2854.1144178431277\n",
      "MAE\n",
      "2661.847421449076\n",
      "MAPE\n",
      "8.797838341915961\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(16, 25, 60)\n",
      "Epoch: 25\n",
      "Neurons: 60\n",
      "RMSE\n",
      "3094.2861460872437\n",
      "MAE\n",
      "3001.332799548755\n",
      "MAPE\n",
      "10.442579692079935\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(16, 25, 100)\n",
      "Epoch: 25\n",
      "Neurons: 100\n",
      "RMSE\n",
      "3212.2592240057947\n",
      "MAE\n",
      "3116.4529870173724\n",
      "MAPE\n",
      "11.953244137162478\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(16, 50, 50)\n",
      "Epoch: 50\n",
      "Neurons: 50\n",
      "RMSE\n",
      "2968.019054995013\n",
      "MAE\n",
      "2729.485839160385\n",
      "MAPE\n",
      "8.828274563168616\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(16, 50, 60)\n",
      "Epoch: 50\n",
      "Neurons: 60\n",
      "RMSE\n",
      "3070.7855514628673\n",
      "MAE\n",
      "2923.123643461014\n",
      "MAPE\n",
      "9.854244563678375\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(16, 50, 100)\n",
      "Epoch: 50\n",
      "Neurons: 100\n",
      "RMSE\n",
      "2782.8144377526833\n",
      "MAE\n",
      "2628.152383502624\n",
      "MAPE\n",
      "8.765595813845357\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(16, 100, 50)\n",
      "Epoch: 100\n",
      "Neurons: 50\n",
      "RMSE\n",
      "2231.815245465543\n",
      "MAE\n",
      "2105.0615244182763\n",
      "MAPE\n",
      "7.037086233549069\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(16, 100, 60)\n",
      "Epoch: 100\n",
      "Neurons: 60\n",
      "RMSE\n",
      "2502.67020517059\n",
      "MAE\n",
      "2336.0336169947377\n",
      "MAPE\n",
      "7.691414661088279\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(16, 100, 100)\n",
      "Epoch: 100\n",
      "Neurons: 100\n",
      "RMSE\n",
      "2323.855421496931\n",
      "MAE\n",
      "2159.1439314091604\n",
      "MAPE\n",
      "7.093030465017396\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "wb1 = Workbook()\n",
    "ws1 = wb1.active\n",
    "for x in models1:\n",
    "    # make a prediction\n",
    "    test_x2 = test_X\n",
    "    yhat = x.predict(test_x2)\n",
    "    # test_x2 = test_x2.reshape((test_x2.shape[0], test_x2.shape[2]))\n",
    "    # invert scaling for forecast\n",
    "    inv_yhat = np.concatenate((np.zeros((len(yhat), 4)),yhat), axis=1)\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    # inv_yhat = inv_yhat[:,0]\n",
    "    # invert scaling for actual\n",
    "    test_y = test_y.reshape((len(test_y), 1))\n",
    "    inv_y = np.concatenate((np.zeros((len(yhat), 4)), test_y), axis=1)\n",
    "    inv_y = scaler.inverse_transform(inv_y)\n",
    "    # inv_y = inv_y[:,0]\n",
    "    yhat_df = pd.DataFrame(inv_yhat, columns = ['Open','High','Low', 'Volume', 'Close'])\n",
    "    y_df = pd.DataFrame(inv_y, columns = ['Open','High','Low', 'Volume', 'Close'])\n",
    "    print(hyperparam1[i])\n",
    "    print(\"Epoch: \"+ str(lstms1[i].params['epochs']))\n",
    "    print(\"Neurons: \"+str(x.layers[0].units))\n",
    "    # print(str(lstms[i].params))\n",
    "    i = i+1\n",
    "    # test_x2 = test_X\n",
    "    # test_x3 = x.predict(test_x2)\n",
    "    # # print(test_x3.shape)\n",
    "    # # print(test_y.shape)\n",
    "    # print(yhat_df)\n",
    "    ws1['A'+str(i)] = 'LSTM'\n",
    "    ws1['B'+str(i)] = hyperparam1[i-1][0]\n",
    "    ws1['C'+str(i)] = hyperparam1[i-1][1]\n",
    "    ws1['D'+str(i)] = hyperparam1[i-1][2]\n",
    "    print('RMSE')\n",
    "    print(RMSE(y_df['Close'],yhat_df['Close']))\n",
    "    ws1['E'+str(i)] = RMSE(y_df['Close'],yhat_df['Close'])\n",
    "    print('MAE')\n",
    "    print(MAE(y_df['Close'],yhat_df['Close']))\n",
    "    ws1['F'+str(i)] = MAE(y_df['Close'],yhat_df['Close'])\n",
    "    print('MAPE')\n",
    "    print(MAPE(y_df['Close'],yhat_df['Close']))\n",
    "    ws1['G'+str(i)] = MAPE(y_df['Close'],yhat_df['Close'])\n",
    "wb1.save('LSTMresult1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09b72569-a783-465c-b828-1a68e970e0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 02:07:17.298503: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:07:17.381423: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:07:17.481981: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:07:25.891089: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:07:25.919875: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 - 10s - loss: 3.1081e-04 - val_loss: 0.0028 - 10s/epoch - 9ms/step\n",
      "Epoch 2/25\n",
      "1076/1076 - 9s - loss: 1.7088e-04 - val_loss: 0.0097 - 9s/epoch - 9ms/step\n",
      "Epoch 3/25\n",
      "1076/1076 - 9s - loss: 3.4033e-04 - val_loss: 0.0226 - 9s/epoch - 9ms/step\n",
      "Epoch 4/25\n",
      "1076/1076 - 9s - loss: 6.8923e-04 - val_loss: 0.0167 - 9s/epoch - 9ms/step\n",
      "Epoch 5/25\n",
      "1076/1076 - 9s - loss: 6.6658e-04 - val_loss: 0.0157 - 9s/epoch - 9ms/step\n",
      "Epoch 6/25\n",
      "1076/1076 - 9s - loss: 5.5073e-04 - val_loss: 0.0108 - 9s/epoch - 8ms/step\n",
      "Epoch 7/25\n",
      "1076/1076 - 9s - loss: 4.2547e-04 - val_loss: 0.0067 - 9s/epoch - 8ms/step\n",
      "Epoch 8/25\n",
      "1076/1076 - 9s - loss: 3.2823e-04 - val_loss: 0.0043 - 9s/epoch - 8ms/step\n",
      "Epoch 9/25\n",
      "1076/1076 - 9s - loss: 2.6099e-04 - val_loss: 0.0029 - 9s/epoch - 9ms/step\n",
      "Epoch 10/25\n",
      "1076/1076 - 9s - loss: 2.1086e-04 - val_loss: 0.0022 - 9s/epoch - 8ms/step\n",
      "Epoch 11/25\n",
      "1076/1076 - 9s - loss: 1.7393e-04 - val_loss: 0.0018 - 9s/epoch - 9ms/step\n",
      "Epoch 12/25\n",
      "1076/1076 - 9s - loss: 1.4902e-04 - val_loss: 0.0017 - 9s/epoch - 8ms/step\n",
      "Epoch 13/25\n",
      "1076/1076 - 9s - loss: 1.3344e-04 - val_loss: 0.0015 - 9s/epoch - 8ms/step\n",
      "Epoch 14/25\n",
      "1076/1076 - 9s - loss: 1.2505e-04 - val_loss: 0.0013 - 9s/epoch - 8ms/step\n",
      "Epoch 15/25\n",
      "1076/1076 - 9s - loss: 1.1747e-04 - val_loss: 0.0011 - 9s/epoch - 8ms/step\n",
      "Epoch 16/25\n",
      "1076/1076 - 9s - loss: 1.1019e-04 - val_loss: 8.2872e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 17/25\n",
      "1076/1076 - 9s - loss: 1.0188e-04 - val_loss: 6.7163e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 18/25\n",
      "1076/1076 - 9s - loss: 9.3581e-05 - val_loss: 5.7770e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 19/25\n",
      "1076/1076 - 9s - loss: 8.6669e-05 - val_loss: 5.2019e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 20/25\n",
      "1076/1076 - 9s - loss: 8.1805e-05 - val_loss: 4.6605e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 21/25\n",
      "1076/1076 - 9s - loss: 7.8636e-05 - val_loss: 4.0850e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 22/25\n",
      "1076/1076 - 9s - loss: 7.7190e-05 - val_loss: 3.4937e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 23/25\n",
      "1076/1076 - 9s - loss: 7.6245e-05 - val_loss: 2.8763e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 24/25\n",
      "1076/1076 - 9s - loss: 7.4307e-05 - val_loss: 2.4416e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 25/25\n",
      "1076/1076 - 9s - loss: 7.1228e-05 - val_loss: 2.2437e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 02:11:04.986163: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:11:05.061349: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:11:05.177459: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:11:13.688496: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:11:13.719822: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 - 10s - loss: 4.7604e-04 - val_loss: 0.0072 - 10s/epoch - 10ms/step\n",
      "Epoch 2/25\n",
      "1076/1076 - 9s - loss: 2.2522e-04 - val_loss: 0.0172 - 9s/epoch - 9ms/step\n",
      "Epoch 3/25\n",
      "1076/1076 - 9s - loss: 4.0287e-04 - val_loss: 0.0256 - 9s/epoch - 9ms/step\n",
      "Epoch 4/25\n",
      "1076/1076 - 9s - loss: 7.4953e-04 - val_loss: 0.0181 - 9s/epoch - 9ms/step\n",
      "Epoch 5/25\n",
      "1076/1076 - 9s - loss: 6.9298e-04 - val_loss: 0.0145 - 9s/epoch - 9ms/step\n",
      "Epoch 6/25\n",
      "1076/1076 - 9s - loss: 5.3080e-04 - val_loss: 0.0097 - 9s/epoch - 9ms/step\n",
      "Epoch 7/25\n",
      "1076/1076 - 9s - loss: 4.0519e-04 - val_loss: 0.0063 - 9s/epoch - 8ms/step\n",
      "Epoch 8/25\n",
      "1076/1076 - 9s - loss: 3.0967e-04 - val_loss: 0.0042 - 9s/epoch - 8ms/step\n",
      "Epoch 9/25\n",
      "1076/1076 - 9s - loss: 2.4261e-04 - val_loss: 0.0030 - 9s/epoch - 8ms/step\n",
      "Epoch 10/25\n",
      "1076/1076 - 9s - loss: 1.9471e-04 - val_loss: 0.0024 - 9s/epoch - 8ms/step\n",
      "Epoch 11/25\n",
      "1076/1076 - 9s - loss: 1.6260e-04 - val_loss: 0.0021 - 9s/epoch - 9ms/step\n",
      "Epoch 12/25\n",
      "1076/1076 - 9s - loss: 1.4799e-04 - val_loss: 0.0017 - 9s/epoch - 8ms/step\n",
      "Epoch 13/25\n",
      "1076/1076 - 9s - loss: 1.3522e-04 - val_loss: 0.0014 - 9s/epoch - 8ms/step\n",
      "Epoch 14/25\n",
      "1076/1076 - 9s - loss: 1.2336e-04 - val_loss: 0.0011 - 9s/epoch - 8ms/step\n",
      "Epoch 15/25\n",
      "1076/1076 - 9s - loss: 1.1198e-04 - val_loss: 8.4174e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 16/25\n",
      "1076/1076 - 9s - loss: 1.0282e-04 - val_loss: 6.8423e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 17/25\n",
      "1076/1076 - 9s - loss: 9.6191e-05 - val_loss: 5.4695e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 18/25\n",
      "1076/1076 - 9s - loss: 9.0632e-05 - val_loss: 4.4416e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 19/25\n",
      "1076/1076 - 9s - loss: 8.5614e-05 - val_loss: 3.7935e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 20/25\n",
      "1076/1076 - 9s - loss: 8.1556e-05 - val_loss: 3.3666e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 21/25\n",
      "1076/1076 - 9s - loss: 7.9178e-05 - val_loss: 2.9626e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 22/25\n",
      "1076/1076 - 9s - loss: 7.8071e-05 - val_loss: 2.4580e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 23/25\n",
      "1076/1076 - 9s - loss: 7.5624e-05 - val_loss: 2.0404e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 24/25\n",
      "1076/1076 - 9s - loss: 7.1776e-05 - val_loss: 1.8828e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 25/25\n",
      "1076/1076 - 9s - loss: 6.8118e-05 - val_loss: 1.8769e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 02:14:54.712160: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:14:54.794672: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:14:54.906964: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:15:03.287426: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:15:03.332233: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 - 10s - loss: 1.7680e-04 - val_loss: 0.0060 - 10s/epoch - 9ms/step\n",
      "Epoch 2/25\n",
      "1076/1076 - 9s - loss: 2.0046e-04 - val_loss: 0.0111 - 9s/epoch - 9ms/step\n",
      "Epoch 3/25\n",
      "1076/1076 - 9s - loss: 3.1494e-04 - val_loss: 0.0260 - 9s/epoch - 8ms/step\n",
      "Epoch 4/25\n",
      "1076/1076 - 9s - loss: 6.0925e-04 - val_loss: 0.0225 - 9s/epoch - 8ms/step\n",
      "Epoch 5/25\n",
      "1076/1076 - 9s - loss: 7.8852e-04 - val_loss: 0.0161 - 9s/epoch - 8ms/step\n",
      "Epoch 6/25\n",
      "1076/1076 - 9s - loss: 6.2520e-04 - val_loss: 0.0119 - 9s/epoch - 8ms/step\n",
      "Epoch 7/25\n",
      "1076/1076 - 9s - loss: 4.7912e-04 - val_loss: 0.0079 - 9s/epoch - 8ms/step\n",
      "Epoch 8/25\n",
      "1076/1076 - 9s - loss: 3.6283e-04 - val_loss: 0.0052 - 9s/epoch - 8ms/step\n",
      "Epoch 9/25\n",
      "1076/1076 - 9s - loss: 2.8004e-04 - val_loss: 0.0036 - 9s/epoch - 8ms/step\n",
      "Epoch 10/25\n",
      "1076/1076 - 9s - loss: 2.2417e-04 - val_loss: 0.0028 - 9s/epoch - 8ms/step\n",
      "Epoch 11/25\n",
      "1076/1076 - 9s - loss: 1.8318e-04 - val_loss: 0.0023 - 9s/epoch - 8ms/step\n",
      "Epoch 12/25\n",
      "1076/1076 - 9s - loss: 1.6354e-04 - val_loss: 0.0019 - 9s/epoch - 8ms/step\n",
      "Epoch 13/25\n",
      "1076/1076 - 9s - loss: 1.5076e-04 - val_loss: 0.0014 - 9s/epoch - 8ms/step\n",
      "Epoch 14/25\n",
      "1076/1076 - 9s - loss: 1.3940e-04 - val_loss: 0.0011 - 9s/epoch - 8ms/step\n",
      "Epoch 15/25\n",
      "1076/1076 - 9s - loss: 1.2944e-04 - val_loss: 8.4120e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 16/25\n",
      "1076/1076 - 9s - loss: 1.2022e-04 - val_loss: 6.1010e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 17/25\n",
      "1076/1076 - 9s - loss: 1.1128e-04 - val_loss: 4.9334e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 18/25\n",
      "1076/1076 - 9s - loss: 1.0408e-04 - val_loss: 4.2292e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 19/25\n",
      "1076/1076 - 9s - loss: 9.8365e-05 - val_loss: 3.4450e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 20/25\n",
      "1076/1076 - 9s - loss: 9.3374e-05 - val_loss: 3.0502e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 21/25\n",
      "1076/1076 - 9s - loss: 8.9102e-05 - val_loss: 2.8079e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 22/25\n",
      "1076/1076 - 9s - loss: 8.4886e-05 - val_loss: 2.5121e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 23/25\n",
      "1076/1076 - 9s - loss: 8.1517e-05 - val_loss: 2.3365e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 24/25\n",
      "1076/1076 - 9s - loss: 7.8235e-05 - val_loss: 2.1678e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 25/25\n",
      "1076/1076 - 9s - loss: 7.5613e-05 - val_loss: 2.0327e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 02:18:41.683811: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:18:41.756721: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:18:41.866053: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:18:50.202885: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:18:50.237291: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 - 10s - loss: 2.7507e-04 - val_loss: 0.0051 - 10s/epoch - 9ms/step\n",
      "Epoch 2/50\n",
      "1076/1076 - 9s - loss: 1.9511e-04 - val_loss: 0.0127 - 9s/epoch - 9ms/step\n",
      "Epoch 3/50\n",
      "1076/1076 - 9s - loss: 3.3535e-04 - val_loss: 0.0219 - 9s/epoch - 9ms/step\n",
      "Epoch 4/50\n",
      "1076/1076 - 9s - loss: 6.4565e-04 - val_loss: 0.0158 - 9s/epoch - 8ms/step\n",
      "Epoch 5/50\n",
      "1076/1076 - 9s - loss: 6.6542e-04 - val_loss: 0.0142 - 9s/epoch - 8ms/step\n",
      "Epoch 6/50\n",
      "1076/1076 - 9s - loss: 5.5729e-04 - val_loss: 0.0108 - 9s/epoch - 8ms/step\n",
      "Epoch 7/50\n",
      "1076/1076 - 9s - loss: 4.3998e-04 - val_loss: 0.0071 - 9s/epoch - 8ms/step\n",
      "Epoch 8/50\n",
      "1076/1076 - 9s - loss: 3.4059e-04 - val_loss: 0.0047 - 9s/epoch - 8ms/step\n",
      "Epoch 9/50\n",
      "1076/1076 - 9s - loss: 2.6733e-04 - val_loss: 0.0031 - 9s/epoch - 8ms/step\n",
      "Epoch 10/50\n",
      "1076/1076 - 9s - loss: 2.1455e-04 - val_loss: 0.0023 - 9s/epoch - 8ms/step\n",
      "Epoch 11/50\n",
      "1076/1076 - 9s - loss: 1.7787e-04 - val_loss: 0.0018 - 9s/epoch - 8ms/step\n",
      "Epoch 12/50\n",
      "1076/1076 - 9s - loss: 1.5313e-04 - val_loss: 0.0016 - 9s/epoch - 8ms/step\n",
      "Epoch 13/50\n",
      "1076/1076 - 9s - loss: 1.3712e-04 - val_loss: 0.0014 - 9s/epoch - 8ms/step\n",
      "Epoch 14/50\n",
      "1076/1076 - 9s - loss: 1.2777e-04 - val_loss: 0.0012 - 9s/epoch - 9ms/step\n",
      "Epoch 15/50\n",
      "1076/1076 - 9s - loss: 1.1871e-04 - val_loss: 9.2667e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 16/50\n",
      "1076/1076 - 9s - loss: 1.0882e-04 - val_loss: 7.6021e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 17/50\n",
      "1076/1076 - 9s - loss: 9.9829e-05 - val_loss: 6.5862e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 18/50\n",
      "1076/1076 - 9s - loss: 9.2997e-05 - val_loss: 5.6607e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 19/50\n",
      "1076/1076 - 9s - loss: 8.6958e-05 - val_loss: 5.1114e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 20/50\n",
      "1076/1076 - 9s - loss: 8.2751e-05 - val_loss: 4.5421e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 21/50\n",
      "1076/1076 - 9s - loss: 7.9313e-05 - val_loss: 4.0287e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 22/50\n",
      "1076/1076 - 9s - loss: 7.8105e-05 - val_loss: 3.5378e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 23/50\n",
      "1076/1076 - 9s - loss: 7.6878e-05 - val_loss: 3.0827e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 24/50\n",
      "1076/1076 - 9s - loss: 7.4119e-05 - val_loss: 2.6986e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 25/50\n",
      "1076/1076 - 9s - loss: 7.0113e-05 - val_loss: 2.6092e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 26/50\n",
      "1076/1076 - 9s - loss: 6.6081e-05 - val_loss: 2.6748e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 27/50\n",
      "1076/1076 - 9s - loss: 6.2990e-05 - val_loss: 2.7721e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 28/50\n",
      "1076/1076 - 9s - loss: 6.1071e-05 - val_loss: 2.8164e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 29/50\n",
      "1076/1076 - 9s - loss: 5.9919e-05 - val_loss: 2.7842e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 30/50\n",
      "1076/1076 - 9s - loss: 5.9052e-05 - val_loss: 2.6785e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 31/50\n",
      "1076/1076 - 9s - loss: 5.8029e-05 - val_loss: 2.5772e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 32/50\n",
      "1076/1076 - 9s - loss: 5.6689e-05 - val_loss: 2.5014e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 33/50\n",
      "1076/1076 - 9s - loss: 5.5076e-05 - val_loss: 2.4738e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 34/50\n",
      "1076/1076 - 9s - loss: 5.3233e-05 - val_loss: 2.4901e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 35/50\n",
      "1076/1076 - 9s - loss: 5.1284e-05 - val_loss: 2.5524e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 36/50\n",
      "1076/1076 - 9s - loss: 4.9745e-05 - val_loss: 2.5770e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 37/50\n",
      "1076/1076 - 9s - loss: 4.8192e-05 - val_loss: 2.5828e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 38/50\n",
      "1076/1076 - 9s - loss: 4.6631e-05 - val_loss: 2.6132e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 39/50\n",
      "1076/1076 - 9s - loss: 4.5145e-05 - val_loss: 2.6437e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 40/50\n",
      "1076/1076 - 9s - loss: 4.3809e-05 - val_loss: 2.6603e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 41/50\n",
      "1076/1076 - 9s - loss: 4.2468e-05 - val_loss: 2.6736e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 42/50\n",
      "1076/1076 - 9s - loss: 4.1270e-05 - val_loss: 2.6859e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 43/50\n",
      "1076/1076 - 9s - loss: 4.0184e-05 - val_loss: 2.6943e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 44/50\n",
      "1076/1076 - 9s - loss: 3.9397e-05 - val_loss: 2.7082e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 45/50\n",
      "1076/1076 - 9s - loss: 3.8729e-05 - val_loss: 2.7322e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 46/50\n",
      "1076/1076 - 9s - loss: 3.8254e-05 - val_loss: 2.7444e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 47/50\n",
      "1076/1076 - 9s - loss: 3.7930e-05 - val_loss: 2.7346e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 48/50\n",
      "1076/1076 - 9s - loss: 3.7661e-05 - val_loss: 2.7100e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 49/50\n",
      "1076/1076 - 9s - loss: 3.7359e-05 - val_loss: 2.6721e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 50/50\n",
      "1076/1076 - 9s - loss: 3.7016e-05 - val_loss: 2.6348e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 02:26:17.056978: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:26:17.142390: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:26:17.243577: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:26:25.947947: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:26:25.977364: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 - 10s - loss: 3.1965e-04 - val_loss: 0.0047 - 10s/epoch - 10ms/step\n",
      "Epoch 2/50\n",
      "1076/1076 - 9s - loss: 1.7216e-04 - val_loss: 0.0099 - 9s/epoch - 9ms/step\n",
      "Epoch 3/50\n",
      "1076/1076 - 9s - loss: 3.0535e-04 - val_loss: 0.0233 - 9s/epoch - 9ms/step\n",
      "Epoch 4/50\n",
      "1076/1076 - 9s - loss: 6.4623e-04 - val_loss: 0.0173 - 9s/epoch - 9ms/step\n",
      "Epoch 5/50\n",
      "1076/1076 - 9s - loss: 6.9669e-04 - val_loss: 0.0169 - 9s/epoch - 9ms/step\n",
      "Epoch 6/50\n",
      "1076/1076 - 9s - loss: 5.8346e-04 - val_loss: 0.0125 - 9s/epoch - 9ms/step\n",
      "Epoch 7/50\n",
      "1076/1076 - 9s - loss: 4.5168e-04 - val_loss: 0.0081 - 9s/epoch - 9ms/step\n",
      "Epoch 8/50\n",
      "1076/1076 - 9s - loss: 3.4740e-04 - val_loss: 0.0052 - 9s/epoch - 9ms/step\n",
      "Epoch 9/50\n",
      "1076/1076 - 9s - loss: 2.8021e-04 - val_loss: 0.0035 - 9s/epoch - 9ms/step\n",
      "Epoch 10/50\n",
      "1076/1076 - 9s - loss: 2.3190e-04 - val_loss: 0.0024 - 9s/epoch - 9ms/step\n",
      "Epoch 11/50\n",
      "1076/1076 - 9s - loss: 1.9615e-04 - val_loss: 0.0018 - 9s/epoch - 9ms/step\n",
      "Epoch 12/50\n",
      "1076/1076 - 9s - loss: 1.6844e-04 - val_loss: 0.0014 - 9s/epoch - 9ms/step\n",
      "Epoch 13/50\n",
      "1076/1076 - 9s - loss: 1.4812e-04 - val_loss: 0.0011 - 9s/epoch - 9ms/step\n",
      "Epoch 14/50\n",
      "1076/1076 - 9s - loss: 1.3315e-04 - val_loss: 9.3245e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 15/50\n",
      "1076/1076 - 9s - loss: 1.2297e-04 - val_loss: 7.4495e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 16/50\n",
      "1076/1076 - 9s - loss: 1.1412e-04 - val_loss: 6.1339e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 17/50\n",
      "1076/1076 - 9s - loss: 1.0642e-04 - val_loss: 5.2304e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 18/50\n",
      "1076/1076 - 9s - loss: 9.9605e-05 - val_loss: 4.3239e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 19/50\n",
      "1076/1076 - 9s - loss: 9.3344e-05 - val_loss: 3.9407e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 20/50\n",
      "1076/1076 - 9s - loss: 8.8202e-05 - val_loss: 3.3811e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 21/50\n",
      "1076/1076 - 9s - loss: 8.4738e-05 - val_loss: 2.9318e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 22/50\n",
      "1076/1076 - 9s - loss: 8.2083e-05 - val_loss: 2.5900e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 23/50\n",
      "1076/1076 - 9s - loss: 8.0088e-05 - val_loss: 2.2444e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 24/50\n",
      "1076/1076 - 9s - loss: 7.7651e-05 - val_loss: 2.0361e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 25/50\n",
      "1076/1076 - 9s - loss: 7.4643e-05 - val_loss: 1.9467e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 26/50\n",
      "1076/1076 - 9s - loss: 7.2273e-05 - val_loss: 1.7794e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 27/50\n",
      "1076/1076 - 9s - loss: 7.1301e-05 - val_loss: 1.6204e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 28/50\n",
      "1076/1076 - 9s - loss: 7.0108e-05 - val_loss: 1.4570e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 29/50\n",
      "1076/1076 - 9s - loss: 6.8080e-05 - val_loss: 1.3674e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 30/50\n",
      "1076/1076 - 9s - loss: 6.5474e-05 - val_loss: 1.3470e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 31/50\n",
      "1076/1076 - 9s - loss: 6.2899e-05 - val_loss: 1.3621e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 32/50\n",
      "1076/1076 - 9s - loss: 6.0719e-05 - val_loss: 1.3801e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 33/50\n",
      "1076/1076 - 9s - loss: 5.8889e-05 - val_loss: 1.3897e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 34/50\n",
      "1076/1076 - 9s - loss: 5.7153e-05 - val_loss: 1.4005e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 35/50\n",
      "1076/1076 - 9s - loss: 5.5305e-05 - val_loss: 1.4295e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 36/50\n",
      "1076/1076 - 9s - loss: 5.3182e-05 - val_loss: 1.4963e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 37/50\n",
      "1076/1076 - 9s - loss: 5.0720e-05 - val_loss: 1.6135e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 38/50\n",
      "1076/1076 - 9s - loss: 4.7953e-05 - val_loss: 1.7857e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 39/50\n",
      "1076/1076 - 9s - loss: 4.4962e-05 - val_loss: 2.0004e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 40/50\n",
      "1076/1076 - 9s - loss: 4.1926e-05 - val_loss: 2.2221e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 41/50\n",
      "1076/1076 - 9s - loss: 3.9307e-05 - val_loss: 2.3975e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 42/50\n",
      "1076/1076 - 9s - loss: 3.7442e-05 - val_loss: 2.5057e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 43/50\n",
      "1076/1076 - 9s - loss: 3.6330e-05 - val_loss: 2.6384e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 44/50\n",
      "1076/1076 - 9s - loss: 3.5854e-05 - val_loss: 2.8676e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 45/50\n",
      "1076/1076 - 9s - loss: 3.5846e-05 - val_loss: 3.1280e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 46/50\n",
      "1076/1076 - 9s - loss: 3.6063e-05 - val_loss: 3.3153e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 47/50\n",
      "1076/1076 - 9s - loss: 3.6312e-05 - val_loss: 3.3902e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 48/50\n",
      "1076/1076 - 9s - loss: 3.6473e-05 - val_loss: 3.3854e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 49/50\n",
      "1076/1076 - 9s - loss: 3.6549e-05 - val_loss: 3.3397e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 50/50\n",
      "1076/1076 - 9s - loss: 3.6536e-05 - val_loss: 3.2866e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 02:33:58.532655: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:33:58.608972: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:33:58.747506: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:34:07.447024: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:34:07.483109: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 - 11s - loss: 2.6795e-04 - val_loss: 0.0047 - 11s/epoch - 10ms/step\n",
      "Epoch 2/50\n",
      "1076/1076 - 9s - loss: 1.9463e-04 - val_loss: 0.0099 - 9s/epoch - 9ms/step\n",
      "Epoch 3/50\n",
      "1076/1076 - 9s - loss: 2.6703e-04 - val_loss: 0.0216 - 9s/epoch - 8ms/step\n",
      "Epoch 4/50\n",
      "1076/1076 - 9s - loss: 4.3636e-04 - val_loss: 0.0230 - 9s/epoch - 8ms/step\n",
      "Epoch 5/50\n",
      "1076/1076 - 9s - loss: 6.8481e-04 - val_loss: 0.0149 - 9s/epoch - 8ms/step\n",
      "Epoch 6/50\n",
      "1076/1076 - 9s - loss: 6.3377e-04 - val_loss: 0.0117 - 9s/epoch - 8ms/step\n",
      "Epoch 7/50\n",
      "1076/1076 - 9s - loss: 4.9227e-04 - val_loss: 0.0080 - 9s/epoch - 8ms/step\n",
      "Epoch 8/50\n",
      "1076/1076 - 9s - loss: 3.7558e-04 - val_loss: 0.0054 - 9s/epoch - 8ms/step\n",
      "Epoch 9/50\n",
      "1076/1076 - 9s - loss: 2.8868e-04 - val_loss: 0.0038 - 9s/epoch - 8ms/step\n",
      "Epoch 10/50\n",
      "1076/1076 - 9s - loss: 2.2754e-04 - val_loss: 0.0029 - 9s/epoch - 8ms/step\n",
      "Epoch 11/50\n",
      "1076/1076 - 9s - loss: 1.8708e-04 - val_loss: 0.0025 - 9s/epoch - 8ms/step\n",
      "Epoch 12/50\n",
      "1076/1076 - 9s - loss: 1.6513e-04 - val_loss: 0.0022 - 9s/epoch - 8ms/step\n",
      "Epoch 13/50\n",
      "1076/1076 - 9s - loss: 1.5146e-04 - val_loss: 0.0018 - 9s/epoch - 8ms/step\n",
      "Epoch 14/50\n",
      "1076/1076 - 9s - loss: 1.3855e-04 - val_loss: 0.0014 - 9s/epoch - 8ms/step\n",
      "Epoch 15/50\n",
      "1076/1076 - 9s - loss: 1.2622e-04 - val_loss: 0.0012 - 9s/epoch - 9ms/step\n",
      "Epoch 16/50\n",
      "1076/1076 - 9s - loss: 1.1672e-04 - val_loss: 8.8547e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 17/50\n",
      "1076/1076 - 9s - loss: 1.0508e-04 - val_loss: 7.7518e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 18/50\n",
      "1076/1076 - 9s - loss: 9.6109e-05 - val_loss: 6.8697e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 19/50\n",
      "1076/1076 - 9s - loss: 8.8384e-05 - val_loss: 6.9358e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 20/50\n",
      "1076/1076 - 9s - loss: 8.6418e-05 - val_loss: 5.7239e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 21/50\n",
      "1076/1076 - 9s - loss: 8.8540e-05 - val_loss: 4.4645e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 22/50\n",
      "1076/1076 - 9s - loss: 8.7532e-05 - val_loss: 3.3256e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 23/50\n",
      "1076/1076 - 9s - loss: 8.2973e-05 - val_loss: 2.7745e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 24/50\n",
      "1076/1076 - 9s - loss: 7.7450e-05 - val_loss: 2.7055e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 25/50\n",
      "1076/1076 - 9s - loss: 7.2878e-05 - val_loss: 2.7552e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 26/50\n",
      "1076/1076 - 9s - loss: 6.9865e-05 - val_loss: 2.7592e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 27/50\n",
      "1076/1076 - 9s - loss: 6.8210e-05 - val_loss: 2.6558e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 28/50\n",
      "1076/1076 - 9s - loss: 6.7286e-05 - val_loss: 2.4596e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 29/50\n",
      "1076/1076 - 9s - loss: 6.6405e-05 - val_loss: 2.2438e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 30/50\n",
      "1076/1076 - 9s - loss: 6.5146e-05 - val_loss: 2.0621e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 31/50\n",
      "1076/1076 - 9s - loss: 6.3211e-05 - val_loss: 1.9550e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 32/50\n",
      "1076/1076 - 9s - loss: 6.0735e-05 - val_loss: 1.9244e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 33/50\n",
      "1076/1076 - 9s - loss: 5.8113e-05 - val_loss: 1.9514e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 34/50\n",
      "1076/1076 - 9s - loss: 5.5675e-05 - val_loss: 2.0062e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 35/50\n",
      "1076/1076 - 9s - loss: 5.3443e-05 - val_loss: 2.0674e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 36/50\n",
      "1076/1076 - 9s - loss: 5.1279e-05 - val_loss: 2.1363e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 37/50\n",
      "1076/1076 - 9s - loss: 4.9223e-05 - val_loss: 2.2080e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 38/50\n",
      "1076/1076 - 9s - loss: 4.7131e-05 - val_loss: 2.2827e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 39/50\n",
      "1076/1076 - 9s - loss: 4.5040e-05 - val_loss: 2.3526e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 40/50\n",
      "1076/1076 - 9s - loss: 4.3101e-05 - val_loss: 2.4091e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 41/50\n",
      "1076/1076 - 9s - loss: 4.1271e-05 - val_loss: 2.4545e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 42/50\n",
      "1076/1076 - 9s - loss: 3.9793e-05 - val_loss: 2.4793e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 43/50\n",
      "1076/1076 - 9s - loss: 3.8803e-05 - val_loss: 2.5208e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 44/50\n",
      "1076/1076 - 9s - loss: 3.8034e-05 - val_loss: 2.6040e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 45/50\n",
      "1076/1076 - 9s - loss: 3.7588e-05 - val_loss: 2.7086e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 46/50\n",
      "1076/1076 - 9s - loss: 3.7327e-05 - val_loss: 2.8133e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 47/50\n",
      "1076/1076 - 9s - loss: 3.7196e-05 - val_loss: 2.8935e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 48/50\n",
      "1076/1076 - 9s - loss: 3.7083e-05 - val_loss: 2.9379e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 49/50\n",
      "1076/1076 - 9s - loss: 3.6943e-05 - val_loss: 2.9483e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 50/50\n",
      "1076/1076 - 9s - loss: 3.6747e-05 - val_loss: 2.9349e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 02:41:31.151940: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:41:31.241624: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:41:31.384964: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:41:39.828834: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:41:39.861790: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 - 10s - loss: 3.5841e-04 - val_loss: 0.0060 - 10s/epoch - 10ms/step\n",
      "Epoch 2/100\n",
      "1076/1076 - 9s - loss: 2.0331e-04 - val_loss: 0.0150 - 9s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "1076/1076 - 9s - loss: 3.7585e-04 - val_loss: 0.0227 - 9s/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "1076/1076 - 9s - loss: 6.9987e-04 - val_loss: 0.0152 - 9s/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "1076/1076 - 9s - loss: 6.3947e-04 - val_loss: 0.0127 - 9s/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "1076/1076 - 9s - loss: 5.0782e-04 - val_loss: 0.0085 - 9s/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "1076/1076 - 9s - loss: 3.8106e-04 - val_loss: 0.0052 - 9s/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "1076/1076 - 9s - loss: 2.8962e-04 - val_loss: 0.0034 - 9s/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "1076/1076 - 9s - loss: 2.2101e-04 - val_loss: 0.0025 - 9s/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "1076/1076 - 9s - loss: 1.7416e-04 - val_loss: 0.0021 - 9s/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "1076/1076 - 9s - loss: 1.4345e-04 - val_loss: 0.0021 - 9s/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "1076/1076 - 9s - loss: 1.2329e-04 - val_loss: 0.0020 - 9s/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "1076/1076 - 9s - loss: 1.1000e-04 - val_loss: 0.0019 - 9s/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "1076/1076 - 9s - loss: 9.9815e-05 - val_loss: 0.0017 - 9s/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "1076/1076 - 9s - loss: 9.2480e-05 - val_loss: 0.0015 - 9s/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "1076/1076 - 9s - loss: 8.5978e-05 - val_loss: 0.0013 - 9s/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "1076/1076 - 9s - loss: 8.3821e-05 - val_loss: 0.0011 - 9s/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "1076/1076 - 9s - loss: 8.1429e-05 - val_loss: 8.3570e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "1076/1076 - 9s - loss: 7.9713e-05 - val_loss: 6.5005e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "1076/1076 - 9s - loss: 7.7822e-05 - val_loss: 5.1708e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "1076/1076 - 9s - loss: 7.4503e-05 - val_loss: 4.2785e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "1076/1076 - 9s - loss: 6.9181e-05 - val_loss: 3.9935e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "1076/1076 - 9s - loss: 6.3161e-05 - val_loss: 4.0106e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "1076/1076 - 9s - loss: 5.7830e-05 - val_loss: 4.1959e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "1076/1076 - 9s - loss: 5.3787e-05 - val_loss: 4.3132e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "1076/1076 - 9s - loss: 5.0606e-05 - val_loss: 4.3819e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "1076/1076 - 9s - loss: 4.8192e-05 - val_loss: 4.4336e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "1076/1076 - 9s - loss: 4.6522e-05 - val_loss: 4.4751e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "1076/1076 - 9s - loss: 4.5342e-05 - val_loss: 4.5524e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "1076/1076 - 9s - loss: 4.4518e-05 - val_loss: 4.6606e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "1076/1076 - 9s - loss: 4.3928e-05 - val_loss: 4.7651e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "1076/1076 - 9s - loss: 4.3448e-05 - val_loss: 4.8132e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "1076/1076 - 9s - loss: 4.2980e-05 - val_loss: 4.8011e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "1076/1076 - 9s - loss: 4.2446e-05 - val_loss: 4.7573e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "1076/1076 - 9s - loss: 4.1876e-05 - val_loss: 4.7140e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "1076/1076 - 9s - loss: 4.1460e-05 - val_loss: 4.6738e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "1076/1076 - 9s - loss: 4.0977e-05 - val_loss: 4.6226e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "1076/1076 - 9s - loss: 4.0407e-05 - val_loss: 4.5416e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "1076/1076 - 9s - loss: 3.9861e-05 - val_loss: 4.4826e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "1076/1076 - 9s - loss: 3.9367e-05 - val_loss: 4.4525e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "1076/1076 - 9s - loss: 3.8917e-05 - val_loss: 4.4312e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "1076/1076 - 9s - loss: 3.8510e-05 - val_loss: 4.4203e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "1076/1076 - 9s - loss: 3.8135e-05 - val_loss: 4.4054e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "1076/1076 - 9s - loss: 3.7782e-05 - val_loss: 4.3906e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "1076/1076 - 9s - loss: 3.7446e-05 - val_loss: 4.3752e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "1076/1076 - 9s - loss: 3.7126e-05 - val_loss: 4.3618e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "1076/1076 - 9s - loss: 3.6828e-05 - val_loss: 4.3509e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "1076/1076 - 9s - loss: 3.6559e-05 - val_loss: 4.3392e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "1076/1076 - 9s - loss: 3.6311e-05 - val_loss: 4.3217e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "1076/1076 - 9s - loss: 3.6072e-05 - val_loss: 4.2943e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "1076/1076 - 9s - loss: 3.5837e-05 - val_loss: 4.2582e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "1076/1076 - 9s - loss: 3.5604e-05 - val_loss: 4.2148e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "1076/1076 - 9s - loss: 3.5368e-05 - val_loss: 4.1645e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "1076/1076 - 9s - loss: 3.5122e-05 - val_loss: 4.1090e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "1076/1076 - 9s - loss: 3.4873e-05 - val_loss: 4.0530e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "1076/1076 - 9s - loss: 3.4642e-05 - val_loss: 3.9987e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "1076/1076 - 9s - loss: 3.4420e-05 - val_loss: 3.9420e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "1076/1076 - 9s - loss: 3.4184e-05 - val_loss: 3.8799e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "1076/1076 - 9s - loss: 3.3926e-05 - val_loss: 3.8136e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 60/100\n",
      "1076/1076 - 9s - loss: 3.3642e-05 - val_loss: 3.7458e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 61/100\n",
      "1076/1076 - 9s - loss: 3.3331e-05 - val_loss: 3.6815e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "1076/1076 - 9s - loss: 3.3011e-05 - val_loss: 3.6279e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "1076/1076 - 9s - loss: 3.2710e-05 - val_loss: 3.5905e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 64/100\n",
      "1076/1076 - 9s - loss: 3.2444e-05 - val_loss: 3.5645e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 65/100\n",
      "1076/1076 - 9s - loss: 3.2195e-05 - val_loss: 3.5392e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 66/100\n",
      "1076/1076 - 9s - loss: 3.1943e-05 - val_loss: 3.5115e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 67/100\n",
      "1076/1076 - 9s - loss: 3.1692e-05 - val_loss: 3.4849e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 68/100\n",
      "1076/1076 - 9s - loss: 3.1443e-05 - val_loss: 3.4596e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 69/100\n",
      "1076/1076 - 9s - loss: 3.1200e-05 - val_loss: 3.4387e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 70/100\n",
      "1076/1076 - 9s - loss: 3.0972e-05 - val_loss: 3.4217e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 71/100\n",
      "1076/1076 - 9s - loss: 3.0761e-05 - val_loss: 3.4085e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 72/100\n",
      "1076/1076 - 9s - loss: 3.0563e-05 - val_loss: 3.3976e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 73/100\n",
      "1076/1076 - 9s - loss: 3.0375e-05 - val_loss: 3.3876e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 74/100\n",
      "1076/1076 - 9s - loss: 3.0193e-05 - val_loss: 3.3772e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 75/100\n",
      "1076/1076 - 9s - loss: 3.0011e-05 - val_loss: 3.3652e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 76/100\n",
      "1076/1076 - 9s - loss: 2.9825e-05 - val_loss: 3.3516e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 77/100\n",
      "1076/1076 - 9s - loss: 2.9634e-05 - val_loss: 3.3381e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 78/100\n",
      "1076/1076 - 9s - loss: 2.9443e-05 - val_loss: 3.3277e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 79/100\n",
      "1076/1076 - 9s - loss: 2.9258e-05 - val_loss: 3.3223e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 80/100\n",
      "1076/1076 - 9s - loss: 2.9084e-05 - val_loss: 3.3216e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 81/100\n",
      "1076/1076 - 9s - loss: 2.8925e-05 - val_loss: 3.3251e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 82/100\n",
      "1076/1076 - 9s - loss: 2.8779e-05 - val_loss: 3.3308e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 83/100\n",
      "1076/1076 - 9s - loss: 2.8648e-05 - val_loss: 3.3371e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 84/100\n",
      "1076/1076 - 9s - loss: 2.8527e-05 - val_loss: 3.3421e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 85/100\n",
      "1076/1076 - 9s - loss: 2.8415e-05 - val_loss: 3.3448e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 86/100\n",
      "1076/1076 - 9s - loss: 2.8307e-05 - val_loss: 3.3449e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 87/100\n",
      "1076/1076 - 9s - loss: 2.8201e-05 - val_loss: 3.3427e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 88/100\n",
      "1076/1076 - 9s - loss: 2.8093e-05 - val_loss: 3.3384e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 89/100\n",
      "1076/1076 - 9s - loss: 2.7982e-05 - val_loss: 3.3323e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 90/100\n",
      "1076/1076 - 9s - loss: 2.7871e-05 - val_loss: 3.3263e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 91/100\n",
      "1076/1076 - 9s - loss: 2.7766e-05 - val_loss: 3.3221e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 92/100\n",
      "1076/1076 - 9s - loss: 2.7667e-05 - val_loss: 3.3191e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 93/100\n",
      "1076/1076 - 9s - loss: 2.7575e-05 - val_loss: 3.3169e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 94/100\n",
      "1076/1076 - 9s - loss: 2.7487e-05 - val_loss: 3.3136e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 95/100\n",
      "1076/1076 - 9s - loss: 2.7404e-05 - val_loss: 3.3091e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 96/100\n",
      "1076/1076 - 9s - loss: 2.7323e-05 - val_loss: 3.3022e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 97/100\n",
      "1076/1076 - 9s - loss: 2.7245e-05 - val_loss: 3.2936e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 98/100\n",
      "1076/1076 - 9s - loss: 2.7168e-05 - val_loss: 3.2827e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 99/100\n",
      "1076/1076 - 9s - loss: 2.7094e-05 - val_loss: 3.2704e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 100/100\n",
      "1076/1076 - 9s - loss: 2.7019e-05 - val_loss: 3.2566e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 02:56:36.208130: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:56:36.297328: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:56:36.428855: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:56:45.090840: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 02:56:45.123675: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 - 11s - loss: 3.3426e-04 - val_loss: 0.0071 - 11s/epoch - 10ms/step\n",
      "Epoch 2/100\n",
      "1076/1076 - 9s - loss: 2.6643e-04 - val_loss: 0.0271 - 9s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "1076/1076 - 9s - loss: 5.6230e-04 - val_loss: 0.0227 - 9s/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "1076/1076 - 9s - loss: 8.1784e-04 - val_loss: 0.0191 - 9s/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "1076/1076 - 9s - loss: 6.7835e-04 - val_loss: 0.0149 - 9s/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "1076/1076 - 9s - loss: 5.3912e-04 - val_loss: 0.0098 - 9s/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "1076/1076 - 9s - loss: 4.1425e-04 - val_loss: 0.0063 - 9s/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "1076/1076 - 9s - loss: 3.1778e-04 - val_loss: 0.0041 - 9s/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "1076/1076 - 9s - loss: 2.4531e-04 - val_loss: 0.0029 - 9s/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "1076/1076 - 9s - loss: 1.9256e-04 - val_loss: 0.0024 - 9s/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "1076/1076 - 9s - loss: 1.5831e-04 - val_loss: 0.0022 - 9s/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "1076/1076 - 9s - loss: 1.3759e-04 - val_loss: 0.0021 - 9s/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "1076/1076 - 9s - loss: 1.2352e-04 - val_loss: 0.0019 - 9s/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "1076/1076 - 9s - loss: 1.1388e-04 - val_loss: 0.0016 - 9s/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "1076/1076 - 9s - loss: 1.0675e-04 - val_loss: 0.0013 - 9s/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "1076/1076 - 9s - loss: 1.0168e-04 - val_loss: 0.0011 - 9s/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "1076/1076 - 9s - loss: 9.7277e-05 - val_loss: 8.3994e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "1076/1076 - 9s - loss: 9.2387e-05 - val_loss: 6.8584e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "1076/1076 - 9s - loss: 8.7875e-05 - val_loss: 6.0995e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "1076/1076 - 9s - loss: 8.4050e-05 - val_loss: 5.6039e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "1076/1076 - 9s - loss: 8.0377e-05 - val_loss: 5.1375e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "1076/1076 - 9s - loss: 7.6407e-05 - val_loss: 4.8123e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "1076/1076 - 9s - loss: 7.2260e-05 - val_loss: 4.6286e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "1076/1076 - 9s - loss: 6.8427e-05 - val_loss: 4.6501e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "1076/1076 - 9s - loss: 6.5130e-05 - val_loss: 4.7055e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "1076/1076 - 9s - loss: 6.2473e-05 - val_loss: 4.7478e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "1076/1076 - 9s - loss: 6.0314e-05 - val_loss: 4.7292e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "1076/1076 - 9s - loss: 5.8362e-05 - val_loss: 4.7205e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "1076/1076 - 9s - loss: 5.6543e-05 - val_loss: 4.6987e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "1076/1076 - 9s - loss: 5.5066e-05 - val_loss: 4.6959e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "1076/1076 - 9s - loss: 5.3913e-05 - val_loss: 4.5935e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "1076/1076 - 9s - loss: 5.2486e-05 - val_loss: 4.5593e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "1076/1076 - 9s - loss: 5.1312e-05 - val_loss: 4.4868e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "1076/1076 - 9s - loss: 5.0029e-05 - val_loss: 4.4603e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "1076/1076 - 9s - loss: 4.8992e-05 - val_loss: 4.4235e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "1076/1076 - 9s - loss: 4.7931e-05 - val_loss: 4.4122e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "1076/1076 - 9s - loss: 4.7059e-05 - val_loss: 4.3766e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "1076/1076 - 9s - loss: 4.6221e-05 - val_loss: 4.3506e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "1076/1076 - 9s - loss: 4.5428e-05 - val_loss: 4.2921e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "1076/1076 - 9s - loss: 4.4604e-05 - val_loss: 4.2526e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "1076/1076 - 9s - loss: 4.3837e-05 - val_loss: 4.2295e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "1076/1076 - 9s - loss: 4.3249e-05 - val_loss: 4.1735e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "1076/1076 - 9s - loss: 4.2620e-05 - val_loss: 4.1231e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "1076/1076 - 9s - loss: 4.1911e-05 - val_loss: 4.0940e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "1076/1076 - 9s - loss: 4.1501e-05 - val_loss: 4.0609e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "1076/1076 - 9s - loss: 4.0982e-05 - val_loss: 4.0127e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "1076/1076 - 9s - loss: 4.0480e-05 - val_loss: 3.9723e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "1076/1076 - 9s - loss: 4.0043e-05 - val_loss: 3.9292e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "1076/1076 - 9s - loss: 3.9615e-05 - val_loss: 3.8842e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "1076/1076 - 9s - loss: 3.9199e-05 - val_loss: 3.8365e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "1076/1076 - 9s - loss: 3.8774e-05 - val_loss: 3.7864e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "1076/1076 - 9s - loss: 3.8352e-05 - val_loss: 3.7392e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "1076/1076 - 9s - loss: 3.7952e-05 - val_loss: 3.6876e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "1076/1076 - 9s - loss: 3.7531e-05 - val_loss: 3.6435e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 55/100\n",
      "1076/1076 - 9s - loss: 3.7140e-05 - val_loss: 3.6031e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 56/100\n",
      "1076/1076 - 9s - loss: 3.6762e-05 - val_loss: 3.5654e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "1076/1076 - 9s - loss: 3.6389e-05 - val_loss: 3.5295e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "1076/1076 - 9s - loss: 3.6045e-05 - val_loss: 3.4961e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "1076/1076 - 9s - loss: 3.5706e-05 - val_loss: 3.4623e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 60/100\n",
      "1076/1076 - 9s - loss: 3.5380e-05 - val_loss: 3.4286e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 61/100\n",
      "1076/1076 - 9s - loss: 3.5058e-05 - val_loss: 3.3954e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 62/100\n",
      "1076/1076 - 9s - loss: 3.4750e-05 - val_loss: 3.3622e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 63/100\n",
      "1076/1076 - 9s - loss: 3.4446e-05 - val_loss: 3.3288e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 64/100\n",
      "1076/1076 - 9s - loss: 3.4147e-05 - val_loss: 3.2943e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 65/100\n",
      "1076/1076 - 9s - loss: 3.3848e-05 - val_loss: 3.2592e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 66/100\n",
      "1076/1076 - 9s - loss: 3.3550e-05 - val_loss: 3.2249e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 67/100\n",
      "1076/1076 - 9s - loss: 3.3255e-05 - val_loss: 3.1926e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 68/100\n",
      "1076/1076 - 9s - loss: 3.2965e-05 - val_loss: 3.1629e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 69/100\n",
      "1076/1076 - 9s - loss: 3.2687e-05 - val_loss: 3.1374e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 70/100\n",
      "1076/1076 - 9s - loss: 3.2423e-05 - val_loss: 3.1141e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 71/100\n",
      "1076/1076 - 9s - loss: 3.2175e-05 - val_loss: 3.0928e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 72/100\n",
      "1076/1076 - 9s - loss: 3.1940e-05 - val_loss: 3.0708e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 73/100\n",
      "1076/1076 - 9s - loss: 3.1713e-05 - val_loss: 3.0480e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 74/100\n",
      "1076/1076 - 9s - loss: 3.1494e-05 - val_loss: 3.0235e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 75/100\n",
      "1076/1076 - 9s - loss: 3.1279e-05 - val_loss: 2.9991e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 76/100\n",
      "1076/1076 - 9s - loss: 3.1067e-05 - val_loss: 2.9748e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 77/100\n",
      "1076/1076 - 9s - loss: 3.0859e-05 - val_loss: 2.9515e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 78/100\n",
      "1076/1076 - 9s - loss: 3.0658e-05 - val_loss: 2.9299e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 79/100\n",
      "1076/1076 - 9s - loss: 3.0465e-05 - val_loss: 2.9094e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 80/100\n",
      "1076/1076 - 9s - loss: 3.0280e-05 - val_loss: 2.8896e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 81/100\n",
      "1076/1076 - 9s - loss: 3.0102e-05 - val_loss: 2.8695e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 82/100\n",
      "1076/1076 - 9s - loss: 2.9930e-05 - val_loss: 2.8497e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 83/100\n",
      "1076/1076 - 9s - loss: 2.9764e-05 - val_loss: 2.8291e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 84/100\n",
      "1076/1076 - 9s - loss: 2.9603e-05 - val_loss: 2.8083e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 85/100\n",
      "1076/1076 - 9s - loss: 2.9445e-05 - val_loss: 2.7871e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 86/100\n",
      "1076/1076 - 9s - loss: 2.9293e-05 - val_loss: 2.7659e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 87/100\n",
      "1076/1076 - 9s - loss: 2.9145e-05 - val_loss: 2.7452e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 88/100\n",
      "1076/1076 - 9s - loss: 2.9001e-05 - val_loss: 2.7242e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 89/100\n",
      "1076/1076 - 9s - loss: 2.8861e-05 - val_loss: 2.7030e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 90/100\n",
      "1076/1076 - 9s - loss: 2.8726e-05 - val_loss: 2.6828e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 91/100\n",
      "1076/1076 - 9s - loss: 2.8593e-05 - val_loss: 2.6613e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 92/100\n",
      "1076/1076 - 9s - loss: 2.8463e-05 - val_loss: 2.6407e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 93/100\n",
      "1076/1076 - 9s - loss: 2.8337e-05 - val_loss: 2.6194e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 94/100\n",
      "1076/1076 - 9s - loss: 2.8213e-05 - val_loss: 2.5989e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 95/100\n",
      "1076/1076 - 9s - loss: 2.8092e-05 - val_loss: 2.5779e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 96/100\n",
      "1076/1076 - 9s - loss: 2.7973e-05 - val_loss: 2.5573e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 97/100\n",
      "1076/1076 - 9s - loss: 2.7855e-05 - val_loss: 2.5364e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 98/100\n",
      "1076/1076 - 9s - loss: 2.7740e-05 - val_loss: 2.5162e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 99/100\n",
      "1076/1076 - 9s - loss: 2.7626e-05 - val_loss: 2.4957e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 100/100\n",
      "1076/1076 - 9s - loss: 2.7514e-05 - val_loss: 2.4762e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 03:11:53.345727: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:11:53.424218: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:11:53.575065: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:12:02.031631: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:12:02.062729: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 - 10s - loss: 1.9147e-04 - val_loss: 0.0040 - 10s/epoch - 10ms/step\n",
      "Epoch 2/100\n",
      "1076/1076 - 9s - loss: 1.8702e-04 - val_loss: 0.0094 - 9s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "1076/1076 - 9s - loss: 2.4405e-04 - val_loss: 0.0171 - 9s/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "1076/1076 - 9s - loss: 4.9874e-04 - val_loss: 0.0324 - 9s/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "1076/1076 - 9s - loss: 8.3227e-04 - val_loss: 0.0181 - 9s/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "1076/1076 - 9s - loss: 7.0369e-04 - val_loss: 0.0124 - 9s/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "1076/1076 - 9s - loss: 5.2471e-04 - val_loss: 0.0082 - 9s/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "1076/1076 - 9s - loss: 3.7981e-04 - val_loss: 0.0055 - 9s/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "1076/1076 - 9s - loss: 2.7358e-04 - val_loss: 0.0041 - 9s/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "1076/1076 - 9s - loss: 2.0196e-04 - val_loss: 0.0037 - 9s/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "1076/1076 - 9s - loss: 1.5841e-04 - val_loss: 0.0037 - 9s/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "1076/1076 - 9s - loss: 1.3114e-04 - val_loss: 0.0036 - 9s/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "1076/1076 - 9s - loss: 1.2233e-04 - val_loss: 0.0038 - 9s/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "1076/1076 - 9s - loss: 1.2286e-04 - val_loss: 0.0030 - 9s/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "1076/1076 - 9s - loss: 1.2629e-04 - val_loss: 0.0022 - 9s/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "1076/1076 - 9s - loss: 1.3537e-04 - val_loss: 0.0013 - 9s/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "1076/1076 - 9s - loss: 1.3792e-04 - val_loss: 7.2126e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "1076/1076 - 9s - loss: 1.2825e-04 - val_loss: 4.8734e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "1076/1076 - 9s - loss: 1.1315e-04 - val_loss: 3.6802e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "1076/1076 - 9s - loss: 1.0027e-04 - val_loss: 3.5598e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "1076/1076 - 9s - loss: 9.1474e-05 - val_loss: 3.5960e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "1076/1076 - 9s - loss: 8.4924e-05 - val_loss: 3.6277e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "1076/1076 - 9s - loss: 8.1385e-05 - val_loss: 3.4054e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "1076/1076 - 9s - loss: 7.9709e-05 - val_loss: 3.0639e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "1076/1076 - 9s - loss: 7.7931e-05 - val_loss: 2.6426e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "1076/1076 - 9s - loss: 7.5783e-05 - val_loss: 2.3665e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "1076/1076 - 9s - loss: 7.2895e-05 - val_loss: 2.1814e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "1076/1076 - 9s - loss: 6.9804e-05 - val_loss: 2.1163e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "1076/1076 - 9s - loss: 6.6568e-05 - val_loss: 2.1052e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "1076/1076 - 9s - loss: 6.3462e-05 - val_loss: 2.1273e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "1076/1076 - 9s - loss: 6.0720e-05 - val_loss: 2.1715e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "1076/1076 - 9s - loss: 5.8176e-05 - val_loss: 2.2384e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "1076/1076 - 9s - loss: 5.5803e-05 - val_loss: 2.3221e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "1076/1076 - 9s - loss: 5.3443e-05 - val_loss: 2.4274e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "1076/1076 - 9s - loss: 5.1013e-05 - val_loss: 2.5475e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "1076/1076 - 9s - loss: 4.8560e-05 - val_loss: 2.6754e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "1076/1076 - 9s - loss: 4.6312e-05 - val_loss: 2.7963e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "1076/1076 - 9s - loss: 4.4507e-05 - val_loss: 2.8790e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "1076/1076 - 9s - loss: 4.2996e-05 - val_loss: 2.9299e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "1076/1076 - 9s - loss: 4.1859e-05 - val_loss: 2.9626e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "1076/1076 - 9s - loss: 4.1079e-05 - val_loss: 3.0040e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "1076/1076 - 9s - loss: 4.0590e-05 - val_loss: 3.0582e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "1076/1076 - 9s - loss: 4.0350e-05 - val_loss: 3.0817e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "1076/1076 - 9s - loss: 4.0124e-05 - val_loss: 3.0715e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "1076/1076 - 9s - loss: 3.9945e-05 - val_loss: 3.0231e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "1076/1076 - 9s - loss: 3.9625e-05 - val_loss: 2.9696e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "1076/1076 - 9s - loss: 3.9253e-05 - val_loss: 2.9216e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "1076/1076 - 9s - loss: 3.8823e-05 - val_loss: 2.8788e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "1076/1076 - 9s - loss: 3.8352e-05 - val_loss: 2.8399e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "1076/1076 - 9s - loss: 3.7803e-05 - val_loss: 2.8114e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "1076/1076 - 9s - loss: 3.7280e-05 - val_loss: 2.7936e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "1076/1076 - 9s - loss: 3.6761e-05 - val_loss: 2.7842e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "1076/1076 - 9s - loss: 3.6278e-05 - val_loss: 2.7821e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "1076/1076 - 9s - loss: 3.5836e-05 - val_loss: 2.7863e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "1076/1076 - 9s - loss: 3.5423e-05 - val_loss: 2.7959e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "1076/1076 - 9s - loss: 3.5060e-05 - val_loss: 2.8090e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "1076/1076 - 9s - loss: 3.4718e-05 - val_loss: 2.8222e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "1076/1076 - 9s - loss: 3.4393e-05 - val_loss: 2.8357e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "1076/1076 - 9s - loss: 3.4096e-05 - val_loss: 2.8488e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 60/100\n",
      "1076/1076 - 9s - loss: 3.3822e-05 - val_loss: 2.8606e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 61/100\n",
      "1076/1076 - 9s - loss: 3.3552e-05 - val_loss: 2.8710e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "1076/1076 - 9s - loss: 3.3289e-05 - val_loss: 2.8830e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "1076/1076 - 9s - loss: 3.3037e-05 - val_loss: 2.8977e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 64/100\n",
      "1076/1076 - 9s - loss: 3.2820e-05 - val_loss: 2.9113e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 65/100\n",
      "1076/1076 - 9s - loss: 3.2607e-05 - val_loss: 2.9241e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 66/100\n",
      "1076/1076 - 9s - loss: 3.2404e-05 - val_loss: 2.9339e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 67/100\n",
      "1076/1076 - 9s - loss: 3.2213e-05 - val_loss: 2.9417e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 68/100\n",
      "1076/1076 - 9s - loss: 3.2024e-05 - val_loss: 2.9466e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 69/100\n",
      "1076/1076 - 9s - loss: 3.1845e-05 - val_loss: 2.9501e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 70/100\n",
      "1076/1076 - 9s - loss: 3.1670e-05 - val_loss: 2.9509e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 71/100\n",
      "1076/1076 - 9s - loss: 3.1500e-05 - val_loss: 2.9506e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 72/100\n",
      "1076/1076 - 9s - loss: 3.1335e-05 - val_loss: 2.9497e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 73/100\n",
      "1076/1076 - 9s - loss: 3.1177e-05 - val_loss: 2.9481e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 74/100\n",
      "1076/1076 - 9s - loss: 3.1025e-05 - val_loss: 2.9454e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 75/100\n",
      "1076/1076 - 9s - loss: 3.0879e-05 - val_loss: 2.9413e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 76/100\n",
      "1076/1076 - 9s - loss: 3.0740e-05 - val_loss: 2.9355e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 77/100\n",
      "1076/1076 - 9s - loss: 3.0606e-05 - val_loss: 2.9278e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 78/100\n",
      "1076/1076 - 9s - loss: 3.0474e-05 - val_loss: 2.9176e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 79/100\n",
      "1076/1076 - 9s - loss: 3.0343e-05 - val_loss: 2.9054e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 80/100\n",
      "1076/1076 - 9s - loss: 3.0212e-05 - val_loss: 2.8924e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 81/100\n",
      "1076/1076 - 9s - loss: 3.0082e-05 - val_loss: 2.8794e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 82/100\n",
      "1076/1076 - 9s - loss: 2.9954e-05 - val_loss: 2.8673e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 83/100\n",
      "1076/1076 - 9s - loss: 2.9831e-05 - val_loss: 2.8552e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 84/100\n",
      "1076/1076 - 9s - loss: 2.9709e-05 - val_loss: 2.8439e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 85/100\n",
      "1076/1076 - 9s - loss: 2.9592e-05 - val_loss: 2.8326e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 86/100\n",
      "1076/1076 - 9s - loss: 2.9475e-05 - val_loss: 2.8213e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 87/100\n",
      "1076/1076 - 9s - loss: 2.9356e-05 - val_loss: 2.8139e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 88/100\n",
      "1076/1076 - 9s - loss: 2.9256e-05 - val_loss: 2.8032e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 89/100\n",
      "1076/1076 - 9s - loss: 2.9145e-05 - val_loss: 2.7844e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 90/100\n",
      "1076/1076 - 9s - loss: 2.9022e-05 - val_loss: 2.7649e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 91/100\n",
      "1076/1076 - 9s - loss: 2.8895e-05 - val_loss: 2.7473e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 92/100\n",
      "1076/1076 - 9s - loss: 2.8769e-05 - val_loss: 2.7317e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 93/100\n",
      "1076/1076 - 9s - loss: 2.8644e-05 - val_loss: 2.7182e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 94/100\n",
      "1076/1076 - 9s - loss: 2.8522e-05 - val_loss: 2.7059e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 95/100\n",
      "1076/1076 - 9s - loss: 2.8402e-05 - val_loss: 2.6946e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 96/100\n",
      "1076/1076 - 9s - loss: 2.8284e-05 - val_loss: 2.6835e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 97/100\n",
      "1076/1076 - 9s - loss: 2.8168e-05 - val_loss: 2.6729e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 98/100\n",
      "1076/1076 - 9s - loss: 2.8054e-05 - val_loss: 2.6622e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 99/100\n",
      "1076/1076 - 9s - loss: 2.7942e-05 - val_loss: 2.6518e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 100/100\n",
      "1076/1076 - 9s - loss: 2.7832e-05 - val_loss: 2.6414e-04 - 9s/epoch - 8ms/step\n"
     ]
    }
   ],
   "source": [
    "lstms2 = []\n",
    "models2 = []\n",
    "for batch, epoch, neuron in hyperparam2:\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neuron, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(loss='mse',optimizer='adam')\n",
    "    lstm = model.fit(train_X, train_y, epochs=epoch, batch_size=batch, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    lstms2.append(lstm)\n",
    "    models2.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0ecec446-1f6b-4f7c-8a44-e9c3caf29c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 1s 3ms/step\n",
      "(32, 25, 50)\n",
      "Epoch: 25\n",
      "Neurons: 50\n",
      "RMSE\n",
      "980.5547854673822\n",
      "MAE\n",
      "761.2876975389521\n",
      "MAPE\n",
      "2.2077981987935926\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(32, 25, 60)\n",
      "Epoch: 25\n",
      "Neurons: 60\n",
      "RMSE\n",
      "896.833936413647\n",
      "MAE\n",
      "686.5859330693648\n",
      "MAPE\n",
      "1.9621323032192297\n",
      "269/269 [==============================] - 1s 4ms/step\n",
      "(32, 25, 100)\n",
      "Epoch: 25\n",
      "Neurons: 100\n",
      "RMSE\n",
      "933.2954722608376\n",
      "MAE\n",
      "731.5860040671937\n",
      "MAPE\n",
      "2.1610818398029483\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(32, 50, 50)\n",
      "Epoch: 50\n",
      "Neurons: 50\n",
      "RMSE\n",
      "1062.5704560609322\n",
      "MAE\n",
      "854.9749393059104\n",
      "MAPE\n",
      "2.5098219806553033\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(32, 50, 60)\n",
      "Epoch: 50\n",
      "Neurons: 60\n",
      "RMSE\n",
      "1186.7569953595523\n",
      "MAE\n",
      "944.6047545782122\n",
      "MAPE\n",
      "2.671194289522734\n",
      "269/269 [==============================] - 1s 4ms/step\n",
      "(32, 50, 100)\n",
      "Epoch: 50\n",
      "Neurons: 100\n",
      "RMSE\n",
      "1121.4648617677399\n",
      "MAE\n",
      "872.5610913060326\n",
      "MAPE\n",
      "2.430024494509788\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(32, 100, 50)\n",
      "Epoch: 100\n",
      "Neurons: 50\n",
      "RMSE\n",
      "1181.3326563077183\n",
      "MAE\n",
      "1013.3737220939455\n",
      "MAPE\n",
      "3.09979986010154\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(32, 100, 60)\n",
      "Epoch: 100\n",
      "Neurons: 60\n",
      "RMSE\n",
      "1030.10261199934\n",
      "MAE\n",
      "818.5528016985751\n",
      "MAPE\n",
      "2.345919375665689\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(32, 100, 100)\n",
      "Epoch: 100\n",
      "Neurons: 100\n",
      "RMSE\n",
      "1063.902729211534\n",
      "MAE\n",
      "862.9684000821552\n",
      "MAPE\n",
      "2.502368200451288\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "wb2 = Workbook()\n",
    "ws2 = wb2.active\n",
    "for x in models2:\n",
    "    # make a prediction\n",
    "    test_x2 = test_X\n",
    "    yhat = x.predict(test_x2)\n",
    "    inv_yhat = np.concatenate((np.zeros((len(yhat), 4)),yhat), axis=1)\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    test_y = test_y.reshape((len(test_y), 1))\n",
    "    inv_y = np.concatenate((np.zeros((len(yhat), 4)), test_y), axis=1)\n",
    "    inv_y = scaler.inverse_transform(inv_y)\n",
    "    yhat_df = pd.DataFrame(inv_yhat, columns = ['Open','High','Low', 'Volume', 'Close'])\n",
    "    y_df = pd.DataFrame(inv_y, columns = ['Open','High','Low', 'Volume', 'Close'])\n",
    "    print(hyperparam2[i])\n",
    "    print(\"Epoch: \"+ str(lstms2[i].params['epochs']))\n",
    "    print(\"Neurons: \"+str(x.layers[0].units))\n",
    "    i = i+1\n",
    "    ws2['A'+str(i)] = 'LSTM'\n",
    "    ws2['B'+str(i)] = hyperparam2[i-1][0]\n",
    "    ws2['C'+str(i)] = hyperparam2[i-1][1]\n",
    "    ws2['D'+str(i)] = hyperparam2[i-1][2]\n",
    "    print('RMSE')\n",
    "    print(RMSE(y_df['Close'],yhat_df['Close']))\n",
    "    ws2['E'+str(i)] = RMSE(y_df['Close'],yhat_df['Close'])\n",
    "    print('MAE')\n",
    "    print(MAE(y_df['Close'],yhat_df['Close']))\n",
    "    ws2['F'+str(i)] = MAE(y_df['Close'],yhat_df['Close'])\n",
    "    print('MAPE')\n",
    "    print(MAPE(y_df['Close'],yhat_df['Close']))\n",
    "    ws2['G'+str(i)] = MAPE(y_df['Close'],yhat_df['Close'])\n",
    "wb2.save('LSTMresult2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "784abd2d-2770-44d6-b780-c4229562b49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 03:27:04.147966: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:27:04.240069: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:27:04.425925: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:27:09.173385: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:27:09.207147: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/538 - 6s - loss: 3.9330e-04 - val_loss: 0.0052 - 6s/epoch - 12ms/step\n",
      "Epoch 2/25\n",
      "538/538 - 5s - loss: 4.2440e-04 - val_loss: 0.0043 - 5s/epoch - 8ms/step\n",
      "Epoch 3/25\n",
      "538/538 - 5s - loss: 4.8570e-04 - val_loss: 0.0089 - 5s/epoch - 8ms/step\n",
      "Epoch 4/25\n",
      "538/538 - 5s - loss: 4.4922e-04 - val_loss: 0.0081 - 5s/epoch - 8ms/step\n",
      "Epoch 5/25\n",
      "538/538 - 5s - loss: 3.6531e-04 - val_loss: 0.0063 - 5s/epoch - 8ms/step\n",
      "Epoch 6/25\n",
      "538/538 - 4s - loss: 2.9246e-04 - val_loss: 0.0048 - 4s/epoch - 8ms/step\n",
      "Epoch 7/25\n",
      "538/538 - 4s - loss: 2.3667e-04 - val_loss: 0.0037 - 4s/epoch - 8ms/step\n",
      "Epoch 8/25\n",
      "538/538 - 4s - loss: 2.0128e-04 - val_loss: 0.0030 - 4s/epoch - 8ms/step\n",
      "Epoch 9/25\n",
      "538/538 - 4s - loss: 1.8272e-04 - val_loss: 0.0026 - 4s/epoch - 8ms/step\n",
      "Epoch 10/25\n",
      "538/538 - 4s - loss: 1.7519e-04 - val_loss: 0.0024 - 4s/epoch - 8ms/step\n",
      "Epoch 11/25\n",
      "538/538 - 4s - loss: 1.7100e-04 - val_loss: 0.0023 - 4s/epoch - 8ms/step\n",
      "Epoch 12/25\n",
      "538/538 - 4s - loss: 1.6718e-04 - val_loss: 0.0022 - 4s/epoch - 8ms/step\n",
      "Epoch 13/25\n",
      "538/538 - 4s - loss: 1.6126e-04 - val_loss: 0.0021 - 4s/epoch - 8ms/step\n",
      "Epoch 14/25\n",
      "538/538 - 4s - loss: 1.5083e-04 - val_loss: 0.0019 - 4s/epoch - 8ms/step\n",
      "Epoch 15/25\n",
      "538/538 - 4s - loss: 1.4164e-04 - val_loss: 0.0017 - 4s/epoch - 8ms/step\n",
      "Epoch 16/25\n",
      "538/538 - 4s - loss: 1.3409e-04 - val_loss: 0.0015 - 4s/epoch - 8ms/step\n",
      "Epoch 17/25\n",
      "538/538 - 4s - loss: 1.2753e-04 - val_loss: 0.0014 - 4s/epoch - 8ms/step\n",
      "Epoch 18/25\n",
      "538/538 - 4s - loss: 1.2263e-04 - val_loss: 0.0013 - 4s/epoch - 8ms/step\n",
      "Epoch 19/25\n",
      "538/538 - 4s - loss: 1.1462e-04 - val_loss: 0.0012 - 4s/epoch - 8ms/step\n",
      "Epoch 20/25\n",
      "538/538 - 4s - loss: 1.0786e-04 - val_loss: 0.0011 - 4s/epoch - 8ms/step\n",
      "Epoch 21/25\n",
      "538/538 - 5s - loss: 1.0225e-04 - val_loss: 9.5660e-04 - 5s/epoch - 8ms/step\n",
      "Epoch 22/25\n",
      "538/538 - 4s - loss: 9.7028e-05 - val_loss: 8.6271e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 23/25\n",
      "538/538 - 4s - loss: 9.1012e-05 - val_loss: 7.7285e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 24/25\n",
      "538/538 - 5s - loss: 8.3603e-05 - val_loss: 6.7309e-04 - 5s/epoch - 8ms/step\n",
      "Epoch 25/25\n",
      "538/538 - 5s - loss: 7.6412e-05 - val_loss: 5.7086e-04 - 5s/epoch - 8ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 03:28:58.265191: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:28:58.351076: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:28:58.642393: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:29:03.572551: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:29:03.603979: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/538 - 6s - loss: 2.3796e-04 - val_loss: 9.5514e-04 - 6s/epoch - 12ms/step\n",
      "Epoch 2/25\n",
      "538/538 - 5s - loss: 2.0871e-04 - val_loss: 0.0076 - 5s/epoch - 9ms/step\n",
      "Epoch 3/25\n",
      "538/538 - 5s - loss: 4.4867e-04 - val_loss: 0.0031 - 5s/epoch - 9ms/step\n",
      "Epoch 4/25\n",
      "538/538 - 5s - loss: 3.0250e-04 - val_loss: 0.0039 - 5s/epoch - 9ms/step\n",
      "Epoch 5/25\n",
      "538/538 - 5s - loss: 3.1320e-04 - val_loss: 0.0048 - 5s/epoch - 9ms/step\n",
      "Epoch 6/25\n",
      "538/538 - 5s - loss: 3.2179e-04 - val_loss: 0.0054 - 5s/epoch - 9ms/step\n",
      "Epoch 7/25\n",
      "538/538 - 5s - loss: 3.2502e-04 - val_loss: 0.0054 - 5s/epoch - 9ms/step\n",
      "Epoch 8/25\n",
      "538/538 - 5s - loss: 2.9454e-04 - val_loss: 0.0046 - 5s/epoch - 9ms/step\n",
      "Epoch 9/25\n",
      "538/538 - 5s - loss: 2.4670e-04 - val_loss: 0.0036 - 5s/epoch - 9ms/step\n",
      "Epoch 10/25\n",
      "538/538 - 5s - loss: 2.0935e-04 - val_loss: 0.0029 - 5s/epoch - 9ms/step\n",
      "Epoch 11/25\n",
      "538/538 - 5s - loss: 1.8634e-04 - val_loss: 0.0024 - 5s/epoch - 9ms/step\n",
      "Epoch 12/25\n",
      "538/538 - 5s - loss: 1.6850e-04 - val_loss: 0.0021 - 5s/epoch - 9ms/step\n",
      "Epoch 13/25\n",
      "538/538 - 5s - loss: 1.5338e-04 - val_loss: 0.0019 - 5s/epoch - 9ms/step\n",
      "Epoch 14/25\n",
      "538/538 - 5s - loss: 1.4262e-04 - val_loss: 0.0017 - 5s/epoch - 9ms/step\n",
      "Epoch 15/25\n",
      "538/538 - 5s - loss: 1.3536e-04 - val_loss: 0.0015 - 5s/epoch - 9ms/step\n",
      "Epoch 16/25\n",
      "538/538 - 5s - loss: 1.2669e-04 - val_loss: 0.0014 - 5s/epoch - 9ms/step\n",
      "Epoch 17/25\n",
      "538/538 - 5s - loss: 1.1676e-04 - val_loss: 0.0012 - 5s/epoch - 9ms/step\n",
      "Epoch 18/25\n",
      "538/538 - 5s - loss: 1.0685e-04 - val_loss: 0.0011 - 5s/epoch - 9ms/step\n",
      "Epoch 19/25\n",
      "538/538 - 5s - loss: 9.7785e-05 - val_loss: 9.3925e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 20/25\n",
      "538/538 - 5s - loss: 8.7367e-05 - val_loss: 7.8811e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 21/25\n",
      "538/538 - 5s - loss: 7.6175e-05 - val_loss: 6.3079e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 22/25\n",
      "538/538 - 5s - loss: 6.4849e-05 - val_loss: 4.7365e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 23/25\n",
      "538/538 - 5s - loss: 5.3081e-05 - val_loss: 3.2598e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 24/25\n",
      "538/538 - 5s - loss: 4.1111e-05 - val_loss: 2.1067e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 25/25\n",
      "538/538 - 5s - loss: 2.9917e-05 - val_loss: 1.8037e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 03:30:58.993599: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:30:59.083760: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:30:59.244953: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:31:04.219018: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:31:04.248075: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/538 - 6s - loss: 2.9214e-04 - val_loss: 0.0011 - 6s/epoch - 12ms/step\n",
      "Epoch 2/25\n",
      "538/538 - 5s - loss: 2.4346e-04 - val_loss: 0.0107 - 5s/epoch - 9ms/step\n",
      "Epoch 3/25\n",
      "538/538 - 5s - loss: 5.9315e-04 - val_loss: 0.0062 - 5s/epoch - 9ms/step\n",
      "Epoch 4/25\n",
      "538/538 - 5s - loss: 5.2218e-04 - val_loss: 0.0105 - 5s/epoch - 9ms/step\n",
      "Epoch 5/25\n",
      "538/538 - 5s - loss: 5.6502e-04 - val_loss: 0.0102 - 5s/epoch - 9ms/step\n",
      "Epoch 6/25\n",
      "538/538 - 5s - loss: 4.7788e-04 - val_loss: 0.0079 - 5s/epoch - 9ms/step\n",
      "Epoch 7/25\n",
      "538/538 - 5s - loss: 3.6292e-04 - val_loss: 0.0057 - 5s/epoch - 9ms/step\n",
      "Epoch 8/25\n",
      "538/538 - 5s - loss: 2.7009e-04 - val_loss: 0.0039 - 5s/epoch - 9ms/step\n",
      "Epoch 9/25\n",
      "538/538 - 5s - loss: 2.0275e-04 - val_loss: 0.0028 - 5s/epoch - 9ms/step\n",
      "Epoch 10/25\n",
      "538/538 - 5s - loss: 1.7431e-04 - val_loss: 0.0023 - 5s/epoch - 9ms/step\n",
      "Epoch 11/25\n",
      "538/538 - 5s - loss: 1.6425e-04 - val_loss: 0.0020 - 5s/epoch - 9ms/step\n",
      "Epoch 12/25\n",
      "538/538 - 5s - loss: 1.6338e-04 - val_loss: 0.0020 - 5s/epoch - 9ms/step\n",
      "Epoch 13/25\n",
      "538/538 - 5s - loss: 1.6858e-04 - val_loss: 0.0020 - 5s/epoch - 9ms/step\n",
      "Epoch 14/25\n",
      "538/538 - 5s - loss: 1.6361e-04 - val_loss: 0.0020 - 5s/epoch - 9ms/step\n",
      "Epoch 15/25\n",
      "538/538 - 5s - loss: 1.5618e-04 - val_loss: 0.0018 - 5s/epoch - 9ms/step\n",
      "Epoch 16/25\n",
      "538/538 - 5s - loss: 1.4490e-04 - val_loss: 0.0017 - 5s/epoch - 9ms/step\n",
      "Epoch 17/25\n",
      "538/538 - 5s - loss: 1.3249e-04 - val_loss: 0.0014 - 5s/epoch - 9ms/step\n",
      "Epoch 18/25\n",
      "538/538 - 5s - loss: 1.1896e-04 - val_loss: 0.0013 - 5s/epoch - 9ms/step\n",
      "Epoch 19/25\n",
      "538/538 - 5s - loss: 1.0773e-04 - val_loss: 0.0011 - 5s/epoch - 9ms/step\n",
      "Epoch 20/25\n",
      "538/538 - 5s - loss: 9.4713e-05 - val_loss: 8.8515e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 21/25\n",
      "538/538 - 5s - loss: 8.0868e-05 - val_loss: 6.9281e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 22/25\n",
      "538/538 - 5s - loss: 6.7108e-05 - val_loss: 4.9938e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 23/25\n",
      "538/538 - 5s - loss: 5.2497e-05 - val_loss: 3.2190e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 24/25\n",
      "538/538 - 5s - loss: 3.8561e-05 - val_loss: 2.1341e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 25/25\n",
      "538/538 - 5s - loss: 2.6433e-05 - val_loss: 2.2559e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 03:33:04.987464: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:33:05.065288: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:33:05.223395: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:33:09.812469: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:33:09.846641: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/538 - 6s - loss: 3.2900e-04 - val_loss: 0.0046 - 6s/epoch - 11ms/step\n",
      "Epoch 2/50\n",
      "538/538 - 5s - loss: 3.6996e-04 - val_loss: 0.0040 - 5s/epoch - 9ms/step\n",
      "Epoch 3/50\n",
      "538/538 - 4s - loss: 3.5229e-04 - val_loss: 0.0064 - 4s/epoch - 8ms/step\n",
      "Epoch 4/50\n",
      "538/538 - 4s - loss: 3.4010e-04 - val_loss: 0.0064 - 4s/epoch - 8ms/step\n",
      "Epoch 5/50\n",
      "538/538 - 4s - loss: 3.0473e-04 - val_loss: 0.0052 - 4s/epoch - 8ms/step\n",
      "Epoch 6/50\n",
      "538/538 - 4s - loss: 2.5065e-04 - val_loss: 0.0041 - 4s/epoch - 8ms/step\n",
      "Epoch 7/50\n",
      "538/538 - 4s - loss: 2.0677e-04 - val_loss: 0.0031 - 4s/epoch - 8ms/step\n",
      "Epoch 8/50\n",
      "538/538 - 5s - loss: 1.7559e-04 - val_loss: 0.0025 - 5s/epoch - 9ms/step\n",
      "Epoch 9/50\n",
      "538/538 - 4s - loss: 1.5723e-04 - val_loss: 0.0020 - 4s/epoch - 8ms/step\n",
      "Epoch 10/50\n",
      "538/538 - 5s - loss: 1.4634e-04 - val_loss: 0.0018 - 5s/epoch - 9ms/step\n",
      "Epoch 11/50\n",
      "538/538 - 5s - loss: 1.4164e-04 - val_loss: 0.0017 - 5s/epoch - 8ms/step\n",
      "Epoch 12/50\n",
      "538/538 - 4s - loss: 1.3754e-04 - val_loss: 0.0016 - 4s/epoch - 8ms/step\n",
      "Epoch 13/50\n",
      "538/538 - 4s - loss: 1.3453e-04 - val_loss: 0.0015 - 4s/epoch - 8ms/step\n",
      "Epoch 14/50\n",
      "538/538 - 5s - loss: 1.3001e-04 - val_loss: 0.0014 - 5s/epoch - 8ms/step\n",
      "Epoch 15/50\n",
      "538/538 - 4s - loss: 1.2413e-04 - val_loss: 0.0013 - 4s/epoch - 8ms/step\n",
      "Epoch 16/50\n",
      "538/538 - 4s - loss: 1.1830e-04 - val_loss: 0.0012 - 4s/epoch - 8ms/step\n",
      "Epoch 17/50\n",
      "538/538 - 4s - loss: 1.1286e-04 - val_loss: 0.0011 - 4s/epoch - 8ms/step\n",
      "Epoch 18/50\n",
      "538/538 - 4s - loss: 1.0754e-04 - val_loss: 0.0010 - 4s/epoch - 8ms/step\n",
      "Epoch 19/50\n",
      "538/538 - 4s - loss: 1.0226e-04 - val_loss: 9.2441e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 20/50\n",
      "538/538 - 4s - loss: 9.7578e-05 - val_loss: 8.4927e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 21/50\n",
      "538/538 - 4s - loss: 9.2440e-05 - val_loss: 7.6728e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 22/50\n",
      "538/538 - 4s - loss: 8.6685e-05 - val_loss: 6.8887e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 23/50\n",
      "538/538 - 4s - loss: 8.0804e-05 - val_loss: 6.1153e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 24/50\n",
      "538/538 - 4s - loss: 7.3820e-05 - val_loss: 5.2108e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 25/50\n",
      "538/538 - 4s - loss: 6.5726e-05 - val_loss: 4.2191e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 26/50\n",
      "538/538 - 4s - loss: 5.6639e-05 - val_loss: 3.1882e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 27/50\n",
      "538/538 - 4s - loss: 4.6691e-05 - val_loss: 2.2064e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 28/50\n",
      "538/538 - 4s - loss: 3.6117e-05 - val_loss: 1.4761e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 29/50\n",
      "538/538 - 4s - loss: 2.6467e-05 - val_loss: 1.5840e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 30/50\n",
      "538/538 - 4s - loss: 2.3085e-05 - val_loss: 2.4615e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 31/50\n",
      "538/538 - 4s - loss: 2.7147e-05 - val_loss: 4.3210e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 32/50\n",
      "538/538 - 4s - loss: 4.0605e-05 - val_loss: 4.5133e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 33/50\n",
      "538/538 - 4s - loss: 4.8284e-05 - val_loss: 1.3360e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 34/50\n",
      "538/538 - 4s - loss: 2.9204e-05 - val_loss: 8.5482e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 35/50\n",
      "538/538 - 4s - loss: 1.9742e-05 - val_loss: 1.2558e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 36/50\n",
      "538/538 - 4s - loss: 1.8348e-05 - val_loss: 2.3245e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 37/50\n",
      "538/538 - 4s - loss: 2.3846e-05 - val_loss: 5.3756e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 38/50\n",
      "538/538 - 4s - loss: 4.5821e-05 - val_loss: 4.6461e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 39/50\n",
      "538/538 - 4s - loss: 5.0973e-05 - val_loss: 1.0520e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 40/50\n",
      "538/538 - 4s - loss: 2.9196e-05 - val_loss: 6.3078e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 41/50\n",
      "538/538 - 4s - loss: 2.0438e-05 - val_loss: 8.0188e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 42/50\n",
      "538/538 - 4s - loss: 1.6826e-05 - val_loss: 1.3932e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 43/50\n",
      "538/538 - 4s - loss: 1.7254e-05 - val_loss: 2.5980e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 44/50\n",
      "538/538 - 4s - loss: 2.4385e-05 - val_loss: 6.1689e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 45/50\n",
      "538/538 - 4s - loss: 4.9576e-05 - val_loss: 3.2950e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 46/50\n",
      "538/538 - 4s - loss: 4.5741e-05 - val_loss: 9.0400e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 47/50\n",
      "538/538 - 4s - loss: 2.8065e-05 - val_loss: 5.5029e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 48/50\n",
      "538/538 - 4s - loss: 2.0440e-05 - val_loss: 6.1340e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 49/50\n",
      "538/538 - 4s - loss: 1.6095e-05 - val_loss: 1.0295e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 50/50\n",
      "538/538 - 4s - loss: 1.5478e-05 - val_loss: 1.7385e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 03:36:50.292053: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:36:50.370812: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:36:50.516143: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:36:55.247646: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:36:55.276734: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/538 - 6s - loss: 5.7396e-04 - val_loss: 0.0044 - 6s/epoch - 11ms/step\n",
      "Epoch 2/50\n",
      "538/538 - 5s - loss: 3.9396e-04 - val_loss: 0.0042 - 5s/epoch - 9ms/step\n",
      "Epoch 3/50\n",
      "538/538 - 5s - loss: 5.3278e-04 - val_loss: 0.0100 - 5s/epoch - 9ms/step\n",
      "Epoch 4/50\n",
      "538/538 - 5s - loss: 4.4556e-04 - val_loss: 0.0073 - 5s/epoch - 9ms/step\n",
      "Epoch 5/50\n",
      "538/538 - 5s - loss: 3.3576e-04 - val_loss: 0.0056 - 5s/epoch - 9ms/step\n",
      "Epoch 6/50\n",
      "538/538 - 5s - loss: 2.6789e-04 - val_loss: 0.0043 - 5s/epoch - 9ms/step\n",
      "Epoch 7/50\n",
      "538/538 - 5s - loss: 2.2127e-04 - val_loss: 0.0033 - 5s/epoch - 9ms/step\n",
      "Epoch 8/50\n",
      "538/538 - 5s - loss: 1.9231e-04 - val_loss: 0.0027 - 5s/epoch - 9ms/step\n",
      "Epoch 9/50\n",
      "538/538 - 5s - loss: 1.7730e-04 - val_loss: 0.0023 - 5s/epoch - 9ms/step\n",
      "Epoch 10/50\n",
      "538/538 - 5s - loss: 1.7586e-04 - val_loss: 0.0022 - 5s/epoch - 9ms/step\n",
      "Epoch 11/50\n",
      "538/538 - 5s - loss: 1.6637e-04 - val_loss: 0.0021 - 5s/epoch - 9ms/step\n",
      "Epoch 12/50\n",
      "538/538 - 5s - loss: 1.6467e-04 - val_loss: 0.0020 - 5s/epoch - 9ms/step\n",
      "Epoch 13/50\n",
      "538/538 - 5s - loss: 1.6280e-04 - val_loss: 0.0020 - 5s/epoch - 9ms/step\n",
      "Epoch 14/50\n",
      "538/538 - 5s - loss: 1.5315e-04 - val_loss: 0.0018 - 5s/epoch - 9ms/step\n",
      "Epoch 15/50\n",
      "538/538 - 5s - loss: 1.4518e-04 - val_loss: 0.0017 - 5s/epoch - 9ms/step\n",
      "Epoch 16/50\n",
      "538/538 - 5s - loss: 1.3792e-04 - val_loss: 0.0015 - 5s/epoch - 9ms/step\n",
      "Epoch 17/50\n",
      "538/538 - 5s - loss: 1.3185e-04 - val_loss: 0.0014 - 5s/epoch - 9ms/step\n",
      "Epoch 18/50\n",
      "538/538 - 5s - loss: 1.2547e-04 - val_loss: 0.0013 - 5s/epoch - 9ms/step\n",
      "Epoch 19/50\n",
      "538/538 - 5s - loss: 1.1930e-04 - val_loss: 0.0012 - 5s/epoch - 9ms/step\n",
      "Epoch 20/50\n",
      "538/538 - 5s - loss: 1.1327e-04 - val_loss: 0.0011 - 5s/epoch - 9ms/step\n",
      "Epoch 21/50\n",
      "538/538 - 5s - loss: 1.0671e-04 - val_loss: 0.0010 - 5s/epoch - 9ms/step\n",
      "Epoch 22/50\n",
      "538/538 - 5s - loss: 9.9416e-05 - val_loss: 9.1060e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 23/50\n",
      "538/538 - 5s - loss: 9.2064e-05 - val_loss: 8.0851e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 24/50\n",
      "538/538 - 5s - loss: 8.4653e-05 - val_loss: 7.0747e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 25/50\n",
      "538/538 - 5s - loss: 7.7076e-05 - val_loss: 6.0488e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 26/50\n",
      "538/538 - 5s - loss: 6.8800e-05 - val_loss: 4.9747e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 27/50\n",
      "538/538 - 5s - loss: 6.0073e-05 - val_loss: 3.8950e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 28/50\n",
      "538/538 - 5s - loss: 5.0429e-05 - val_loss: 2.7864e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 29/50\n",
      "538/538 - 5s - loss: 3.9578e-05 - val_loss: 1.7833e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 30/50\n",
      "538/538 - 5s - loss: 2.8752e-05 - val_loss: 1.4477e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 31/50\n",
      "538/538 - 5s - loss: 2.1489e-05 - val_loss: 1.9652e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 32/50\n",
      "538/538 - 5s - loss: 2.2391e-05 - val_loss: 3.7457e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 33/50\n",
      "538/538 - 5s - loss: 3.6481e-05 - val_loss: 6.7106e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 34/50\n",
      "538/538 - 5s - loss: 5.7577e-05 - val_loss: 2.0995e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 35/50\n",
      "538/538 - 5s - loss: 3.5669e-05 - val_loss: 1.0208e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 36/50\n",
      "538/538 - 5s - loss: 2.3652e-05 - val_loss: 9.8781e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 37/50\n",
      "538/538 - 5s - loss: 1.7685e-05 - val_loss: 1.4876e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 38/50\n",
      "538/538 - 5s - loss: 1.8382e-05 - val_loss: 3.1061e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 39/50\n",
      "538/538 - 5s - loss: 3.0642e-05 - val_loss: 7.8838e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 40/50\n",
      "538/538 - 5s - loss: 5.9254e-05 - val_loss: 2.3708e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 41/50\n",
      "538/538 - 5s - loss: 3.9401e-05 - val_loss: 1.2237e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 42/50\n",
      "538/538 - 5s - loss: 2.7876e-05 - val_loss: 7.9106e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 43/50\n",
      "538/538 - 5s - loss: 1.9419e-05 - val_loss: 1.0073e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 44/50\n",
      "538/538 - 5s - loss: 1.6513e-05 - val_loss: 1.6659e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 45/50\n",
      "538/538 - 5s - loss: 1.8931e-05 - val_loss: 3.7570e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 46/50\n",
      "538/538 - 5s - loss: 3.5822e-05 - val_loss: 7.4291e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 47/50\n",
      "538/538 - 5s - loss: 5.5963e-05 - val_loss: 1.4839e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 48/50\n",
      "538/538 - 5s - loss: 3.0772e-05 - val_loss: 7.7610e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 49/50\n",
      "538/538 - 5s - loss: 2.1853e-05 - val_loss: 6.8195e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 50/50\n",
      "538/538 - 5s - loss: 1.6052e-05 - val_loss: 1.0239e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 03:40:47.992667: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:40:48.075237: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:40:48.224842: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:40:53.145513: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:40:53.177775: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/538 - 6s - loss: 4.6994e-04 - val_loss: 0.0013 - 6s/epoch - 12ms/step\n",
      "Epoch 2/50\n",
      "538/538 - 5s - loss: 2.3034e-04 - val_loss: 0.0095 - 5s/epoch - 9ms/step\n",
      "Epoch 3/50\n",
      "538/538 - 5s - loss: 5.2964e-04 - val_loss: 0.0046 - 5s/epoch - 9ms/step\n",
      "Epoch 4/50\n",
      "538/538 - 5s - loss: 4.1802e-04 - val_loss: 0.0071 - 5s/epoch - 9ms/step\n",
      "Epoch 5/50\n",
      "538/538 - 5s - loss: 4.5250e-04 - val_loss: 0.0083 - 5s/epoch - 9ms/step\n",
      "Epoch 6/50\n",
      "538/538 - 5s - loss: 4.2883e-04 - val_loss: 0.0072 - 5s/epoch - 9ms/step\n",
      "Epoch 7/50\n",
      "538/538 - 5s - loss: 3.6289e-04 - val_loss: 0.0055 - 5s/epoch - 9ms/step\n",
      "Epoch 8/50\n",
      "538/538 - 5s - loss: 2.9171e-04 - val_loss: 0.0041 - 5s/epoch - 9ms/step\n",
      "Epoch 9/50\n",
      "538/538 - 5s - loss: 2.2613e-04 - val_loss: 0.0030 - 5s/epoch - 9ms/step\n",
      "Epoch 10/50\n",
      "538/538 - 5s - loss: 1.8923e-04 - val_loss: 0.0024 - 5s/epoch - 9ms/step\n",
      "Epoch 11/50\n",
      "538/538 - 5s - loss: 1.7376e-04 - val_loss: 0.0021 - 5s/epoch - 9ms/step\n",
      "Epoch 12/50\n",
      "538/538 - 5s - loss: 1.6537e-04 - val_loss: 0.0019 - 5s/epoch - 9ms/step\n",
      "Epoch 13/50\n",
      "538/538 - 5s - loss: 1.5932e-04 - val_loss: 0.0018 - 5s/epoch - 9ms/step\n",
      "Epoch 14/50\n",
      "538/538 - 5s - loss: 1.5530e-04 - val_loss: 0.0018 - 5s/epoch - 9ms/step\n",
      "Epoch 15/50\n",
      "538/538 - 5s - loss: 1.4709e-04 - val_loss: 0.0017 - 5s/epoch - 9ms/step\n",
      "Epoch 16/50\n",
      "538/538 - 5s - loss: 1.3700e-04 - val_loss: 0.0015 - 5s/epoch - 9ms/step\n",
      "Epoch 17/50\n",
      "538/538 - 5s - loss: 1.2777e-04 - val_loss: 0.0014 - 5s/epoch - 9ms/step\n",
      "Epoch 18/50\n",
      "538/538 - 5s - loss: 1.2042e-04 - val_loss: 0.0012 - 5s/epoch - 10ms/step\n",
      "Epoch 19/50\n",
      "538/538 - 5s - loss: 1.1216e-04 - val_loss: 0.0011 - 5s/epoch - 9ms/step\n",
      "Epoch 20/50\n",
      "538/538 - 5s - loss: 1.0262e-04 - val_loss: 9.8679e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 21/50\n",
      "538/538 - 5s - loss: 9.3534e-05 - val_loss: 8.7105e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 22/50\n",
      "538/538 - 5s - loss: 8.5306e-05 - val_loss: 7.3955e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 23/50\n",
      "538/538 - 5s - loss: 7.5713e-05 - val_loss: 6.0379e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 24/50\n",
      "538/538 - 5s - loss: 6.4779e-05 - val_loss: 4.5046e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 25/50\n",
      "538/538 - 5s - loss: 5.2538e-05 - val_loss: 3.0241e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 26/50\n",
      "538/538 - 5s - loss: 3.9830e-05 - val_loss: 1.9460e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 27/50\n",
      "538/538 - 5s - loss: 2.7974e-05 - val_loss: 1.8249e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 28/50\n",
      "538/538 - 5s - loss: 2.2129e-05 - val_loss: 2.6352e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 29/50\n",
      "538/538 - 5s - loss: 2.6723e-05 - val_loss: 5.3244e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 30/50\n",
      "538/538 - 5s - loss: 4.3871e-05 - val_loss: 8.8512e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 31/50\n",
      "538/538 - 5s - loss: 7.7275e-05 - val_loss: 2.8230e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 32/50\n",
      "538/538 - 5s - loss: 4.1861e-05 - val_loss: 1.7039e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 33/50\n",
      "538/538 - 5s - loss: 3.2491e-05 - val_loss: 1.0564e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 34/50\n",
      "538/538 - 5s - loss: 2.2755e-05 - val_loss: 1.1525e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 35/50\n",
      "538/538 - 5s - loss: 1.7811e-05 - val_loss: 1.8375e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 36/50\n",
      "538/538 - 5s - loss: 2.0425e-05 - val_loss: 4.2911e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 37/50\n",
      "538/538 - 5s - loss: 3.8220e-05 - val_loss: 8.5494e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 38/50\n",
      "538/538 - 5s - loss: 7.2304e-05 - val_loss: 2.7809e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 39/50\n",
      "538/538 - 5s - loss: 4.4264e-05 - val_loss: 1.8928e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 40/50\n",
      "538/538 - 5s - loss: 3.6145e-05 - val_loss: 1.2448e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 41/50\n",
      "538/538 - 5s - loss: 2.7582e-05 - val_loss: 8.1779e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 42/50\n",
      "538/538 - 5s - loss: 1.8953e-05 - val_loss: 1.1025e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 43/50\n",
      "538/538 - 5s - loss: 1.6750e-05 - val_loss: 1.9554e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 44/50\n",
      "538/538 - 5s - loss: 1.9857e-05 - val_loss: 4.4445e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 45/50\n",
      "538/538 - 5s - loss: 3.9444e-05 - val_loss: 8.4180e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 46/50\n",
      "538/538 - 5s - loss: 6.5386e-05 - val_loss: 1.8250e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 47/50\n",
      "538/538 - 5s - loss: 3.3964e-05 - val_loss: 1.0084e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 48/50\n",
      "538/538 - 5s - loss: 2.6621e-05 - val_loss: 5.7824e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 49/50\n",
      "538/538 - 5s - loss: 1.8703e-05 - val_loss: 7.3308e-05 - 5s/epoch - 10ms/step\n",
      "Epoch 50/50\n",
      "538/538 - 5s - loss: 1.5212e-05 - val_loss: 1.1617e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 03:44:59.209904: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:44:59.302835: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:44:59.450388: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:45:03.934689: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:45:03.965213: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/538 - 6s - loss: 2.2635e-04 - val_loss: 0.0036 - 6s/epoch - 11ms/step\n",
      "Epoch 2/100\n",
      "538/538 - 5s - loss: 3.9062e-04 - val_loss: 0.0072 - 5s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "538/538 - 4s - loss: 6.9428e-04 - val_loss: 0.0135 - 4s/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "538/538 - 4s - loss: 6.1923e-04 - val_loss: 0.0089 - 4s/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "538/538 - 4s - loss: 4.7077e-04 - val_loss: 0.0068 - 4s/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "538/538 - 4s - loss: 3.7741e-04 - val_loss: 0.0054 - 4s/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "538/538 - 4s - loss: 2.9656e-04 - val_loss: 0.0043 - 4s/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "538/538 - 4s - loss: 2.2956e-04 - val_loss: 0.0034 - 4s/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "538/538 - 4s - loss: 1.7593e-04 - val_loss: 0.0026 - 4s/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "538/538 - 4s - loss: 1.3696e-04 - val_loss: 0.0019 - 4s/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "538/538 - 4s - loss: 1.1600e-04 - val_loss: 0.0014 - 4s/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "538/538 - 4s - loss: 1.0886e-04 - val_loss: 0.0011 - 4s/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "538/538 - 4s - loss: 1.0974e-04 - val_loss: 0.0011 - 4s/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "538/538 - 5s - loss: 1.1295e-04 - val_loss: 0.0011 - 5s/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "538/538 - 5s - loss: 1.1702e-04 - val_loss: 0.0012 - 5s/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "538/538 - 4s - loss: 1.1721e-04 - val_loss: 0.0012 - 4s/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "538/538 - 4s - loss: 1.1564e-04 - val_loss: 0.0012 - 4s/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "538/538 - 4s - loss: 1.1098e-04 - val_loss: 0.0011 - 4s/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "538/538 - 4s - loss: 1.0611e-04 - val_loss: 9.9793e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "538/538 - 4s - loss: 1.0151e-04 - val_loss: 9.0440e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "538/538 - 4s - loss: 9.7389e-05 - val_loss: 8.2563e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "538/538 - 4s - loss: 9.3341e-05 - val_loss: 7.5537e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "538/538 - 4s - loss: 8.9218e-05 - val_loss: 6.8993e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "538/538 - 4s - loss: 8.4928e-05 - val_loss: 6.2322e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "538/538 - 4s - loss: 8.0067e-05 - val_loss: 5.5548e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "538/538 - 4s - loss: 7.4116e-05 - val_loss: 4.8105e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "538/538 - 4s - loss: 6.7642e-05 - val_loss: 4.0272e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "538/538 - 4s - loss: 5.9906e-05 - val_loss: 3.1722e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "538/538 - 4s - loss: 5.1255e-05 - val_loss: 2.2976e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "538/538 - 4s - loss: 4.1316e-05 - val_loss: 1.5098e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "538/538 - 4s - loss: 3.0905e-05 - val_loss: 1.0860e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "538/538 - 4s - loss: 2.2804e-05 - val_loss: 1.5100e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "538/538 - 4s - loss: 2.2703e-05 - val_loss: 2.9195e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "538/538 - 5s - loss: 3.2830e-05 - val_loss: 4.9059e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "538/538 - 5s - loss: 4.8047e-05 - val_loss: 1.8913e-04 - 5s/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "538/538 - 4s - loss: 3.4886e-05 - val_loss: 7.3588e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "538/538 - 4s - loss: 2.1591e-05 - val_loss: 9.4437e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "538/538 - 4s - loss: 1.8609e-05 - val_loss: 1.7393e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "538/538 - 4s - loss: 2.2271e-05 - val_loss: 3.9785e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "538/538 - 4s - loss: 3.8123e-05 - val_loss: 4.3675e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "538/538 - 4s - loss: 4.6288e-05 - val_loss: 7.2797e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "538/538 - 4s - loss: 2.5914e-05 - val_loss: 4.8208e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "538/538 - 4s - loss: 1.8104e-05 - val_loss: 8.2575e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "538/538 - 4s - loss: 1.7022e-05 - val_loss: 1.7022e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "538/538 - 4s - loss: 2.0679e-05 - val_loss: 3.9106e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "538/538 - 4s - loss: 3.6488e-05 - val_loss: 4.2133e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "538/538 - 4s - loss: 4.4565e-05 - val_loss: 5.3097e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "538/538 - 4s - loss: 2.5284e-05 - val_loss: 3.1682e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "538/538 - 4s - loss: 1.8060e-05 - val_loss: 5.4918e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "538/538 - 4s - loss: 1.5926e-05 - val_loss: 1.1132e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "538/538 - 4s - loss: 1.6639e-05 - val_loss: 2.1913e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "538/538 - 5s - loss: 2.2919e-05 - val_loss: 4.8996e-04 - 5s/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "538/538 - 5s - loss: 4.1163e-05 - val_loss: 2.1771e-04 - 5s/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "538/538 - 4s - loss: 3.8376e-05 - val_loss: 3.7838e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "538/538 - 4s - loss: 2.4237e-05 - val_loss: 2.3963e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "538/538 - 4s - loss: 1.8325e-05 - val_loss: 3.7164e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "538/538 - 4s - loss: 1.5474e-05 - val_loss: 7.6251e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "538/538 - 4s - loss: 1.4975e-05 - val_loss: 1.3276e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "538/538 - 4s - loss: 1.6459e-05 - val_loss: 2.5870e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 60/100\n",
      "538/538 - 4s - loss: 2.4542e-05 - val_loss: 4.9728e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 61/100\n",
      "538/538 - 4s - loss: 3.8836e-05 - val_loss: 1.0544e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "538/538 - 4s - loss: 3.1166e-05 - val_loss: 1.7148e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "538/538 - 4s - loss: 2.0760e-05 - val_loss: 1.4826e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 64/100\n",
      "538/538 - 4s - loss: 1.5875e-05 - val_loss: 3.0203e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 65/100\n",
      "538/538 - 4s - loss: 1.3894e-05 - val_loss: 5.2989e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 66/100\n",
      "538/538 - 4s - loss: 1.3105e-05 - val_loss: 4.9075e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 67/100\n",
      "538/538 - 4s - loss: 1.3064e-05 - val_loss: 5.3607e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 68/100\n",
      "538/538 - 4s - loss: 1.4634e-05 - val_loss: 1.5691e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 69/100\n",
      "538/538 - 4s - loss: 1.9216e-05 - val_loss: 4.7852e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 70/100\n",
      "538/538 - 4s - loss: 3.6697e-05 - val_loss: 2.8297e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 71/100\n",
      "538/538 - 4s - loss: 4.0041e-05 - val_loss: 3.1119e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 72/100\n",
      "538/538 - 4s - loss: 2.7955e-05 - val_loss: 3.1437e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 73/100\n",
      "538/538 - 4s - loss: 2.5424e-05 - val_loss: 2.6516e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 74/100\n",
      "538/538 - 4s - loss: 2.2145e-05 - val_loss: 1.9666e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 75/100\n",
      "538/538 - 4s - loss: 1.8018e-05 - val_loss: 2.5842e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 76/100\n",
      "538/538 - 4s - loss: 1.5002e-05 - val_loss: 5.1006e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 77/100\n",
      "538/538 - 4s - loss: 1.3851e-05 - val_loss: 7.6324e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 78/100\n",
      "538/538 - 4s - loss: 1.3594e-05 - val_loss: 9.4728e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 79/100\n",
      "538/538 - 4s - loss: 1.4575e-05 - val_loss: 1.7070e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 80/100\n",
      "538/538 - 4s - loss: 1.8640e-05 - val_loss: 3.7056e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 81/100\n",
      "538/538 - 4s - loss: 2.7582e-05 - val_loss: 1.9123e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 82/100\n",
      "538/538 - 4s - loss: 2.7049e-05 - val_loss: 1.7140e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 83/100\n",
      "538/538 - 4s - loss: 1.8104e-05 - val_loss: 2.6279e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 84/100\n",
      "538/538 - 4s - loss: 1.4462e-05 - val_loss: 4.4972e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 85/100\n",
      "538/538 - 4s - loss: 1.4969e-05 - val_loss: 1.3530e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 86/100\n",
      "538/538 - 4s - loss: 1.7830e-05 - val_loss: 1.9340e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 87/100\n",
      "538/538 - 4s - loss: 2.2296e-05 - val_loss: 2.8630e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 88/100\n",
      "538/538 - 4s - loss: 2.7664e-05 - val_loss: 4.8298e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 89/100\n",
      "538/538 - 4s - loss: 4.1832e-05 - val_loss: 3.4673e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 90/100\n",
      "538/538 - 4s - loss: 2.6550e-05 - val_loss: 3.6585e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 91/100\n",
      "538/538 - 4s - loss: 1.4616e-05 - val_loss: 2.8114e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 92/100\n",
      "538/538 - 4s - loss: 1.4004e-05 - val_loss: 4.7893e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 93/100\n",
      "538/538 - 4s - loss: 1.5064e-05 - val_loss: 6.3448e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 94/100\n",
      "538/538 - 4s - loss: 1.5045e-05 - val_loss: 5.2376e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 95/100\n",
      "538/538 - 4s - loss: 1.4728e-05 - val_loss: 2.6647e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 96/100\n",
      "538/538 - 4s - loss: 1.5625e-05 - val_loss: 1.8988e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 97/100\n",
      "538/538 - 4s - loss: 2.3831e-05 - val_loss: 5.2118e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 98/100\n",
      "538/538 - 4s - loss: 3.6281e-05 - val_loss: 2.8691e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 99/100\n",
      "538/538 - 4s - loss: 2.2983e-05 - val_loss: 1.4363e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 100/100\n",
      "538/538 - 4s - loss: 1.8309e-05 - val_loss: 1.3670e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 03:52:26.406364: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:52:26.495723: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:52:26.635502: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:52:31.407074: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 03:52:31.436609: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/538 - 6s - loss: 1.9622e-04 - val_loss: 9.1000e-04 - 6s/epoch - 11ms/step\n",
      "Epoch 2/100\n",
      "538/538 - 5s - loss: 2.1903e-04 - val_loss: 0.0091 - 5s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "538/538 - 5s - loss: 5.4284e-04 - val_loss: 0.0063 - 5s/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "538/538 - 5s - loss: 4.7911e-04 - val_loss: 0.0098 - 5s/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "538/538 - 5s - loss: 4.7223e-04 - val_loss: 0.0090 - 5s/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "538/538 - 5s - loss: 4.2247e-04 - val_loss: 0.0071 - 5s/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "538/538 - 5s - loss: 3.2978e-04 - val_loss: 0.0052 - 5s/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "538/538 - 5s - loss: 2.3960e-04 - val_loss: 0.0035 - 5s/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "538/538 - 5s - loss: 1.8565e-04 - val_loss: 0.0026 - 5s/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "538/538 - 5s - loss: 1.6276e-04 - val_loss: 0.0021 - 5s/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "538/538 - 5s - loss: 1.5669e-04 - val_loss: 0.0020 - 5s/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "538/538 - 5s - loss: 1.5679e-04 - val_loss: 0.0020 - 5s/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "538/538 - 5s - loss: 1.6062e-04 - val_loss: 0.0020 - 5s/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "538/538 - 5s - loss: 1.5688e-04 - val_loss: 0.0020 - 5s/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "538/538 - 5s - loss: 1.4900e-04 - val_loss: 0.0019 - 5s/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "538/538 - 5s - loss: 1.3826e-04 - val_loss: 0.0017 - 5s/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "538/538 - 5s - loss: 1.3183e-04 - val_loss: 0.0016 - 5s/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "538/538 - 5s - loss: 1.2202e-04 - val_loss: 0.0014 - 5s/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "538/538 - 5s - loss: 1.1414e-04 - val_loss: 0.0012 - 5s/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "538/538 - 5s - loss: 1.0627e-04 - val_loss: 0.0011 - 5s/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "538/538 - 5s - loss: 9.8122e-05 - val_loss: 9.7558e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "538/538 - 5s - loss: 8.9134e-05 - val_loss: 8.3681e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "538/538 - 5s - loss: 8.0232e-05 - val_loss: 6.9948e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "538/538 - 5s - loss: 7.0338e-05 - val_loss: 5.6690e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "538/538 - 5s - loss: 6.0033e-05 - val_loss: 4.1897e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "538/538 - 5s - loss: 4.8946e-05 - val_loss: 2.8130e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "538/538 - 5s - loss: 3.7667e-05 - val_loss: 1.7922e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "538/538 - 5s - loss: 2.7183e-05 - val_loss: 1.6676e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "538/538 - 5s - loss: 2.1115e-05 - val_loss: 2.3273e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "538/538 - 5s - loss: 2.5314e-05 - val_loss: 5.0250e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "538/538 - 5s - loss: 4.6485e-05 - val_loss: 6.4204e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "538/538 - 5s - loss: 5.7850e-05 - val_loss: 1.8376e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "538/538 - 5s - loss: 3.2713e-05 - val_loss: 1.1077e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "538/538 - 5s - loss: 2.2546e-05 - val_loss: 1.2165e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "538/538 - 5s - loss: 1.8131e-05 - val_loss: 1.9202e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "538/538 - 5s - loss: 2.1720e-05 - val_loss: 4.5747e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "538/538 - 5s - loss: 4.6168e-05 - val_loss: 6.1431e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "538/538 - 5s - loss: 5.4533e-05 - val_loss: 1.7050e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "538/538 - 5s - loss: 3.1435e-05 - val_loss: 9.8892e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "538/538 - 5s - loss: 2.1347e-05 - val_loss: 1.0686e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "538/538 - 5s - loss: 1.7133e-05 - val_loss: 1.6584e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "538/538 - 5s - loss: 1.9686e-05 - val_loss: 3.8742e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "538/538 - 5s - loss: 3.8779e-05 - val_loss: 6.6705e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "538/538 - 5s - loss: 5.5408e-05 - val_loss: 1.6115e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "538/538 - 5s - loss: 3.0281e-05 - val_loss: 8.3725e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "538/538 - 5s - loss: 2.0776e-05 - val_loss: 8.5985e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "538/538 - 5s - loss: 1.6167e-05 - val_loss: 1.2815e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "538/538 - 5s - loss: 1.7091e-05 - val_loss: 2.7687e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "538/538 - 5s - loss: 2.7682e-05 - val_loss: 7.0053e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "538/538 - 5s - loss: 5.2304e-05 - val_loss: 1.9379e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "538/538 - 5s - loss: 3.5812e-05 - val_loss: 8.1695e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "538/538 - 5s - loss: 2.4031e-05 - val_loss: 5.3780e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "538/538 - 5s - loss: 1.6652e-05 - val_loss: 7.7130e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "538/538 - 5s - loss: 1.4946e-05 - val_loss: 1.3318e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 55/100\n",
      "538/538 - 5s - loss: 1.6554e-05 - val_loss: 2.8209e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 56/100\n",
      "538/538 - 5s - loss: 2.6497e-05 - val_loss: 6.3453e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 57/100\n",
      "538/538 - 5s - loss: 4.6662e-05 - val_loss: 1.3378e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "538/538 - 5s - loss: 3.3404e-05 - val_loss: 4.0120e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "538/538 - 5s - loss: 2.1969e-05 - val_loss: 2.8179e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 60/100\n",
      "538/538 - 5s - loss: 1.5614e-05 - val_loss: 4.8067e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 61/100\n",
      "538/538 - 5s - loss: 1.3747e-05 - val_loss: 7.2550e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 62/100\n",
      "538/538 - 5s - loss: 1.3437e-05 - val_loss: 8.9036e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 63/100\n",
      "538/538 - 5s - loss: 1.4515e-05 - val_loss: 1.6499e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 64/100\n",
      "538/538 - 5s - loss: 1.8609e-05 - val_loss: 4.3518e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 65/100\n",
      "538/538 - 5s - loss: 3.2807e-05 - val_loss: 4.0654e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 66/100\n",
      "538/538 - 5s - loss: 3.8625e-05 - val_loss: 1.4848e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 67/100\n",
      "538/538 - 5s - loss: 2.1346e-05 - val_loss: 1.4393e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 68/100\n",
      "538/538 - 5s - loss: 1.5452e-05 - val_loss: 2.3712e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 69/100\n",
      "538/538 - 5s - loss: 1.3555e-05 - val_loss: 4.0384e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 70/100\n",
      "538/538 - 5s - loss: 1.4469e-05 - val_loss: 7.1038e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 71/100\n",
      "538/538 - 5s - loss: 1.5207e-05 - val_loss: 6.4456e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 72/100\n",
      "538/538 - 5s - loss: 1.5576e-05 - val_loss: 3.5397e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 73/100\n",
      "538/538 - 5s - loss: 1.6121e-05 - val_loss: 1.2539e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 74/100\n",
      "538/538 - 5s - loss: 1.8902e-05 - val_loss: 4.2394e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 75/100\n",
      "538/538 - 5s - loss: 3.4722e-05 - val_loss: 2.2723e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 76/100\n",
      "538/538 - 5s - loss: 3.6710e-05 - val_loss: 1.5416e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 77/100\n",
      "538/538 - 5s - loss: 2.2619e-05 - val_loss: 1.3766e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 78/100\n",
      "538/538 - 5s - loss: 1.7839e-05 - val_loss: 1.5263e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 79/100\n",
      "538/538 - 5s - loss: 1.4269e-05 - val_loss: 2.7474e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 80/100\n",
      "538/538 - 5s - loss: 1.3389e-05 - val_loss: 4.2214e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 81/100\n",
      "538/538 - 5s - loss: 1.4354e-05 - val_loss: 5.9400e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 82/100\n",
      "538/538 - 5s - loss: 1.4781e-05 - val_loss: 4.7679e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 83/100\n",
      "538/538 - 5s - loss: 1.5302e-05 - val_loss: 4.9267e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 84/100\n",
      "538/538 - 5s - loss: 1.6151e-05 - val_loss: 2.0767e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 85/100\n",
      "538/538 - 5s - loss: 2.2882e-05 - val_loss: 4.1547e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 86/100\n",
      "538/538 - 5s - loss: 2.9571e-05 - val_loss: 4.1773e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 87/100\n",
      "538/538 - 5s - loss: 2.2226e-05 - val_loss: 2.5168e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 88/100\n",
      "538/538 - 5s - loss: 1.6135e-05 - val_loss: 4.2733e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 89/100\n",
      "538/538 - 5s - loss: 1.5704e-05 - val_loss: 1.1435e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 90/100\n",
      "538/538 - 5s - loss: 2.0298e-05 - val_loss: 2.8851e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 91/100\n",
      "538/538 - 5s - loss: 2.9843e-05 - val_loss: 5.3786e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 92/100\n",
      "538/538 - 5s - loss: 4.3115e-05 - val_loss: 3.4001e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 93/100\n",
      "538/538 - 5s - loss: 2.7369e-05 - val_loss: 4.9652e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 94/100\n",
      "538/538 - 5s - loss: 1.6086e-05 - val_loss: 4.3747e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 95/100\n",
      "538/538 - 5s - loss: 1.6416e-05 - val_loss: 8.1113e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 96/100\n",
      "538/538 - 5s - loss: 1.8094e-05 - val_loss: 1.0060e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 97/100\n",
      "538/538 - 5s - loss: 1.8125e-05 - val_loss: 9.4754e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 98/100\n",
      "538/538 - 5s - loss: 1.6711e-05 - val_loss: 6.0887e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 99/100\n",
      "538/538 - 5s - loss: 1.5236e-05 - val_loss: 2.1747e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 100/100\n",
      "538/538 - 5s - loss: 1.5810e-05 - val_loss: 1.8506e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 04:00:18.444900: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 04:00:18.530093: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 04:00:18.744310: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 04:00:23.899436: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-17 04:00:23.931424: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/538 - 7s - loss: 3.3368e-04 - val_loss: 0.0012 - 7s/epoch - 13ms/step\n",
      "Epoch 2/100\n",
      "538/538 - 5s - loss: 2.2492e-04 - val_loss: 0.0094 - 5s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "538/538 - 5s - loss: 6.3061e-04 - val_loss: 0.0080 - 5s/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "538/538 - 5s - loss: 5.8730e-04 - val_loss: 0.0111 - 5s/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "538/538 - 5s - loss: 5.5815e-04 - val_loss: 0.0086 - 5s/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "538/538 - 5s - loss: 4.2291e-04 - val_loss: 0.0063 - 5s/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "538/538 - 5s - loss: 3.0784e-04 - val_loss: 0.0045 - 5s/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "538/538 - 5s - loss: 2.2481e-04 - val_loss: 0.0030 - 5s/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "538/538 - 5s - loss: 1.8604e-04 - val_loss: 0.0024 - 5s/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "538/538 - 5s - loss: 1.6652e-04 - val_loss: 0.0020 - 5s/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "538/538 - 5s - loss: 1.6883e-04 - val_loss: 0.0021 - 5s/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "538/538 - 5s - loss: 1.7822e-04 - val_loss: 0.0022 - 5s/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "538/538 - 5s - loss: 1.8436e-04 - val_loss: 0.0024 - 5s/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "538/538 - 5s - loss: 1.7929e-04 - val_loss: 0.0023 - 5s/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "538/538 - 5s - loss: 1.6021e-04 - val_loss: 0.0020 - 5s/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "538/538 - 5s - loss: 1.4560e-04 - val_loss: 0.0018 - 5s/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "538/538 - 5s - loss: 1.3448e-04 - val_loss: 0.0016 - 5s/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "538/538 - 5s - loss: 1.3008e-04 - val_loss: 0.0015 - 5s/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "538/538 - 5s - loss: 1.2458e-04 - val_loss: 0.0014 - 5s/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "538/538 - 5s - loss: 1.1767e-04 - val_loss: 0.0012 - 5s/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "538/538 - 5s - loss: 1.0799e-04 - val_loss: 0.0011 - 5s/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "538/538 - 5s - loss: 1.0157e-04 - val_loss: 0.0010 - 5s/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "538/538 - 5s - loss: 9.4875e-05 - val_loss: 9.0799e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "538/538 - 5s - loss: 8.8078e-05 - val_loss: 7.9692e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "538/538 - 5s - loss: 7.9923e-05 - val_loss: 6.8398e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "538/538 - 5s - loss: 7.1067e-05 - val_loss: 5.6134e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "538/538 - 5s - loss: 6.1129e-05 - val_loss: 4.2001e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "538/538 - 5s - loss: 4.9934e-05 - val_loss: 2.8219e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "538/538 - 5s - loss: 3.7990e-05 - val_loss: 1.7557e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "538/538 - 5s - loss: 2.6992e-05 - val_loss: 1.6447e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "538/538 - 5s - loss: 2.1410e-05 - val_loss: 2.4084e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "538/538 - 5s - loss: 2.6265e-05 - val_loss: 5.2499e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "538/538 - 5s - loss: 4.7965e-05 - val_loss: 6.8105e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "538/538 - 5s - loss: 6.6644e-05 - val_loss: 1.8210e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "538/538 - 5s - loss: 3.2851e-05 - val_loss: 1.0314e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "538/538 - 5s - loss: 2.4489e-05 - val_loss: 8.9353e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "538/538 - 5s - loss: 1.7792e-05 - val_loss: 1.4311e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "538/538 - 5s - loss: 1.8857e-05 - val_loss: 3.2073e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "538/538 - 5s - loss: 3.2861e-05 - val_loss: 7.6154e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "538/538 - 5s - loss: 6.6107e-05 - val_loss: 2.8899e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "538/538 - 5s - loss: 4.1829e-05 - val_loss: 1.4588e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "538/538 - 5s - loss: 3.0991e-05 - val_loss: 8.4510e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "538/538 - 5s - loss: 2.1669e-05 - val_loss: 8.8155e-05 - 5s/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "538/538 - 5s - loss: 1.6678e-05 - val_loss: 1.4057e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "538/538 - 5s - loss: 1.8223e-05 - val_loss: 3.2230e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "538/538 - 5s - loss: 3.2619e-05 - val_loss: 8.3261e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "538/538 - 5s - loss: 6.3572e-05 - val_loss: 2.0255e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "538/538 - 5s - loss: 3.5015e-05 - val_loss: 1.0204e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "538/538 - 5s - loss: 2.5559e-05 - val_loss: 6.3311e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "538/538 - 5s - loss: 1.7541e-05 - val_loss: 9.3208e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "538/538 - 5s - loss: 1.5896e-05 - val_loss: 1.7219e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "538/538 - 5s - loss: 1.9333e-05 - val_loss: 4.1566e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "538/538 - 5s - loss: 4.2009e-05 - val_loss: 6.9988e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "538/538 - 5s - loss: 5.6313e-05 - val_loss: 1.4404e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 55/100\n",
      "538/538 - 5s - loss: 3.0210e-05 - val_loss: 7.4476e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 56/100\n",
      "538/538 - 5s - loss: 2.3065e-05 - val_loss: 4.9657e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 57/100\n",
      "538/538 - 5s - loss: 1.6245e-05 - val_loss: 7.8413e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "538/538 - 5s - loss: 1.4741e-05 - val_loss: 1.3351e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "538/538 - 5s - loss: 1.6424e-05 - val_loss: 2.8315e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 60/100\n",
      "538/538 - 5s - loss: 2.7680e-05 - val_loss: 8.4415e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 61/100\n",
      "538/538 - 5s - loss: 5.5747e-05 - val_loss: 1.5212e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 62/100\n",
      "538/538 - 5s - loss: 3.2772e-05 - val_loss: 6.2872e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 63/100\n",
      "538/538 - 5s - loss: 2.3713e-05 - val_loss: 3.5751e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 64/100\n",
      "538/538 - 5s - loss: 1.6691e-05 - val_loss: 5.5085e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 65/100\n",
      "538/538 - 5s - loss: 1.3938e-05 - val_loss: 8.0929e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 66/100\n",
      "538/538 - 5s - loss: 1.3586e-05 - val_loss: 1.1207e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 67/100\n",
      "538/538 - 5s - loss: 1.5486e-05 - val_loss: 2.5203e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 68/100\n",
      "538/538 - 5s - loss: 2.2593e-05 - val_loss: 7.1812e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 69/100\n",
      "538/538 - 5s - loss: 5.4430e-05 - val_loss: 2.7746e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 70/100\n",
      "538/538 - 5s - loss: 4.5564e-05 - val_loss: 1.7297e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 71/100\n",
      "538/538 - 5s - loss: 3.7793e-05 - val_loss: 1.3540e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 72/100\n",
      "538/538 - 5s - loss: 3.1854e-05 - val_loss: 9.1578e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 73/100\n",
      "538/538 - 5s - loss: 2.5905e-05 - val_loss: 5.2185e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 74/100\n",
      "538/538 - 5s - loss: 1.9838e-05 - val_loss: 4.3126e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 75/100\n",
      "538/538 - 5s - loss: 1.4907e-05 - val_loss: 6.8567e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 76/100\n",
      "538/538 - 5s - loss: 1.3854e-05 - val_loss: 1.0375e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 77/100\n",
      "538/538 - 5s - loss: 1.4722e-05 - val_loss: 1.8816e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 78/100\n",
      "538/538 - 5s - loss: 1.9625e-05 - val_loss: 4.5952e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 79/100\n",
      "538/538 - 5s - loss: 3.8029e-05 - val_loss: 3.2284e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 80/100\n",
      "538/538 - 5s - loss: 4.0978e-05 - val_loss: 4.6923e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 81/100\n",
      "538/538 - 5s - loss: 2.5285e-05 - val_loss: 2.7560e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 82/100\n",
      "538/538 - 5s - loss: 1.9800e-05 - val_loss: 2.1970e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 83/100\n",
      "538/538 - 5s - loss: 1.4786e-05 - val_loss: 4.0251e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 84/100\n",
      "538/538 - 5s - loss: 1.3109e-05 - val_loss: 5.0818e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 85/100\n",
      "538/538 - 5s - loss: 1.2724e-05 - val_loss: 4.7900e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 86/100\n",
      "538/538 - 5s - loss: 1.3290e-05 - val_loss: 7.1477e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 87/100\n",
      "538/538 - 5s - loss: 1.5337e-05 - val_loss: 2.0364e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 88/100\n",
      "538/538 - 5s - loss: 2.0703e-05 - val_loss: 4.7584e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 89/100\n",
      "538/538 - 5s - loss: 3.4156e-05 - val_loss: 1.6456e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 90/100\n",
      "538/538 - 5s - loss: 3.2130e-05 - val_loss: 1.4225e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 91/100\n",
      "538/538 - 5s - loss: 2.0052e-05 - val_loss: 1.4388e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 92/100\n",
      "538/538 - 5s - loss: 1.5289e-05 - val_loss: 2.2557e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 93/100\n",
      "538/538 - 5s - loss: 1.3267e-05 - val_loss: 3.6173e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 94/100\n",
      "538/538 - 5s - loss: 1.3693e-05 - val_loss: 5.5992e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 95/100\n",
      "538/538 - 5s - loss: 1.4172e-05 - val_loss: 4.4586e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 96/100\n",
      "538/538 - 5s - loss: 1.4390e-05 - val_loss: 3.8264e-05 - 5s/epoch - 9ms/step\n",
      "Epoch 97/100\n",
      "538/538 - 5s - loss: 1.5253e-05 - val_loss: 1.3202e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 98/100\n",
      "538/538 - 5s - loss: 1.7828e-05 - val_loss: 3.2300e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 99/100\n",
      "538/538 - 5s - loss: 2.7738e-05 - val_loss: 1.7429e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 100/100\n",
      "538/538 - 5s - loss: 2.6298e-05 - val_loss: 1.8365e-05 - 5s/epoch - 9ms/step\n"
     ]
    }
   ],
   "source": [
    "lstms3 = []\n",
    "models3 = []\n",
    "for batch, epoch, neuron in hyperparam3:\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neuron, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(loss='mse',optimizer='adam')\n",
    "    lstm = model.fit(train_X, train_y, epochs=epoch, batch_size=batch, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    lstms3.append(lstm)\n",
    "    models3.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "546cd3a7-bfcc-4077-9e56-6b8bfda87f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 1s 4ms/step\n",
      "(64, 25, 50)\n",
      "Epoch: 25\n",
      "Neurons: 50\n",
      "RMSE\n",
      "1564.049579459865\n",
      "MAE\n",
      "1345.2382258437272\n",
      "MAPE\n",
      "5.939033383352242\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(64, 25, 60)\n",
      "Epoch: 25\n",
      "Neurons: 60\n",
      "RMSE\n",
      "879.1673943721795\n",
      "MAE\n",
      "790.160248715066\n",
      "MAPE\n",
      "3.3264872892811446\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(64, 25, 100)\n",
      "Epoch: 25\n",
      "Neurons: 100\n",
      "RMSE\n",
      "983.2203482933398\n",
      "MAE\n",
      "919.2043442752166\n",
      "MAPE\n",
      "3.7374417113486524\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(64, 50, 50)\n",
      "Epoch: 50\n",
      "Neurons: 50\n",
      "RMSE\n",
      "863.1279414704155\n",
      "MAE\n",
      "833.4169173860311\n",
      "MAPE\n",
      "3.1247800333167404\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(64, 50, 60)\n",
      "Epoch: 50\n",
      "Neurons: 60\n",
      "RMSE\n",
      "662.3826598328911\n",
      "MAE\n",
      "624.4346390839029\n",
      "MAPE\n",
      "2.3949385561479866\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(64, 50, 100)\n",
      "Epoch: 50\n",
      "Neurons: 100\n",
      "RMSE\n",
      "705.5720548249003\n",
      "MAE\n",
      "671.10840576378\n",
      "MAPE\n",
      "2.5002970553080597\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(64, 100, 50)\n",
      "Epoch: 100\n",
      "Neurons: 50\n",
      "RMSE\n",
      "242.02745109853294\n",
      "MAE\n",
      "159.82871680488512\n",
      "MAPE\n",
      "0.5172003095678751\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(64, 100, 60)\n",
      "Epoch: 100\n",
      "Neurons: 60\n",
      "RMSE\n",
      "890.5194486606285\n",
      "MAE\n",
      "859.3597052138966\n",
      "MAPE\n",
      "3.158330030005925\n",
      "269/269 [==============================] - 1s 3ms/step\n",
      "(64, 100, 100)\n",
      "Epoch: 100\n",
      "Neurons: 100\n",
      "RMSE\n",
      "280.53201599726464\n",
      "MAE\n",
      "217.29618296924218\n",
      "MAPE\n",
      "0.8053016895042848\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "wb3 = Workbook()\n",
    "ws3 = wb3.active\n",
    "for x in models3:\n",
    "    # make a prediction\n",
    "    test_x2 = test_X\n",
    "    yhat = x.predict(test_x2)\n",
    "    inv_yhat = np.concatenate((np.zeros((len(yhat), 4)),yhat), axis=1)\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    test_y = test_y.reshape((len(test_y), 1))\n",
    "    inv_y = np.concatenate((np.zeros((len(yhat), 4)), test_y), axis=1)\n",
    "    inv_y = scaler.inverse_transform(inv_y)\n",
    "    yhat_df = pd.DataFrame(inv_yhat, columns = ['Open','High','Low', 'Volume', 'Close'])\n",
    "    y_df = pd.DataFrame(inv_y, columns = ['Open','High','Low', 'Volume', 'Close'])\n",
    "    print(hyperparam3[i])\n",
    "    print(\"Epoch: \"+ str(lstms3[i].params['epochs']))\n",
    "    print(\"Neurons: \"+str(x.layers[0].units))\n",
    "    i = i+1\n",
    "    ws3['A'+str(i)] = 'LSTM'\n",
    "    ws3['B'+str(i)] = hyperparam3[i-1][0]\n",
    "    ws3['C'+str(i)] = hyperparam3[i-1][1]\n",
    "    ws3['D'+str(i)] = hyperparam3[i-1][2]\n",
    "    print('RMSE')\n",
    "    print(RMSE(y_df['Close'],yhat_df['Close']))\n",
    "    ws3['E'+str(i)] = RMSE(y_df['Close'],yhat_df['Close'])\n",
    "    print('MAE')\n",
    "    print(MAE(y_df['Close'],yhat_df['Close']))\n",
    "    ws3['F'+str(i)] = MAE(y_df['Close'],yhat_df['Close'])\n",
    "    print('MAPE')\n",
    "    print(MAPE(y_df['Close'],yhat_df['Close']))\n",
    "    ws3['G'+str(i)] = MAPE(y_df['Close'],yhat_df['Close'])\n",
    "wb3.save('LSTMresult3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "437a712e-6fab-4837-a968-0ec65d9294ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for x in models1:\n",
    "    x.save('LSTM_BTC'+str(hyperparam1[i])+'.h5')\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7dc4933-7665-4202-9cd2-99e55cbd9af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for x in models2:\n",
    "    x.save('LSTM_BTC'+str(hyperparam2[i])+'.h5')\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c0c7795-99a5-49bf-bd8a-01a9b7921cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for x in models3:\n",
    "    x.save('LSTM_BTC'+str(hyperparam3[i])+'.h5')\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d99b65f4-ade9-447a-9440-bab346a23910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.70460292, 0.70139869, 0.69903957, 0.04063563, 0.69894613],\n",
       "        [0.69893086, 0.69813987, 0.68260966, 0.08796077, 0.68405741],\n",
       "        [0.68404247, 0.69308025, 0.68517693, 0.05862605, 0.69212687],\n",
       "        ...,\n",
       "        [0.697227  , 0.69954349, 0.6944213 , 0.02694942, 0.70249966],\n",
       "        [0.70248447, 0.69954076, 0.69862652, 0.0196356 , 0.70334397],\n",
       "        [0.70332861, 0.70442549, 0.70210474, 0.0243104 , 0.70612774]],\n",
       "\n",
       "       [[0.69893086, 0.69813987, 0.68260966, 0.08796077, 0.68405741],\n",
       "        [0.68404247, 0.69308025, 0.68517693, 0.05862605, 0.69212687],\n",
       "        [0.69223823, 0.70098237, 0.69243814, 0.03939832, 0.70407891],\n",
       "        ...,\n",
       "        [0.70248447, 0.69954076, 0.69862652, 0.0196356 , 0.70334397],\n",
       "        [0.70332861, 0.70442549, 0.70210474, 0.0243104 , 0.70612774],\n",
       "        [0.70611216, 0.70277679, 0.69291352, 0.03340667, 0.69615671]],\n",
       "\n",
       "       [[0.68404247, 0.69308025, 0.68517693, 0.05862605, 0.69212687],\n",
       "        [0.69223823, 0.70098237, 0.69243814, 0.03939832, 0.70407891],\n",
       "        [0.70406353, 0.70145658, 0.70309869, 0.01836972, 0.70143568],\n",
       "        ...,\n",
       "        [0.70332861, 0.70442549, 0.70210474, 0.0243104 , 0.70612774],\n",
       "        [0.70611216, 0.70277679, 0.69291352, 0.03340667, 0.69615671],\n",
       "        [0.6961415 , 0.6960124 , 0.69097739, 0.03729539, 0.69708214]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.19896959, 0.19822184, 0.19962821, 0.03695466, 0.19921957],\n",
       "        [0.19921522, 0.1983516 , 0.19918514, 0.05411871, 0.19879917],\n",
       "        [0.19879483, 0.19795914, 0.19900611, 0.04730477, 0.19869988],\n",
       "        ...,\n",
       "        [0.19912097, 0.19825314, 0.19892417, 0.04533334, 0.1983858 ],\n",
       "        [0.19839491, 0.1986333 , 0.19900075, 0.03586396, 0.19939464],\n",
       "        [0.1994022 , 0.19883446, 0.19993895, 0.03284709, 0.19987706]],\n",
       "\n",
       "       [[0.19921522, 0.1983516 , 0.19918514, 0.05411871, 0.19879917],\n",
       "        [0.19879483, 0.19795914, 0.19900611, 0.04730477, 0.19869988],\n",
       "        [0.19869844, 0.1994322 , 0.19931042, 0.07796525, 0.19926708],\n",
       "        ...,\n",
       "        [0.19839491, 0.1986333 , 0.19900075, 0.03586396, 0.19939464],\n",
       "        [0.1994022 , 0.19883446, 0.19993895, 0.03284709, 0.19987706],\n",
       "        [0.19987269, 0.19870805, 0.19955209, 0.03659509, 0.19901029]],\n",
       "\n",
       "       [[0.19879483, 0.19795914, 0.19900611, 0.04730477, 0.19869988],\n",
       "        [0.19869844, 0.1994322 , 0.19931042, 0.07796525, 0.19926708],\n",
       "        [0.1992638 , 0.19833245, 0.19854712, 0.07507691, 0.19819562],\n",
       "        ...,\n",
       "        [0.1994022 , 0.19883446, 0.19993895, 0.03284709, 0.19987706],\n",
       "        [0.19987269, 0.19870805, 0.19955209, 0.03659509, 0.19901029],\n",
       "        [0.19902076, 0.1982893 , 0.19970096, 0.02019068, 0.19933369]]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4164a8f9-5a50-4f2e-a763-46d97b3a46b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
